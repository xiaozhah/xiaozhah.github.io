<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[å­¦ä¹ D3.jså¯è§†åŒ–]]></title>
    <url>%2F2018%2F08%2F03%2F%E5%AD%A6%E4%B9%A0D3-js%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[ä¹‹å‰D3.jsæ‰€å­¦çŸ¥è¯†å¯ä»¥ä»æˆ‘çš„åšå®¢çš„é€æ¸å®Œå–„èšç±»æ•ˆæœçš„å¯è§†åŒ–ä¸­æ‰¾åˆ°å› æ­¤åŸºç¡€çš„ä¸€äº›ä¸åœ¨æ­¤æ•™ç¨‹ä¸­äº†ï¼Œä»¥ä¸‹çš„ä¸€äº›å°†å‚è€ƒä¹¦æœ¬ä»¥åŠç½‘ç«™ æ•°æ®å¯è§†åŒ–-ä½¿ç”¨D3è®¾è®¡äº¤äº’å¼å›¾è¡¨D3ç‰ˆæœ¬4.5.0ã€‚ç›®å‰æ˜¯5.5.0ï¼Œåœ¨è¿™é‡Œæš‚æ—¶ä¸è€ƒè™‘å‘é«˜ç‰ˆæœ¬å‡çº§ ä¹¦æœ¬é‡‡ç”¨äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾çš„ã€Šæ•°æ®å¯è§†åŒ–-ä½¿ç”¨D3è®¾è®¡äº¤äº’å¼å›¾è¡¨ã€‹ï¼ˆä½œè€…Scott Murrayï¼‰ï¼Œæˆ‘çš„D3å…¥é—¨ä¹¦ä¹Ÿæ˜¯JavaScriptçš„å…¥é—¨æ•™æã€‚ ç¬¬äº”ç«  è¯»å–æ•°æ®rowConverterä½œä¸ºä¸€ä¸ªæ–°å‚æ•°ï¼Œå¯ä»¥è¿›è¡Œé€è¡Œçš„æ•°æ®é¢„å¤„ç† 12345678var rowConverter = function(d) &#123; return &#123; Food: d.Food, //No conversion Deliciousness: parseFloat(d.Deliciousness) &#125;;&#125;d3.csv("food.csv", rowConverter, function(data) &#123; console.log(data);&#125;); ç¬¬å…«ç«  æ•°è½´ç¬¬ä¸€ç‰ˆå†…å®¹é¦–å…ˆå»ºç«‹äº†ä¸¤ä¸ªæ¯”ä¾‹å°ºï¼Œåˆæ ¹æ®æ•°æ®èŒƒå›´å»ºç«‹ç›¸åº”çš„åæ ‡è½´ï¼ˆticksæ˜¯5ï¼Œä½†æ˜¯D3ä¼šä¸ºäº†ç¾è§‚è€Œåœ¨5é™„è¿‘å–å€¼ï¼ŒtickFormatç”¨äºæ ¼å¼åŒ–åæ ‡è½´æ ‡ç­¾å°ºåº¦çš„æ•°æ®æ ¼å¼ï¼Œè¿™é‡Œæ˜¯ä¿ç•™ä¸€ä½æœ‰æ•ˆæ•°ç»„ï¼‰ã€‚ç´§æ¥ç€åˆ›å»ºäº†gåˆ†ç»„ï¼Œå¹¶å°†å®ƒä¼ é€’ç»™åæ ‡è½´ï¼ˆcallå‡½æ•°ï¼‰ï¼Œå¯ä»¥è®¤ä¸ºè¿™æ—¶å€™åæ ‡è½´å‡½æ•°ç›¸å½“äºä¸€ä¸ªé­”æ³•å¸ˆå¼€å§‹æ‰“é€ ä¸ä¸€æ ·çš„gåˆ†ç»„äº†ï¼è®¾ç½®gåˆ†ç»„å±äºç±».axisæ˜¯ä¸ºäº†å¯ä»¥åœ¨CSSæ ·å¼è¡¨ä¸­ç»Ÿä¸€å¯¹åæ ‡è½´çš„è§†è§‰æ ¼å¼è¿›è¡Œç®¡ç† 123456789101112131415161718192021222324252627282930var xScale = d3.scaleLinear() .domain([0, d3.max(dataset, function(d) &#123; return d[0]; &#125;)]) .range([padding, w - padding * 2]);var yScale = d3.scaleLinear() .domain([0, d3.max(dataset, function(d) &#123; return d[1]; &#125;)]) .range([h - padding, padding]);var formatAsPercentage = d3.format(".1%");var xAxis = d3.axisBottom() .scale(xScale) .ticks(5) .tickFormat(formatAsPercentage);var yAxis = d3.axisLeft() .scale(yScale) .ticks(5) .tickFormat(formatAsPercentage);svg.append("g") .attr("class", "axis") .attr("transform", "translate(0," + (h - padding) + ")") .call(xAxis);//Create Y axissvg.append("g") .attr("class", "axis") .attr("transform", "translate(" + padding + ",0)") .call(yAxis); ç¬¬äºŒç‰ˆå¢åŠ çš„å†…å®¹å¯ä»¥å¢åŠ æ—¶é—´æ¯”ä¾‹å°ºd3.extentç­‰äºmmaçš„MinMaxå‡½æ•° 12345678910111213141516var parseTime = d3.timeParse("%m/%d/%y");//Function for converting CSV values from strings to Dates and numbers//parseIntæ˜¯JavaScriptçš„å‡½æ•°var rowConverter = function(d) &#123; return &#123; Date: parseTime(d.Date), Amount: parseInt(d.Amount) &#125;;&#125;xScale = d3.scaleTime() .domain( d3.extent(dataset, function(d) &#123; return d.Date; &#125;), ) .range([padding, w - padding]); ç¬¬ä¹ç«  æ›´æ–°ã€è¿‡æ¸¡å’ŒåŠ¨ç”»]]></content>
      <categories>
        <category>ç¼–ç¨‹</category>
      </categories>
      <tags>
        <tag>å¯è§†åŒ–</tag>
        <tag>JavaScript</tag>
        <tag>D3.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[é€æ¸å®Œå–„èšç±»æ•ˆæœçš„å¯è§†åŒ–]]></title>
    <url>%2F2018%2F07%2F31%2F%E9%80%90%E6%B8%90%E5%AE%8C%E5%96%84%E8%81%9A%E7%B1%BB%E6%95%88%E6%9E%9C%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[æˆ‘çš„ç›®æ ‡æ˜¯å¯è§†åŒ–ä¸€ä¸ªEmbeddingçŸ©é˜µçš„èšç±»æ•ˆæœï¼Œä½†æ˜¯çŸ©é˜µæå¤§ï¼Œç»´æ•°ä¹Ÿé«˜ã€‚ å…·ä½“æ¥è¯´å°±æ˜¯çŸ©é˜µæ˜¯ä¸€ä¸ªçŸ©é˜µç»´åº¦æ˜¯459753*32ï¼Œæ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªå‘é‡ï¼Œä»£è¡¨å•å…ƒå¯¹åº”çš„UnitVectorï¼›çŸ©é˜µå¯¹åº”çš„æ ‡ç­¾æ˜¯459753ä¸ªï¼Œæ¯ä¸€ä¸ªæ ‡ç­¾è®°å½•å½“å‰å•å…ƒå¯¹åº”çš„å…¶ä»–ä¿¡æ¯ï¼ˆä¾‹å¦‚å•å…ƒçš„æ—¶é•¿ã€å•å…ƒæ‰€å±ç±»åˆ«ã€å•å…ƒå¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶åï¼‰ï¼Œå…¶ä¸­æœ€å…³æ³¨çš„æ˜¯UnitVectorä¸å•å…ƒæ‰€å±ç±»åˆ«çš„å…³ç³» ä¹Ÿå°±æ˜¯å·²çŸ¥äºŒè¿›åˆ¶æ–‡ä»¶UnitVectorçŸ©é˜µä¸æ ‡ç­¾æ–‡ä»¶ Mathematicaæœ€å¼€å§‹é‡‡ç”¨çš„æ–¹æ³•æ˜¯Mathematica tSNEé™ç»´12345678data=Import["../phone_name_frame_id.csv","Table"];features=Partition[Import["Unit2Vec_UnitVector.dat","Real32"],32];features=DimensionReduce[features,2,Method-&gt;"TSNE"];Export["./explain/Unit2Vec_tSNE.dat",features,"Real32"];byspecies=GroupBy[Thread[features-&gt;data[[All,2]]],Last-&gt;First];file="./explain/Visualization Phone Unit2Vec.wl";If[FileExistsQ[file],DeleteFile@file];Save[file,byspecies] å…¶ä¸­data[[All,2]]å°±æ˜¯éŸ³ç´ æ‰€å±ç±»åˆ«ä¿¡æ¯ï¼ŒUnit2Vec_UnitVector.datæ˜¯EmbeddingçŸ©é˜µã€‚ä¼šè¾“å‡ºä¸¤ä¸ªæ–‡ä»¶ ç¬¬ä¸€ä¸ªUnit2Vec_tSNE.datæ˜¯459753*2çš„å·²ç»é™ç»´å¾—åˆ°çš„çŸ©é˜µï¼Œè¿™åœ¨Javascriptæ‰ç”¨åˆ°çš„ ç¬¬äºŒä¸ªä¾¿äºMathematicaå¯è§†åŒ– å¯è§†åŒ–é™ç»´çš„åˆ†å¸ƒ123456byspecies=KeySort@Import["Visualization Phone Unit2Vec.wl"];$scheme="Rainbow";ListPlot[Values[byspecies],PlotLegends-&gt;PointLegend[$scheme,Keys[byspecies],LegendMarkerSize-&gt;15],PlotStyle-&gt;Map[(Directive[PointSize[0.0015],ColorData[$scheme][#]]&amp;),Rescale@Range@Length@Keys@byspecies],ImageSize-&gt;650]Export["UnitVector_vis.pdf",Rasterize[Magnify[%,4],"Image"]](*å› ä¸ºç‚¹æ•°å¤ªå¤šåªèƒ½å…ˆè½¬åŒ–ä¸ºå›¾åƒåå†å¯¼å‡ºï¼Œä¸ç„¶PDFæœ‰å‡ ç™¾å…†*) å¯è§†åŒ–æ··æ·†çŸ©é˜µåœ¨åŸå§‹ç©ºé—´è®¡ç®—è·ç¦»å³é’ˆå¯¹æ¬§å¼è·ç¦»æœ€è¿‘çš„å•å…ƒè§‚å¯Ÿå¯¹åº”çš„æ‰€å±ç±»åˆ«æ˜¯å¦ç›¸åŒæ¥è¿›è¡Œå¯è§†åŒ– 12345678data=Partition[Import["Unit2Vec_UnitVector.dat","Real32"],32];phoneid=Import["../phone_name_frame_id.csv","Table"];nearstData=Nearest[data,DistanceFunction-&gt;EuclideanDistance];Assodata=Association@Thread[data-&gt;Range[Length@data]];ReplaceiablePhone=Table[phoneid[[x]]-&gt;phoneid[[Assodata[nearstData[data[[phoneid[[x,1]]+1]],2][[2]]]]],&#123;x,Length@phoneid&#125;];fileName="./explain/ReplaceiablePhone Unit2Vec_64_epochs50.wl";If[FileExistsQ[fileName],DeleteFile[fileName]];Save[fileName,ReplaceiablePhone] 12345678910111213ReplaceiablePhoneDir="\\\\172.16.46.88\\xzhou\\project\\Yanping13k\\Unit2VecAddDur\\Unit2Vec_64_epochs50\\explain\\ReplaceiablePhone Unit2Vec_64_epochs50.wl";ReplaceiablePhone=Get[ReplaceiablePhoneDir];confusionMatrixData=#[[1,2]]-&gt;#[[2,2]]&amp;/@ReplaceiablePhone;phone=Union@confusionMatrixData[[All,1]];m=Normal@SparseArray@Normal@Counts[&#123;#[[1]],#[[2]]&#125;&amp;/@(confusionMatrixData/.Thread[phone-&gt;Range[Length@phone]])];mNorm=N[m/Total[m,&#123;2&#125;]];t=Transpose@Map[Flatten,&#123;#,Reverse@Transpose@#&#125;&amp;[Table[Range[1,2 #-1,2],&#123;#&#125;]]&amp;[Length@mNorm]]/2;p=MatrixPlot[mNorm,Epilog-&gt;Text@@@Transpose[&#123;Catenate@m,t&#125;],FrameTicks-&gt;&#123;Transpose@&#123;Range[Length@phone],phone&#125;,Transpose@&#123;Range[Length@phone],Total[m,&#123;1&#125;]&#125;,Transpose@&#123;Range[Length@phone],Total[m,&#123;2&#125;]&#125;,Transpose@&#123;Range[Length@phone],phone&#125;&#125;,ImageSize-&gt;1700];Column[&#123;Row[&#123;Rotate["actual class",90 Degree],p&#125;,Alignment-&gt;Center],Spacer@5,"predicted class"&#125;,Alignment-&gt;Center];Export[FileNameJoin@Flatten[&#123;Most@#,"ConfusionMatrixPlot "&lt;&gt;StringSplit[StringSplit[Last@#," "][[2]],"."][[1]]&lt;&gt;".pdf"&#125;&amp;@FileNameSplit[ReplaceiablePhoneDir]],%];p=MatrixPlot[mNorm,FrameTicks-&gt;&#123;Transpose@&#123;Range[Length@phone],Style[#,13]&amp;/@phone&#125;,Transpose@&#123;Range[Length@phone],Rotate[Style[#,13],30Degree]&amp;/@Total[m,&#123;1&#125;]&#125;,Transpose@&#123;Range[Length@phone],Style[#,13]&amp;/@Total[m,&#123;2&#125;]&#125;, Transpose@&#123;Range[Length@phone],Rotate[Style[#,13],30Degree]&amp;/@phone&#125;&#125;,ImageSize-&gt;1700];Column[&#123;Row[&#123;Rotate["actual class",90 Degree],p&#125;,Alignment-&gt;Center],Spacer@5,"predicted class"&#125;,Alignment-&gt;Center];SystemOpen@Export[FileNameJoin@Flatten[&#123;Most@#,"ConfusionMatrixPlotBeautiful_"&lt;&gt;StringSplit[StringSplit[Last@#," "][[2]],"."][[1]]&lt;&gt;".pdf"&#125;&amp;@FileNameSplit[ReplaceiablePhoneDir]],%]; ä½¿ç”¨Tensorboardä¼˜ç‚¹ å¯ä»¥äº¤äº’ å¯ä»¥åŠ¨æ€è§‚å¯Ÿèšç±»æƒ…å†µ å¯ä»¥å­˜å‚¨é™ç»´çš„ç»“æœ 123456789101112131415161718192021222324252627282930313233343536373839404142434445import osimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datafrom tensorflow.contrib.tensorboard.plugins import projectorimport numpy as npdef BinaryRead(datafile,column): data = np.fromfile(datafile,dtype=np.float32) LengthOfFile=len(data) assert(LengthOfFile) assert((LengthOfFile%column)==0) data.shape = [int(LengthOfFile/column),column] return dataLOG_DIR = 'logs'metadata = os.path.join(LOG_DIR, 'metadata.tsv')data_path='Unit2Vec_UnitVector.dat'name='Unit2Vec'aall_data=BinaryRead(data_path,32)UnitVector = tf.Variable(all_data, name=name)txt = open(r"../phone_name_frame_id.csv").readlines()all_label = list(map(lambda i:i.split('\t')[1],txt))all_dur = list(map(lambda i:int(i.split('\t')[3]),txt))mydict=&#123;p:i for i,p in enumerate(sorted(list(set(all_label))))&#125;with open(metadata, 'w') as metadata_file: metadata_file.write('Index\tColorIndex\tPhoneme\tPhoneDur\n') for i,row in enumerate(all_label): metadata_file.write('%d\t%d\t%s\t%d\n' % (i,mydict[row],row,all_dur[i]))with tf.Session() as sess: saver = tf.train.Saver([UnitVector]) sess.run(UnitVector.initializer) saver.save(sess, os.path.join(LOG_DIR, name+'.ckpt')) config = projector.ProjectorConfig() # One can add multiple embeddings. embedding = config.embeddings.add() embedding.tensor_name = UnitVector.name # Link this tensor to its metadata file (e.g. labels). embedding.metadata_path = 'metadata.tsv' # Saves a config file that TensorBoard will read during startup. projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config) PCA éš”ç¦»æŸ¥çœ‹ç›¸åŒéŸ³ç´ å¯¹åº”çš„ç‚¹ï¼ˆä½¿ç”¨äº†æ­£åˆ™è¡¨è¾¾å¼ï¼‰ tSNE ç­›é€‰ç‚¹å¹¶å¯è§†åŒ–å…¶ä»–ç‰¹å¾æ¯”å¦‚æ—¶é•¿ ç¼ºç‚¹åœ¨äº ä¸èƒ½å¬éŸ³ç´ å¯¹åº”çš„å£°éŸ³ tSNEç»“æœä¸å¦‚Mathematicaå¥½,è€Œä¸”mmaä¹Ÿæ˜¯å®Œå…¨ä¸çŸ¥é“labelä¿¡æ¯å»åšé™ç»´çš„ ä¸èƒ½åœ¨å·²ç»ç»è¿‡tSNEé™ç»´å¹¶æ˜¾ç¤ºæ‰€æœ‰éŸ³ç´ ç±»åˆ«çš„æƒ…å†µä¸‹ï¼ŒæŸ¥çœ‹æŸä¸ªéŸ³ç´ å›¢çš„éŸ³ç´ æ—¶é•¿åˆ†å¸ƒæƒ…å†µã€‚ä¹Ÿå°±æ˜¯ä¸»å›¾ä¸èƒ½åŒæ—¶æŸ¥çœ‹å¤šç§ç‰¹å¾ï¼Œè‡ªå®šä¹‰ç¨‹åº¦ä½ D3.jsé˜¶æ®µä½¿ç”¨D3ç‰ˆæœ¬æ˜¯5.5.0å› ä¸ºæˆ‘çƒ­çˆ±å¯è§†åŒ–ï¼Œæ‰€ä»¥å†³å®šå­¦ä¹ D3.jsï¼Œç›®å‰æœ€æµè¡Œçš„å¯è§†åŒ–åº“ä¹‹ä¸€ï¼Œä¸ä»…å¯ä»¥å­¦ä¹ å‰ç«¯çŸ¥è¯†,Javascriptè¿˜å¯ä»¥é€šè¿‡çœ‹åˆ«äººçš„å¯è§†åŒ–é¡¹ç›®åŸ¹å…»è‰ºæœ¯ç›´è§‰ Githubåœ°å€è§æˆ‘çš„Vis-UnitVector åœ¨ä»¥ä¸‹ä»£ç ä¸­ï¼Œé¢œè‰²æ¸²æŸ“çš„æ–¹å¼å’Œä»¥å‰mathematicaä¸€æ ·ï¼Œåªæ˜¯èƒŒæ™¯è‰²æ¢æˆäº†é»‘è‰²ï¼Œæ›´é…·äº†æ˜¯ä¸æ˜¯ğŸ˜ä¹‹å‰Mathematicaé¢œè‰²æ˜¯è¿™æ ·ä½¿ç”¨çš„, å°±æ˜¯ç¬¬äºŒä¸ªè¾“å‡ºçš„61ç§é¢œè‰²ï¼Œç°åœ¨æŠŠå®ƒè½¬åŒ–ä¸ºäº†åå…­è¿›åˆ¶å½¢å¼ åˆæœŸä»£ç ç®€å•åªèƒ½æ˜¾ç¤ºé™æ€å›¾123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Vis UnitVector&lt;/title&gt; &lt;script type="text/javascript" src="d3/d3.js"&gt;&lt;/script&gt; &lt;style type="text/css"&gt; /* No style rules here yet */ &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;script type="text/javascript"&gt; //Width and height var w = 1170, h=680; var dataset, cur_lab, selectQ = false; // a global d3.json("Unit2Vec_tSNE.json").then(function(json) &#123; dataset = json; visualize(); &#125;); function visualize() &#123; //Create SVG element var svg = d3.select("body") .append("svg") .attr("width", w) .attr("height", h); //åˆ›å»ºèƒŒæ™¯ç”¨äºè§¦å‘ç‚¹å‡»äº‹ä»¶ï¼ˆé¢œè‰²å¤ä½ï¼‰ svg.append("rect") .attr("x", 0) .attr("y", 0) .attr("width", w) .attr("height", h) .attr("fill","black") .on("click",function(d)&#123; //è§¦å‘èƒŒæ™¯ç‚¹å‡»äº‹ä»¶ï¼Œå¤ä½é¢œè‰²çš„äº‹ä»¶ d3.selectAll("circle") .attr("fill", function(d) &#123; return color_map(d3.values(d)[0].lab); &#125;); //ç»™æ–‡æœ¬ä¼ ç©ºå­—ç¬¦ä¸²ï¼Œå› ä¸ºå½“å‰ç‚¹å‡»çš„æ˜¯èƒŒæ™¯è€Œæ²¡ç‚¹å‡»ä»»ä½•ç‚¹ d3.select("text").text(""); selectQ = false; &#125;); //æ·»åŠ æ–‡æœ¬æ˜¾ç¤ºå½“å‰ç‚¹å‡»çš„ç‚¹å¯¹åº”çš„éŸ³ç´ ç±»åˆ« svg.append("text") .attr("x",100) .attr("y",80) .attr("font-size",50); var min_max_x = d3.extent(dataset,function(d)&#123;return d3.values(d)[0].pos[0]&#125;); var min_x = min_max_x[0]; var max_x = min_max_x[1]; var min_max_y = d3.extent(dataset,function(d)&#123;return d3.values(d)[0].pos[1]&#125;); var min_y = min_max_y[0]; var max_y = min_max_y[1]; //åˆ›å»ºæ˜ å°„ç‚¹ä½ç½®çš„æ¯”ä¾‹å°º var xScale = d3.scaleLinear().domain([min_x,max_x]).range([0,w]); var yScale = d3.scaleLinear().domain([min_y,max_y]).range([h,0]); var phoneme = ["a", "ai", "an", "ang", "ao", "b", "c", "ch", "d", "e", "ei", "en", "eng", "er", "f", "g", "h", "i", "ia", "ian", "iang", "iao", "ie", "ii", "iii", "in", "ing", "iong", "iou", "j", "k", "l", "m", "n", "o", "ong", "ou", "p", "q", "r", "s", "sh", "sil", "sp", "t", "u", "ua", "uai", "uan", "uang", "uei", "uen", "ueng", "uo", "v", "van", "ve", "vn", "x", "z", "zh"] var color = ["#781c86", "#6d1c90", "#621d99", "#571ea2", "#4e20ab", "#4a27b2","#462eb9", "#4236c1", "#403ec6", "#3f47c9", "#3f51cc", "#3e5acf","#3f63cf", "#416bce", "#4274ce", "#447ccd", "#4783c8", "#498ac4", "#4c90c0", "#4f97bb", "#539bb5", "#56a0ae", "#5aa5a8", "#5ea9a1", "#63ac9a", "#68af93", "#6cb28c", "#72b485", "#78b67e", "#7db877", "#83ba70", "#89bb6b", "#90bc65", "#96bd60", "#9dbe5a", "#a3be56", "#aabd52", "#b0bd4e", "#b7bd4b", "#bdbb48", "#c3ba46", "#c9b843", "#ceb541", "#d3b240", "#d8ae3e", "#dcab3c", "#dfa53b", "#e19f3a", "#e49938", "#e69237", "#e68a35", "#e68133", "#e67832", "#e56e30", "#e4632e", "#e2582c", "#e04e29", "#df4327", "#dd3726", "#dc2c24", "#db2122"] //åˆ›å»ºéŸ³ç´ ä¸å¯¹åº”é¢œè‰²çš„åºæ•°æ¯”ä¾‹å°º var color_map = d3.scaleOrdinal() .domain(phoneme) .range(color); //åˆ›å»ºä¸€ä¸ªåŒ…å«æ¯”ä¾‹å°ºçš„å­—å…¸ï¼Œå¯ä»¥å°†éŸ³ç´ æ—¶é•¿æ˜ å°„åœ¨[-2,2]å†… var color_map_dict = new Array(); for (var i = 0; i &lt; phoneme.length; i++) &#123; var min_max_dur = d3.extent( dataset.filter(function(d) &#123;return d3.values(d)[0].lab == phoneme[i];&#125;), function(d)&#123;return d3.values(d)[0].dur&#125;); color_map_dict[phoneme[i]] = d3.scaleLinear() .domain([min_max_dur[0],min_max_dur[1]]) .range([-2,2]); &#125; //è®¾ç½®ç‚¹çš„ç›¸å…³äº‹ä»¶å±æ€§ svg.selectAll("circle") .data(dataset) .enter() .append("circle") .attr("cx", function(d) &#123; return xScale(d3.values(d)[0].pos[0]); &#125;) .attr("cy", function(d) &#123; return yScale(d3.values(d)[0].pos[1]); &#125;) .attr("r", 3) .attr("fill", function(d) &#123; return color_map(d3.values(d)[0].lab); &#125;) .call(d3.zoom().on("zoom",function()&#123; svg.attr("transform",d3.event.transform); &#125;)) .on("mouseover",function(d)&#123; var info = d3.values(d)[0] if(selectQ)&#123; if(info.lab == cur_lab) new Audio("wav_phone/"+info.name+".wav").play(); &#125; else new Audio("wav_phone/"+info.name+".wav").play(); //ç»™æ–‡æœ¬ä¼ å½“å‰é¼ æ ‡æ»‘è¿‡çš„éŸ³ç´ å d3.select("text") .text(info.lab) .attr("fill","white"); &#125;) .on("click",function(d)&#123; cur_lab = d3.values(d)[0].lab; //ç»™æŒ‡å®šç‚¹ä¸Šå½©è‰²ï¼Œå¹¶æ ¹æ®æ¯ä¸ªå•å…ƒæ—¶é•¿ä¸åŒä¸Šä¸ä¸€æ ·çš„äº®åº¦ //æ—¶é•¿è¶Šå°è¶ŠæŒ‰ï¼Œè¶Šå¤§è¶Šäº® d3.selectAll("circle").filter(function(d) &#123; return d3.values(d)[0].lab == cur_lab; &#125;) .attr("fill", function(d) &#123; var info = d3.values(d)[0] return d3.rgb(color_map(info.lab)).darker(color_map_dict[info.lab](info.dur)); &#125;) //ç»™å…¶ä½™ç‚¹ä¸Šç°è‰² d3.selectAll("circle").filter(function(d) &#123; return d3.values(d)[0].lab != cur_lab; &#125;) .attr("fill","grey"); selectQ = true; &#125;) ; &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; æ•´ä½“å›¾çš„å±•ç¤ºå±€éƒ¨å›¾çš„å±•ç¤ºï¼Œé€‰ä¸­æŸä¸€ä¸ªç‚¹ä¹‹å æ²¡å¯¹æ¯”æ²¡ä¼¤å®³ï¼Œä¸ºä»€ä¹ˆD3ç”»çš„å›¾é¢œè‰²è¿™ä¹ˆå¥½çœ‹æ~]]></content>
      <categories>
        <category>å®éªŒé¡¹ç›®</category>
      </categories>
      <tags>
        <tag>å¯è§†åŒ–</tag>
        <tag>JavaScript</tag>
        <tag>D3.js</tag>
        <tag>Mathematica</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æµ‹è¯•Markdown]]></title>
    <url>%2F2018%2F07%2F30%2F%E6%B5%8B%E8%AF%95Markdown%2F</url>
    <content type="text"><![CDATA[é©¬å…‹é£è±¡æ˜¯ä¸€æ¬¾ä¸“ä¸ºå°è±¡ç¬”è®°ï¼ˆEvernoteï¼‰æ‰“é€ çš„Markdownç¼–è¾‘å™¨ï¼Œé€šè¿‡ç²¾å¿ƒçš„è®¾è®¡ä¸æŠ€æœ¯å®ç°ï¼Œé…åˆå°è±¡ç¬”è®°å¼ºå¤§çš„å­˜å‚¨å’ŒåŒæ­¥åŠŸèƒ½ï¼Œå¸¦æ¥å‰æ‰€æœªæœ‰çš„ä¹¦å†™ä½“éªŒã€‚ç‰¹ç‚¹æ¦‚è¿°ï¼š åŠŸèƒ½ä¸°å¯Œ ï¼šæ”¯æŒé«˜äº®ä»£ç å—ã€LaTeX å…¬å¼ã€æµç¨‹å›¾ï¼Œæœ¬åœ°å›¾ç‰‡ä»¥åŠé™„ä»¶ä¸Šä¼ ï¼Œç”šè‡³æˆªå›¾ç²˜è´´ï¼Œå·¥ä½œå­¦ä¹ å¥½å¸®æ‰‹ï¼› å¾—å¿ƒåº”æ‰‹ ï¼šç®€æ´é«˜æ•ˆçš„ç¼–è¾‘å™¨ï¼Œæä¾›æ¡Œé¢å®¢æˆ·ç«¯ä»¥åŠç¦»çº¿Chrome Appï¼Œæ”¯æŒç§»åŠ¨ç«¯ Webï¼› æ·±åº¦æ•´åˆ ï¼šæ”¯æŒé€‰æ‹©ç¬”è®°æœ¬å’Œæ·»åŠ æ ‡ç­¾ï¼Œæ”¯æŒä»å°è±¡ç¬”è®°è·³è½¬ç¼–è¾‘ï¼Œè½»æ¾ç®¡ç†ã€‚ Markdownç®€ä»‹ Markdown æ˜¯ä¸€ç§è½»é‡çº§æ ‡è®°è¯­è¨€ï¼Œå®ƒå…è®¸äººä»¬ä½¿ç”¨æ˜“è¯»æ˜“å†™çš„çº¯æ–‡æœ¬æ ¼å¼ç¼–å†™æ–‡æ¡£ï¼Œç„¶åè½¬æ¢æˆæ ¼å¼ä¸°å¯Œçš„HTMLé¡µé¢ã€‚ â€”â€” ç»´åŸºç™¾ç§‘ æ­£å¦‚æ‚¨åœ¨é˜…è¯»çš„è¿™ä»½æ–‡æ¡£ï¼Œå®ƒä½¿ç”¨ç®€å•çš„ç¬¦å·æ ‡è¯†ä¸åŒçš„æ ‡é¢˜ï¼Œå°†æŸäº›æ–‡å­—æ ‡è®°ä¸ºç²—ä½“æˆ–è€…æ–œä½“ï¼Œåˆ›å»ºä¸€ä¸ªé“¾æ¥æˆ–ä¸€ä¸ªè„šæ³¨[^demo]ã€‚ä¸‹é¢åˆ—ä¸¾äº†å‡ ä¸ªé«˜çº§åŠŸèƒ½ï¼Œæ›´å¤šè¯­æ³•è¯·æŒ‰Ctrl + /æŸ¥çœ‹å¸®åŠ©ã€‚ ä»£ç å—12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' LaTeX å…¬å¼å¯ä»¥åˆ›å»ºè¡Œå†…å…¬å¼ï¼Œä¾‹å¦‚ $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$ã€‚æˆ–è€…å—çº§å…¬å¼ï¼š $$ x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$ è¡¨æ ¼ Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 æµç¨‹å›¾12345678st=&gt;start: Starte=&gt;endop=&gt;operation: My Operationcond=&gt;condition: Yes or No?st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op ä»¥åŠæ—¶åºå›¾: 123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! æç¤ºï¼šæƒ³äº†è§£æ›´å¤šï¼Œè¯·æŸ¥çœ‹æµç¨‹å›¾è¯­æ³•ä»¥åŠæ—¶åºå›¾è¯­æ³•ã€‚ å¤é€‰æ¡†ä½¿ç”¨ - [ ] å’Œ - [x] è¯­æ³•å¯ä»¥åˆ›å»ºå¤é€‰æ¡†ï¼Œå®ç° todo-list ç­‰åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼š å·²å®Œæˆäº‹é¡¹ å¾…åŠäº‹é¡¹1 å¾…åŠäº‹é¡¹2 æ³¨æ„ï¼šç›®å‰æ”¯æŒå°šä¸å®Œå…¨ï¼Œåœ¨å°è±¡ç¬”è®°ä¸­å‹¾é€‰å¤é€‰æ¡†æ˜¯æ— æ•ˆã€ä¸èƒ½åŒæ­¥çš„ï¼Œæ‰€ä»¥å¿…é¡»åœ¨é©¬å…‹é£è±¡ä¸­ä¿®æ”¹ Markdown åŸæ–‡æ‰å¯ç”Ÿæ•ˆã€‚ä¸‹ä¸ªç‰ˆæœ¬å°†ä¼šå…¨é¢æ”¯æŒã€‚ å°è±¡ç¬”è®°ç›¸å…³ç¬”è®°æœ¬å’Œæ ‡ç­¾é©¬å…‹é£è±¡å¢åŠ äº†@(ç¬”è®°æœ¬)[æ ‡ç­¾A|æ ‡ç­¾B]è¯­æ³•, ä»¥é€‰æ‹©ç¬”è®°æœ¬å’Œæ·»åŠ æ ‡ç­¾ã€‚ ç»‘å®šè´¦å·åï¼Œ è¾“å…¥(è‡ªåŠ¨ä¼šå‡ºç°ç¬”è®°æœ¬åˆ—è¡¨ï¼Œè¯·ä»ä¸­é€‰æ‹©ã€‚ ç¬”è®°æ ‡é¢˜é©¬å…‹é£è±¡ä¼šè‡ªåŠ¨ä½¿ç”¨æ–‡æ¡£å†…å‡ºç°çš„ç¬¬ä¸€ä¸ªæ ‡é¢˜ä½œä¸ºç¬”è®°æ ‡é¢˜ã€‚ä¾‹å¦‚æœ¬æ–‡ï¼Œå°±æ˜¯ç¬¬ä¸€è¡Œçš„ æ¬¢è¿ä½¿ç”¨é©¬å…‹é£è±¡ã€‚ å¿«æ·ç¼–è¾‘ä¿å­˜åœ¨å°è±¡ç¬”è®°ä¸­çš„ç¬”è®°ï¼Œå³ä¸Šè§’ä¼šæœ‰ä¸€ä¸ªçº¢è‰²çš„ç¼–è¾‘æŒ‰é’®ï¼Œç‚¹å‡»åä¼šå›åˆ°é©¬å…‹é£è±¡ä¸­æ‰“å¼€å¹¶ç¼–è¾‘è¯¥ç¬”è®°ã€‚ æ³¨æ„ï¼šç›®å‰ç”¨æˆ·åœ¨å°è±¡ç¬”è®°ä¸­å•æ–¹é¢åšçš„ä»»ä½•ä¿®æ”¹ï¼Œé©¬å…‹é£è±¡æ˜¯æ— æ³•è‡ªåŠ¨æ„ŸçŸ¥å’Œæ›´æ–°çš„ã€‚æ‰€ä»¥è¯·åŠ¡å¿…å›åˆ°é©¬å…‹é£è±¡ç¼–è¾‘ã€‚ æ•°æ®åŒæ­¥é©¬å…‹é£è±¡é€šè¿‡å°†MarkdownåŸæ–‡ä»¥éšè—å†…å®¹ä¿å­˜åœ¨ç¬”è®°ä¸­çš„ç²¾å¦™è®¾è®¡ï¼Œå®ç°äº†å¯¹Markdownçš„å­˜å‚¨å’Œå†æ¬¡ç¼–è¾‘ã€‚æ—¢è§£å†³äº†å…¶ä»–äº§å“åªæ˜¯å•å‘å¯¼å‡ºHTMLçš„å•è–„ï¼Œåˆè§„é¿äº†æœåŠ¡ç«¯å­˜å‚¨Markdownå¸¦æ¥çš„éšç§å®‰å…¨é—®é¢˜ã€‚è¿™æ ·ï¼ŒæœåŠ¡ç«¯ä»…ä½œä¸ºå¯¹å°è±¡ç¬”è®° APIè°ƒç”¨å’Œæ•°æ®è½¬æ¢ä¹‹ç”¨ã€‚ éšç§å£°æ˜ï¼šç”¨æˆ·æ‰€æœ‰çš„ç¬”è®°æ•°æ®ï¼Œå‡ä¿å­˜åœ¨å°è±¡ç¬”è®°ä¸­ã€‚é©¬å…‹é£è±¡ä¸å­˜å‚¨ç”¨æˆ·çš„ä»»ä½•ç¬”è®°æ•°æ®ã€‚ ç¦»çº¿å­˜å‚¨é©¬å…‹é£è±¡ä½¿ç”¨æµè§ˆå™¨ç¦»çº¿å­˜å‚¨å°†å†…å®¹å®æ—¶ä¿å­˜åœ¨æœ¬åœ°ï¼Œä¸å¿…æ‹…å¿ƒç½‘ç»œæ–­æ‰æˆ–æµè§ˆå™¨å´©æºƒã€‚ä¸ºäº†èŠ‚çœç©ºé—´å’Œé¿å…å†²çªï¼Œå·²åŒæ­¥è‡³å°è±¡ç¬”è®°å¹¶ä¸”ä¸å†ä¿®æ”¹çš„ç¬”è®°å°†åˆ é™¤éƒ¨åˆ†æœ¬åœ°ç¼“å­˜ï¼Œä¸è¿‡ä¾ç„¶å¯ä»¥éšæ—¶é€šè¿‡æ–‡æ¡£ç®¡ç†æ‰“å¼€ã€‚ æ³¨æ„ï¼šè™½ç„¶æµè§ˆå™¨å­˜å‚¨å¤§éƒ¨åˆ†æ—¶å€™éƒ½æ¯”è¾ƒå¯é ï¼Œä½†å°è±¡ç¬”è®°ä½œä¸ºä¸“ä¸šäº‘å­˜å‚¨ï¼Œæ›´å€¼å¾—ä¿¡èµ–ã€‚ä»¥é˜²ä¸‡ä¸€ï¼Œè¯·åŠ¡å¿…ç»å¸¸åŠæ—¶åŒæ­¥åˆ°å°è±¡ç¬”è®°ã€‚ ç¼–è¾‘å™¨ç›¸å…³è®¾ç½®å³ä¾§ç³»ç»Ÿèœå•ï¼ˆå¿«æ·é”®Ctrl + Mï¼‰çš„è®¾ç½®ä¸­ï¼Œæä¾›äº†ç•Œé¢å­—ä½“ã€å­—å·ã€è‡ªå®šä¹‰CSSã€vim/emacs é”®ç›˜æ¨¡å¼ç­‰é«˜çº§é€‰é¡¹ã€‚ å¿«æ·é”®å¸®åŠ© Ctrl + /åŒæ­¥æ–‡æ¡£ Ctrl + Såˆ›å»ºæ–‡æ¡£ Ctrl + Alt + Næœ€å¤§åŒ–ç¼–è¾‘å™¨ Ctrl + Enteré¢„è§ˆæ–‡æ¡£ Ctrl + Alt + Enteræ–‡æ¡£ç®¡ç† Ctrl + Oç³»ç»Ÿèœå• Ctrl + M åŠ ç²— Ctrl + Bæ’å…¥å›¾ç‰‡ Ctrl + Gæ’å…¥é“¾æ¥ Ctrl + Læå‡æ ‡é¢˜ Ctrl + H å…³äºæ”¶è´¹é©¬å…‹é£è±¡ä¸ºæ–°ç”¨æˆ·æä¾› 10 å¤©çš„è¯•ç”¨æœŸï¼Œè¯•ç”¨æœŸè¿‡åéœ€è¦ç»­è´¹æ‰èƒ½ç»§ç»­ä½¿ç”¨ã€‚æœªè´­ä¹°æˆ–è€…æœªåŠæ—¶ç»­è´¹ï¼Œå°†ä¸èƒ½åŒæ­¥æ–°çš„ç¬”è®°ã€‚ä¹‹å‰ä¿å­˜è¿‡çš„ç¬”è®°ä¾ç„¶å¯ä»¥ç¼–è¾‘ã€‚ åé¦ˆä¸å»ºè®® å¾®åšï¼š@é©¬å…‹é£è±¡ï¼Œ@GGock é‚®ç®±ï¼š&#104;&#117;&#115;&#x74;&#x67;&#x6f;&#99;&#x6b;&#64;&#x67;&#x6d;&#97;&#x69;&#108;&#46;&#99;&#x6f;&#x6d; æ„Ÿè°¢é˜…è¯»è¿™ä»½å¸®åŠ©æ–‡æ¡£ã€‚è¯·ç‚¹å‡»å³ä¸Šè§’ï¼Œç»‘å®šå°è±¡ç¬”è®°è´¦å·ï¼Œå¼€å¯å…¨æ–°çš„è®°å½•ä¸åˆ†äº«ä½“éªŒå§ã€‚ [^demo]: è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹è„šæ³¨ã€‚è¯·æŸ¥é˜… MultiMarkdown æ–‡æ¡£ å…³äºè„šæ³¨çš„è¯´æ˜ã€‚ é™åˆ¶ï¼š å°è±¡ç¬”è®°çš„ç¬”è®°å†…å®¹ä½¿ç”¨ ENML æ ¼å¼ï¼ŒåŸºäº HTMLï¼Œä½†æ˜¯ä¸æ”¯æŒæŸäº›æ ‡ç­¾å’Œå±æ€§ï¼Œä¾‹å¦‚idï¼Œè¿™å°±å¯¼è‡´è„šæ³¨å’ŒTOCæ— æ³•æ­£å¸¸ç‚¹å‡»ã€‚]]></content>
      <categories>
        <category>åšå®¢</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[åšå®¢æ›´æ–°æ—¥å¿—]]></title>
    <url>%2F2018%2F07%2F30%2F%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[2018å¹´7æœˆ24æ—¥å‘¨äºŒæˆ‘å¼€å§‹ç€æ‰‹ç ”ç©¶åšå®¢ã€‚èµ·å› æ˜¯å› ä¸ºå°è±¡ç¬”è®°çš„æœ€é«˜çº§ä¼šå‘˜ä¸€ä¸ªç¬”è®°çš„å®¹é‡ä¹Ÿåªæœ‰200MBï¼Œå¯¹äºæ¸¸è®°é‡Œå–œæ¬¢æ”¾ç…§ç‰‡çš„æˆ‘æ¥è¯´å¤ªå°äº†ã€‚å› æ­¤å†³å®šä»ä½¿ç”¨äº†äº”å¹´çš„å°è±¡ç¬”è®°è¿ç§»è‡³æˆ‘ç°åœ¨è¿™ä¸ªåšå®¢ã€‚ æ›¾ç»æˆ‘å†™å°è±¡ç¬”è®°æ˜¯ç›´æ¥ä½¿ç”¨ï¼Œåæ¥ä½¿ç”¨StackExchangeè®ºå›å‘ç°äº†Markdownè¿™ç§å†™ä½œæ–¹å¼ï¼Œäºæ˜¯è´­ä¹°äº†å°è±¡ç¬”è®°æ’ä»¶â€œé©¬å…‹é£è±¡â€ï¼Œæ€»ä½“æ¥è¯´ä¸é”™ã€‚ å› æ­¤æ–°åšå®¢ç«™å®šå¾ˆé‡è¦çš„ä¸€ä¸ªåŠŸèƒ½å°±æ˜¯æ”¯æŒMarkdownã€‚ æœ€å…ˆæ³¨æ„åˆ°çš„æ¡†æ¶æ˜¯Hugo,å› ä¸ºè‡ªå·±å–œæ¬¢çš„ä¸€ä¸ªå¯è§†åŒ–è®¾è®¡å¸ˆNadieh Bremerçš„åšå®¢ä½¿ç”¨çš„å°±æ˜¯è¿™ä¸ªï¼Œæˆ‘éå¸¸å–œæ¬¢ç½‘ç«™çš„ä¸»é¢˜Victor Hugoã€‚æˆ‘åŒæ—¶äº†è§£åˆ°è¿™æ˜¯ä¸€ä¸ªé™æ€ç½‘ç«™ç”Ÿæˆå™¨ï¼Œä¼˜ç‚¹æ˜¯ç”Ÿæˆé€Ÿåº¦æ˜¯åŒç±»æ¡†æ¶ä¸­æœ€å¿«çš„ï¼Œå®‰è£…ä¹Ÿç®€å•ã€‚ä½†æ˜¯ä¸€å¼€å§‹æˆ‘å°±çŸ¥é“æˆ‘å¸Œæœ›è‡ªå·±çš„ç½‘ç«™å…·å¤‡ä»€ä¹ˆï¼Œæ¯”å¦‚æ—…è¡Œåšå®¢å¯ä»¥æ‹¥æœ‰èƒŒæ™¯éŸ³ä¹ï¼Œä½†æ˜¯æœç´¢äº†ä¸‹ï¼Œèµ„æ–™å¾ˆå°‘ã€‚jekyllå’ŒHexoå’ŒHugoéƒ½æ˜¯é™æ€ç½‘ç«™ç”Ÿæˆå™¨ï¼ŒHexoç”Ÿæˆé€Ÿåº¦ä»‹äºä¸‰è€…ä¹‹é—´ï¼Œè€Œä¸”ä¸­æ–‡æ–‡æ¡£ä¹Ÿå¾ˆä¸é”™ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯NodeJsæ‰€ä»¥æ‹“å±•æ€§æ˜¯ä¼˜äºHugoçš„ã€‚ æ‰€ä»¥é€‰æ‹©Hexoè¿™ä¸ªä½œä¸ºç½‘ç«™æ¡†æ¶ï¼Œä¸»é¢˜å…ˆæš‚æ—¶é…ç½®æˆä¸»æµé»‘ç™½é£æ ¼çš„Nextï¼Œä¸è¿‡æˆ‘è§‰å¾—è¿™ç§é£æ ¼å¤ªç¨‹åºå‘˜äº†ï¼Œä¹‹åä¼šæ¢æ‰ã€‚ï¼ˆæ›´æ¢ä¸»é¢˜åœ¨Hexoä¸­å¾ˆç®€å•ï¼‰ ä¸è‡ªå·±çš„Githubå…³è”å¹¶æ‰˜ç®¡è‡ªå·±çš„ç½‘ç«™å†…å®¹åœ¨ä¸Šé¢ï¼Œå¾ˆå¤šåšå®¢å·²æœ‰å™è¿°è¿™é‡Œä¸å¤šè¯´ã€‚è®¾ç½®Nextä¸»é¢˜ï¼Œè®¾ç½®æ ¹ç›®å½•ä¸‹_config.ymlçš„theme: next,è®¾ç½®ä¸»é¢˜ç›®å½•ä¸‹çš„_config.ymlçš„Schemeså­—æ®µæ›´æ¢é£æ ¼ æŒ‰ç…§èµ„æºæ–‡ä»¶å¤¹çš„è¯´æ³•ï¼Œæ‰“å¼€æ ¹ç›®å½•ä¸‹_config.ymlå†…çš„post_asset_folderå­—æ®µ,è¿™æ ·ä¸ç®¡æ˜¯å›¾ç‰‡è¿˜æ˜¯è‡ªå·±æœ¬åœ°çš„éŸ³ä¹éƒ½å¯ä»¥ç›´æ¥è¢«Markdownå¼•ç”¨ã€‚æ¯å½“dexo new &quot;testPost&quot;,source/_posts_ç›®å½•ä¸‹éƒ½ä¼šå‡ºç°testPostæ–‡ä»¶å¤¹ä»¥åŠtestPost.mdã€‚æ‰€ä»¥ç´ ææ”¾ç½®åœ¨testPostä¸­ å›¾ç‰‡ï¼š1&#123;% asset_img IMG_20180720_105107.jpg %&#125; æœ¬åœ°éŸ³ä¹ï¼š1&#123;% aplayer &quot;å•è½¦ç»ƒä¹ æ›²&quot; &quot;ç‹é›ç›Ÿ&quot; &quot;å•è½¦ç»ƒä¹ æ›².mp3&quot; &quot;å•è½¦ç»ƒä¹ æ›².jpg&quot; %&#125; ç½‘æ˜“äº‘éŸ³ä¹ï¼š123456&lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&amp;id=28582962&amp;auto=1&amp;height=66"&gt;&lt;/iframe&gt; å¯¹äºé‚£äº›æƒ³è¦æ›´æœ‰è§„å¾‹åœ°æä¾›å›¾ç‰‡å’Œå…¶ä»–èµ„æºä»¥åŠæƒ³è¦å°†ä»–ä»¬çš„èµ„æºåˆ†å¸ƒåœ¨å„ä¸ªæ–‡ç« ä¸Šçš„äººæ¥è¯´ï¼ŒHexoä¹Ÿæä¾›äº†æ›´ç»„ç»‡åŒ–çš„æ–¹å¼æ¥ç®¡ç†èµ„æºã€‚è¿™ä¸ªç¨å¾®æœ‰äº›å¤æ‚ä½†æ˜¯ç®¡ç†èµ„æºéå¸¸æ–¹ä¾¿çš„åŠŸèƒ½å¯ä»¥é€šè¿‡å°† config.yml æ–‡ä»¶ä¸­çš„ post_asset_folder é€‰é¡¹è®¾ä¸º true æ¥æ‰“å¼€ã€‚ è®¾ç½®æ ‡ç­¾ï¼Œåˆ†ç±»ä»¥åŠæ–‡ç« ç›®å½•ï¼ˆä¸è¦å®‰è£…hexo-tocæ’ä»¶ä¸ç„¶ç›®å½•ä¸èƒ½è·³è½¬ï¼‰è®¾ç½®å¦‚æˆ‘è¿™ç¯‡åšå®¢toc: trueä»£è¡¨æ‰“å¼€ç›®å½•&lt;!-- toc --&gt;è®¾ç½®ç›®å½•å‡ºç°çš„ä½ç½®comments: trueä»£è¡¨æ‰“å¼€è¯„è®ºï¼Œè¯„è®ºåŒºåŸŸï¼Œä½¿ç”¨éŸ©å›½â€œæ¥å¿…åŠ›â€è¯„è®ºç³»ç»Ÿï¼Œå¡«å†™ä¸»é¢˜ç›®å½•ä¸‹çš„_config.ymlçš„livere_uidå­—æ®µ 12345678910---title: åšå®¢æ›´æ–°æ—¥å¿—date: 2018-07-30 14:54:12tags: [åšå®¢,Hexo]comments: truetoc: truecategories: åšå®¢---&lt;!-- toc --&gt; 2018/7/30 å¢åŠ æœç´¢åŠŸèƒ½ã€‚ä¿®æ”¹ç«™ç‚¹é…ç½®æ–‡ä»¶_config.yml search:path: search.xmlfield: postformat: htmllimit: 10000 ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶/themes/nextä¸‹çš„_config.ymlçš„enableï¼Œè®¾ç½®ä¸ºtrue æœªæ¥å¯èƒ½ä¼šè®¾ç½®æ ‡ç­¾äº‘ä»¥åŠæ€ç»´å¯¼å›¾]]></content>
      <categories>
        <category>åšå®¢</category>
      </categories>
      <tags>
        <tag>åšå®¢</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ and VS]]></title>
    <url>%2F2018%2F07%2F29%2FC%2B%2B%20and%20VS%2F</url>
    <content type="text"><![CDATA[VSçŸ¥è¯†å¿«æ·é”®Ctrl-K + Ctrl-Cï¼š æ³¨é‡Šä¸€æ®µé€‰æ‹©ä»£ç Ctrl-K+ Ctrl-Uï¼š å–æ¶ˆä¸€æ®µé€‰æ‹©ä»£ç çš„æ³¨é‡Šæ ¼å¼åŒ–æ•´ç¯‡ä»£ç ï¼š Ctrl+Kï¼Œ D ä¸ºè§£å†³æ–¹æ¡ˆåˆ›å»ºç›®å½•åé‚£ä¹ˆæ ¹ç›®å½•åŒ…å« .sln .db gitæ–‡ä»¶å¤¹ solutionæ–‡ä»¶å¤¹: ä¸å·¥ç¨‹åŒå, æ”¾æºä»£ç . ä»¥åŠx64æ–‡ä»¶å¤¹ï¼Œç”¨äºæ”¾ç¼–è¯‘å‡ºæ¥çš„é¡¹ç›®. åœ¨solutionæ–‡ä»¶å¤¹ä¸­, æ¯”å¦‚é¡¹ç›®åæ˜¯test, é‚£ä¹ˆæºä»£ç å°±åœ¨./test/test/é‡Œé¢, ç¬¬ä¸€ä¸ªtestæŒ‡çš„æ˜¯è§£å†³æ–¹æ¡ˆç›®å½•, ç¬¬äºŒä¸ªå°±æ˜¯é¡¹ç›®å. åŒ…å« æ‰€æœ‰çš„æºä»£ç , .cppå’Œ.hç­‰ç­‰ .vcxproj .vcxproj.filters .vcxproj.user è¿™ä¹Ÿæ˜¯é»˜è®¤çš„è¾“å…¥è¾“å‡ºçš„æ ¹ç›®å½•ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœç¨‹åºä¸­æ‰“å¼€æˆ–æ–°å»ºä¸€ä¸ªæ–‡ä»¶ï¼Œåªç»™æ–‡ä»¶åçš„è¯ï¼Œå°±ä»è¿™ä¸ªç›®å½•æ‰“å¼€. ç–‘é—®ä¸ºä»€ä¹ˆé¡¹ç›®æ€»æ˜¯è®©æˆ‘ä»¬ç¼–è¯‘æŸ¥çœ‹å·¥å…·-&gt;é€‰é¡¹-&gt;é¡¹ç›®å’Œè§£å†³æ–¹æ¡ˆ-&gt;MSBuildé¡¹ç›®ç”Ÿæˆè¾“å‡ºè¯¦ç»†çº§åˆ«å†æŠŠ è§†å›¾-&gt;è¾“å‡º ä¸­çš„å†…å®¹å¤åˆ¶åˆ°txtä¸­ å¯»æ‰¾ç±»ä¼¼è¯­å¥â€œé¡¹ç›®ä¸æ˜¯æœ€æ–°çš„ï¼Œå› ä¸ºç¼ºå°‘â€¦â€ä¿®å¤åå¯¹è§£å†³æ–¹æ¡ˆæˆ–é¡¹ç›®é€‰æ‹©å…¨éƒ¨ç”Ÿæˆã€‚ä¹‹åè¿è¡Œå°±æ­£å¸¸äº† Note: ä¸æ˜¯â€œMSBuildé¡¹ç›®ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è¯¦ç»†çº§åˆ«â€ï¼Œé‚£ä¸ªå†…å®¹ä¸å¤Ÿä¸°å¯Œï¼Œä¼šé—æ¼ä¸€äº› ä¿®å¤åä¸æ˜¯ç«‹å³è¿è¡Œï¼Œè€Œæ˜¯å¯¹è§£å†³æ–¹æ¡ˆæˆ–é¡¹ç›®é€‰æ‹©å…¨éƒ¨ç”Ÿæˆ å¦‚ä½•åœ¨VSé‡Œæ·»åŠ å¤´æ–‡ä»¶åŒ…å«è·¯å¾„é¡¹ç›®-&gt;å±æ€§-&gt;C++-&gt;é™„åŠ åŒ…è·¯å¾„ C++çŸ¥è¯†çŸ¥è¯†æ³¨æ„äº‹é¡¹C++å†…éƒ¨å˜é‡è¿ç»­å­˜å‚¨ï¼Œæ„å‘³ç€å…ˆå®šä¹‰äº†aæ•°ç»„a[100]åå®šä¹‰äº†bï¼Œé‚£ä¹ˆå¦‚æœa[105]åŸå…ˆæ˜¯æœªå®šä¹‰çš„ ä½†æ˜¯å½“æŠŠbç½®0åï¼Œa[105]çš„å€¼ä¹Ÿä¼šè·Ÿç€æ”¹å˜ï¼Œå› ä¸ºa[105]åœ°å€å¯èƒ½å°±æ˜¯bçš„åœ°å€ æŒ‡é’ˆåˆå§‹åŒ–aæŒ‡å‘æ•´å‹æ•°ç»„int* a = new int[5]; åˆå§‹åŒ–aæŒ‡å‘5è¿™ä¸ªæ•´å‹int* a = new int(5); æ‹·è´æ‹·è´æ•°ç»„è‡³å¦ä¸€ä¸ªæ•°ç»„(æ•°ç»„å…ƒç´ ä¸ºNä¸ª)æ‹·è´æ•°ç»„aè‡³æ•°ç»„bï¼šmemcpy(b, a, sizeof(float)*N);æ‹·è´æ•°ç»„aè‡³å‘é‡bï¼šmemcpy(&amp;b[0], a, sizeof(float)*N);æ‹·è´å‘é‡aè‡³å‘é‡bï¼šmemcpy(&amp;b[0], &amp;a[0], sizeof(float)*N); ####æ‹·è´äºŒç»´æ•°ç»„çš„ä¸€éƒ¨åˆ†ï¼ˆNåˆ—ï¼‰è‡³å‘é‡bï¼ˆNä¸ªå…ƒç´ ï¼‰æ‹·è´äºŒç»´æ•°ç»„çš„ç¬¬ä¸€è¡Œè‡³å‘é‡bï¼šmemcpy(&amp;b[0], a, sizeof(float)*N);æ‹·è´äºŒç»´æ•°ç»„çš„ç¬¬äºŒè¡Œè‡³å‘é‡bï¼šmemcpy(&amp;b[0], a+1 sizeof(float)*N);æ‹·è´äºŒç»´æ•°ç»„çš„ç¬¬äºŒè¡Œç¬¬ä¸‰ä¸ªå…ƒç´ å¼€å§‹çš„Nä¸ªå…ƒç´ è‡³å‘é‡bï¼šmemcpy(&amp;b[0], *(a+1)+2,sizeof(float)*N);æˆ–è€…memcpy(&amp;b[0], &amp;a[1][2],sizeof(float)*N);å› ä¸º&amp;a[i]=a+iï¼Œ&amp;a[i][j]=*(a+i)+j,åœ¨æŒ‡å‘è¡Œçš„æŒ‡é’ˆå‰åŠ  * ,è½¬æ¢ä¸ºæŒ‡å‘åˆ—çš„æŒ‡é’ˆï¼›åœ¨æŒ‡å‘åˆ—çš„æŒ‡é’ˆå‰åŠ  &amp; ,è½¬æ¢ä¸ºæŒ‡å‘è¡Œçš„æŒ‡é’ˆï¼› æµ‹é‡æ—¶é—´123456#include "time.h"clock_t start, end;start = clock();//code hereend = clock();printf("Elapsed time:%f secs.\n", (double)(end - start) / CLOCKS_PER_SEC); å‡½æ•° sprintf 12int sprintf( char *buffer, const char *format, [ argument] â€¦ )//æŠŠæ ¼å¼åŒ–çš„æ•°æ®å†™å…¥æŸä¸ªå­—ç¬¦ä¸²ç¼“å†²åŒºbufferä¸­sprintf(szLstFile,"%s\\lists\\phoneme.lst",g_LibCfg.szPrjDir);//æŠŠ g_LibCfg.szPrjDir æŒ‰ç…§ "%s\\lists\\phoneme.lst"æ ¼å¼è½¬åŒ–ï¼Œå¹¶å­˜åœ¨ szLstFile ä¸­ sscanf 1int sscanf(const char *buffer,const char *format,[argument ]...); //sscanfä¼šä»bufferé‡Œè¯»è¿›æ•°æ®ï¼Œä¾ç…§formatçš„æ ¼å¼å°†æ•°æ®å†™å…¥åˆ°argumenté‡Œã€‚ fgets 1char *fgets(char *buf, int bufsize, FILE *stream);//ä»æ–‡ä»¶ç»“æ„ä½“æŒ‡é’ˆstreamä¸­è¯»å–æ•°æ®ï¼Œæ¯æ¬¡è¯»å–ä¸€è¡Œã€‚è¯»å–çš„æ•°æ®ä¿å­˜åœ¨bufæŒ‡å‘çš„å­—ç¬¦æ•°ç»„ä¸­ï¼Œæ¯æ¬¡æœ€å¤šè¯»å–bufsize-1ä¸ªå­—ç¬¦ï¼ˆç¬¬bufsizeä¸ªå­—ç¬¦èµ‹'\0'ï¼‰ fgetsè¿”å›å€¼ æˆåŠŸï¼Œåˆ™è¿”å›ç¬¬ä¸€ä¸ªå‚æ•°buf åœ¨è¯»å­—ç¬¦æ—¶é‡åˆ°end-of-fileï¼Œåˆ™eofæŒ‡ç¤ºå™¨è¢«è®¾ç½®ï¼Œå¦‚æœè¿˜æ²¡è¯»å…¥ä»»ä½•å­—ç¬¦å°±é‡åˆ°è¿™ç§æƒ…å†µï¼Œåˆ™bufä¿æŒåŸæ¥çš„å†…å®¹ï¼Œè¿”å›NULL å¦‚æœå‘ç”Ÿè¯»å…¥é”™è¯¯ï¼ŒerroræŒ‡ç¤ºå™¨è¢«è®¾ç½®ï¼Œè¿”å›NULLï¼Œbufçš„å€¼å¯èƒ½è¢«æ”¹å˜ fscanf 12int fscanf(FILE*stream, constchar*format, [argument...]); //å…¶åŠŸèƒ½ä¸ºæ ¹æ®æ•°æ®æ ¼å¼(format)ä»è¾“å…¥æµ(stream)ä¸­å†™å…¥æ•°æ®(argument)ï¼›ä¸fgetsçš„å·®åˆ«åœ¨äºï¼šfscanfé‡åˆ°ç©ºæ ¼å’Œæ¢è¡Œæ—¶ç»“æŸï¼Œæ³¨æ„ç©ºæ ¼æ—¶ä¹Ÿç»“æŸï¼Œfgetsé‡åˆ°ç©ºæ ¼ä¸ç»“æŸã€‚fscanf(fpPhone," %s %s",szTmpStr,szTmpStr);//åªä¼šå°†ç¬¬äºŒä¸ªå­—ç¬¦ä¸²èµ‹å€¼ç»™szTmpStr fread 1size_t fread ( void * ptr, size_t size, size_t count, FILE * stream );//ä»æ–‡ä»¶æµæŒ‡é’ˆstreamå¤„è¯»countä¸ªæ•°æ®ï¼Œæ¯ä¸ªæ•°æ®å¤§å°sizeä¸ªå­—èŠ‚ï¼Œæ”¾åˆ°pträ¸­å­˜å‚¨ã€‚ fwrite 1size_t fwrite ( const void * ptr, size_t size, size_t count, FILE * stream )//fwrite()ç”¨æ¥å°†æ•°æ®å†™å…¥æ–‡ä»¶æµä¸­,å°†ptræŒ‡å‘çš„æ•°æ®åœ°å€çš„å†…å®¹è¾“å‡ºè‡³streamæ–‡ä»¶æŒ‡é’ˆæŒ‡å‘çš„æ–‡ä»¶ memset 12void *memset(void *s, int ch, size_t n);//å‡½æ•°è§£é‡Šï¼šå°†sä¸­å½“å‰ä½ç½®åé¢çš„nä¸ªå­—èŠ‚ï¼ˆtypedef unsigned int size_t ï¼‰ç”¨ ch æ›¿æ¢å¹¶è¿”å› s//memsetï¼šä½œç”¨æ˜¯åœ¨ä¸€æ®µå†…å­˜å—ä¸­å¡«å……æŸä¸ªç»™å®šçš„å€¼ï¼Œå®ƒæ˜¯å¯¹è¾ƒå¤§çš„ç»“æ„ä½“æˆ–æ•°ç»„è¿›è¡Œæ¸…é›¶æ“ä½œçš„ä¸€ç§æœ€å¿«æ–¹æ³• strstr 1extern char *strstr(char *str1, const char *str2);//è¿”å›å€¼ï¼›è‹¥str2æ˜¯str1çš„å­ä¸²ï¼Œåˆ™è¿”å›str2åœ¨str1çš„é¦–æ¬¡å‡ºç°çš„åœ°å€ï¼›å¦‚æœstr2ä¸æ˜¯str1çš„å­ä¸²ï¼Œåˆ™è¿”å›NULLã€‚ strncpy 1char *strncpy(char *dest, const char *src, int n)//æŠŠsrcæ‰€æŒ‡å‘çš„å­—ç¬¦ä¸²ä¸­ä»¥srcåœ°å€å¼€å§‹çš„å‰nä¸ªå­—èŠ‚å¤åˆ¶åˆ°destæ‰€æŒ‡çš„æ•°ç»„ä¸­ï¼Œå¹¶è¿”å›destã€‚ strcpy 1char *strcpy(char *dest, const char *src);//strcpy()ä¼šå°†å‚æ•°src å­—ç¬¦ä¸²æ‹·è´è‡³å‚æ•°dest æ‰€æŒ‡çš„åœ°å€ã€‚ strcmp 1234extern int strcmp(const char *s1,const char *s2);//å½“s1&lt;s2æ—¶ï¼Œè¿”å›ä¸ºè´Ÿæ•°//å½“s1=s2æ—¶ï¼Œè¿”å›å€¼= 0//å½“s1&gt;s2æ—¶ï¼Œè¿”å›æ­£æ•° memcpy 1void * memcpy ( void * destination, const void * source, size_t num );//ä»sourceå¤„è¯»numä¸ªå­—èŠ‚æ”¾åˆ°destinationæŒ‡å‘çš„å†…å­˜ä¸­å»ã€‚ assertassertå®èƒ½æµ‹è¯•ä¼ å…¥è¡¨è¾¾å¼çš„çœŸå‡å€¼ï¼Œå½“è¡¨è¾¾å¼ä¸ºçœŸ(true)ï¼Œåˆ™ä¸ä¼šæœ‰ä»»ä½•ååº”ï¼›å½“è¡¨è¾¾å¼ä¸ºå‡(false)ï¼Œåˆ™å‡½æ•°å°†è¾“å‡ºé”™è¯¯ä¿¡æ¯ï¼Œå¹¶ä¸­æ–­ç¨‹åºçš„æ‰§è¡Œã€‚ ç–‘é—®å¦‚ä½•åœ¨sprintfå‡½æ•°ä¸­ä½¿ç”¨stringï¼Ÿsprintfæ˜¯C++ç»§æ‰¿è‡ªCè¯­è¨€çš„å‡½æ•°ï¼Œæ— æ³•ç›´æ¥æ”¯æŒstringç±»å‹ï¼Œæ‰€ä»¥è¦å…ˆæŠŠstringç±»å‹è½¬ä¸ºåŸºç¡€ç±»å‹ï¼Œä¹Ÿå°±æ˜¯char*ã€‚è¿™é‡Œéœ€è¦ä½¿ç”¨stringç±»çš„æˆå‘˜å‡½æ•°c_str();è¯¥æˆå‘˜å‡½æ•°åŠŸèƒ½ä¸ºï¼Œå°†stringçš„å†…å®¹è½¬ä¸ºCè¯­è¨€çš„å­—ç¬¦æ•°ç»„è¡¨è¾¾å½¢å¼ã€‚æ‰€ä»¥ç”¨sprintfå°†stringå¯¹è±¡strï¼Œè¾“å‡ºçš„char[]æ•°ç»„arrayä¸­çš„ä»£ç å¯ä»¥å†™ä½œï¼š sprintf(array, &quot;%s&quot;, str.c_str());é™¤æ­¤å¤–ï¼Œè¿˜å¯ä»¥ç”¨strcpyå‡½æ•°ï¼Œä½¿ä»£ç æ›´ç®€å•ï¼šstrcpy(array, str.c_str()); å®é™…ä¾‹å­å»ºç«‹äºŒç»´æ•°ç»„1234567891011//å¼€è¾Ÿå†…å­˜float **ppTrgAnswer_Data = new float*[nTrgPhoneNum];for (int i = 0; i &lt; nTrgPhoneNum; i++)&#123; ppTrgAnswer_Data[i] = new float[MAX_QUES_NUM]; memset(ppTrgAnswer_Data[i], 0, sizeof(float)*MAX_QUES_NUM);&#125;//é‡Šæ”¾å†…å­˜for (i = 0; i &lt; nTrgPhoneNum; i++) delete[] ppTrgAnswer_Data[i];delete[] ppTrgAnswer_Data;]]></content>
      <categories>
        <category>ç¼–ç¨‹</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Visual Studio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MXNet]]></title>
    <url>%2F2018%2F07%2F27%2FMXNet%2F</url>
    <content type="text"><![CDATA[MXNetç¯å¢ƒæŒ‡å— æ‰“å¼€mxnet source activate gluon # æ³¨æ„Windowsä¸‹ä¸éœ€è¦ sourceé€€å‡ºç¯å¢ƒ source deactivate GPUç‰ˆæœ¬è¿›å…¥ç¯å¢ƒåå¦‚æœç”¨æŒ‡å®šçš„å¡å¯ä»¥ CUDA_VISIBLE_DEVICES=2 pythonï¼Œè¿™æ ·æ•°æ®åªèƒ½åˆ†é…åœ¨ä¸€ä¸ªGPUä¸Š CUDA_VISIBLE_DEVICES=2 jupyter notebook ï¼Œè¿›å…¥jupyteråå†å¯¼å…¥mxnetï¼Œå¦‚æœä½¿ç”¨GPUè®­ç»ƒï¼Œä¹Ÿåªè®­ç»ƒåœ¨ä¸€å—å¡ä¸Š å‡çº§ pip install --pre mxnet-cu80 --upgradeæˆ–è€…pip install --pre mxnet --upgrade å¯ä»¥ä¸è®©MXNetå ç”¨è¿‡å¤šæ˜¾å­˜ï¼Œè®¾ç½®ä¿ç•™çš„ç™¾åˆ†æ•° export MXNET_GPU_MEM_POOL_RESERVE=5 å®‰è£…ä¾èµ–åº“ï¼šjupyterï¼Œmatplotlibï¼Œpandasï¼Œrequestsï¼Œmxnet MXNetå¦‚ä½•å¤„ç†è®­ç»ƒæ¨¡å¼å’Œæµ‹è¯•æ¨¡å¼Gluonï¼šè‹¥åœ¨é€šè¿‡ç½‘ç»œçš„ä»£ç met(â€¦)è¢«with autograd.record()åŒ…è£¹ï¼Œé‚£ä¹ˆè¿™æ—¶å€™GluonçŸ¥é“æ˜¯è®­ç»ƒæ¨¡å¼ã€‚å¦‚æœæ²¡æœ‰åˆ™æ˜¯æµ‹è¯•æ¨¡å¼ã€‚å¯ä»¥å‚è§åœ¨è®ºå›çš„å¸–å­å¾—åˆ°ä¸€äº›è¯æ˜MNNetï¼šé»˜è®¤æ˜¯è®­ç»ƒæ¨¡å¼ï¼Œæµ‹è¯•æ¨¡å¼éœ€è¦æŒ‡æ˜mod.forward(Batch([x]),is_train=False)C++ï¼šé»˜è®¤æ˜¯æµ‹è¯•æ¨¡å¼ MXNetè®­ç»ƒï¼ŒC++ä½¿ç”¨åŸºæœ¬æµç¨‹ åœ¨pythonä¸­è®­ç»ƒMXNetæ¨¡å‹ åœ¨pythonä¸­å¯¼å…¥æ¨¡å‹ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ åœ¨C++ä¸­å¯¼å…¥æ¨¡å‹ï¼ˆåœ¨å°ä¾‹å­ä¸Šè¿›è¡ŒéªŒè¯ä¸¤ä¸ªæ¥å£ç»“æœä¸€è‡´ï¼‰ åœ¨C++é¡¹ç›®ä¸­ä½¿ç”¨æ¨¡å‹ å·¥ç¨‹å°ä¾‹å­å±‚çš„ä½¿ç”¨RNNå¾ªç¯ç¥ç»ç½‘ç»œçš„ä½¿ç”¨12345678910layer = mx.gluon.rnn.RNN(100, 3)#åªçŸ¥é“æ¯ä¸ªtime-stepsçš„è¾“å‡ºç»´åº¦æ˜¯100ï¼Œæœ‰ä¸‰ä¸ªéšå±‚ï¼Œå…·ä½“å‡ ä¸ªtime-stepsæœªçŸ¥layer.initialize()input = mx.nd.random_uniform(shape=(6, 8, 10))# é»˜è®¤TNCæ¨¡å¼ï¼Œæ–¹ä¾¿å–åˆ°è·¨batchçš„æ•°æ®# ä»£è¡¨time-stepsæ˜¯6ï¼Œæ¯ä¸ªtime-stepså¯¹åº”çš„è¾“å…¥ç»´åº¦æ˜¯10ï¼Œbatch_sizeä¸º8# 6*10-&gt;6*100# by default zeros are used as begin stateoutput = layer(input)print output.shape Embeddingå±‚ æå–æƒé‡1net.weight.data().asnumpy() å…³äºæé«˜GPUåˆ©ç”¨ç‡å¯ä»¥å°è¯•å°†æ•°æ®å…¨éƒ¨æ”¾è¿›å†…å­˜ï¼Œå¦‚æœæ˜¯ä¸è§„åˆ™æ•°æ®é›†ï¼Œnumpyå¤„ç†ä¸äº†å¯ä»¥ç”¨pythonè‡ªå¸¦çš„æ•°ç»„å¤„ç† MXNetå¸¸ç”¨å‡½æ•°nd.concatenateï¼ˆè¢«å¼ƒç”¨,æ”¹ä¸ºnd.concatï¼‰123456789101112print img_list[0].shape #(1L, 3L, 64L, 64L) æ¯ä¸ªéƒ½æ˜¯è¿™æ ·çš„å½¢çŠ¶print len(img_list) #13233nd.concatenate(img_list).shape #(13233L, 3L, 64L, 64L)train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list),batch_size=64)train_data.reset()for batch in train_data: print batch break#è¾“å‡ºDataBatch: data shapes: [(64L, 3L, 64L, 64L)] label shapes: []#å³æ¯ä¸ªbatchæ˜¯64å¼ å›¾ nd.concatenate([history,temp],axis=1)æˆ–è€…nd.concat(history,temp,dim=1)å¯¹åº”F.concat(history, temp, dim=1) è®¡ç®—L2Loss123456789import mxnet as mxfrom mxnet import gluonimport numpy as nploss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,2,4))b=mx.nd.random.uniform(0, 10,shape=(3,2,4))print loss1(a,b)print np.mean(np.square((a[:,0,:]-b[:,0,:]).asnumpy()))/2print np.mean(np.square((a[:,1,:]-b[:,1,:]).asnumpy()))/2 sym.list_outputs()åˆ—å‡ºä¸€ä¸ªæ¨¡å‹è¾“å‡ºç«¯å£çš„åå­— sym.list_arguments()åˆ—å‡ºä¸€ä¸ªæ¨¡å‹çš„è¾“å…¥ç«¯å£çš„åå­—ä»¥åŠæƒé‡å’Œåç½®çš„åå­— sym.tojson()å¯ä»¥æ‰“å°å‡ºç½‘ç»œç»“æ„ mod.get_outputs()åˆ—å‡ºå‰é¦ˆçš„è¾“å‡º æ˜¾ç¤ºç½‘ç»œç»“æ„ viz.plot_networkç›´æ¥æ˜¾ç¤ºç½‘ç»œç»“æ„mx.viz.plot_network(symbol=sym) 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraphPlot"&#125;] 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraph"&#125;] mask-RNNé‡è¦çš„SequenceMaskå‡½æ•°ç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºè¿™ä¸ªmini-batchå†…å‡ ä¸ªæ ·æœ¬æ˜¯çœŸå®çš„ï¼Œè¿™é‡Œä»£è¡¨ä¸¤ä¸ªçœŸå®12345678910111213141516171819202122232425x = mx.nd.array([[[ 1., 2., 3.], [ 4., 5., 6.]], [[ 7., 8., 9.], [ 10., 11., 12.]], [[ 13., 14., 15.], [ 16., 17., 18.]]])#x.shape=(3L,2L,3L)res=mx.nd.SequenceMask(x,mx.nd.array([2,1]), use_sequence_length=True)print res#è¡¨æ˜ç¬¬ä¸€ä¸ªbatchä¿ç•™ä¸¤ä¸ªtime-stsepsï¼Œç¬¬äºŒä¸ªbatchä¿ç•™1ä¸ªtime-stsep# å¾—åˆ°# [[ 1. 2. 3.]# [ 4. 5. 6.]]# [[ 7. 8. 9.]# [ 0. 0. 0.]]# [[ 0. 0. 0.]# [ 0. 0. 0.]]]#è¿™æ ·çš„è¯ res[:,0,:]å–å‡ºçš„å°±æ˜¯ç¬¬ä¸€ä¸ªbatchåŠ äº†maskçš„ç»“æœ# [[ 1. 2. 3.]# [ 7. 8. 9.]# [ 0. 0. 0.]]# res[:,1,:]å–å‡ºçš„å°±æ˜¯ç¬¬2ä¸ªbatchåŠ äº†maskçš„ç»“æœ# [[ 4. 5. 6.]# [ 0. 0. 0.]# [ 0. 0. 0.]] é¦–å…ˆè§£å†³å¸¦maskçš„loss1234567891011121314151617import mxnet as mxa=mx.random.normal(0,1,shape=(50,128,43))b=mx.random.normal(0,1,shape=(50,128,43))mask=[49]*128 #å¦‚æœè¿™é‡Œæ˜¯[50]*128é‚£ä¹ˆè¿™ä¸¤ä¸ªlossçš„ç»“æœä¸€æ ·loss=mx.gluon.loss.L2Loss(batch_axis=1)print loss(a,b)def L2LossMask(a,b,mask): #ç±»ä¼¼äºgluon.loss.L2Loss(batch_axis=1)ï¼Œä½†æ˜¯å¯ä»¥ç”¨maskæ–¹å¼è®¡ç®— maskloss=[] maska=nd.SequenceMask(a, mask, use_sequence_length=True) maskb=nd.SequenceMask(b, mask, use_sequence_length=True) for i in range(a.shape[1]): maskloss.append(nd.sum((maska[:,i,:]-maskb[:,i,:])**2)/(2*mask[i]*a.shape[2])) return nd.concat(*maskloss,dim=0)print L2LossMask(a,b,mask) MXNeté«˜é˜¶åº”ç”¨åˆ©ç”¨HDF5æ–‡ä»¶åšè¿­ä»£å™¨ç”¨äºè®­ç»ƒ123456789101112131415161718192021222324252627282930313233343536import mxnet as mxfrom mxnet import nd,gluon,autogradfrom mxnet.gluon import nnimport h5pynet = nn.Sequential()with net.name_scope(): net.add(nn.Dense(32,in_units=2,activation="tanh")) net.add(nn.Dense(1))net.initialize()# load data from filewith h5py.File('test_data_SE.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] batch_size = 512 epochs=10 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'adam', &#123;'learning_rate': 0.3&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0]) loss = square_loss(output, batch.label[0]) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() print("Epoch %d, average loss: %f" % (epoch, total_loss/num_examples)) print(net(nd.array([[-1,-0.9]]))[0].asnumpy()) å•è¾“å…¥å•è¾“å‡ºSeq2Seqæ¨¡å‹Pythonä»£ç ï¼ˆHybridBlockç‰ˆæœ¬ï¼‰123456789101112131415161718192021222324252627282930313233import mxnet as mxfrom mxnet.gluon import nnprint("mxnet version: "+mx.__version__)mx.random.seed(1234) #Getting the same result everytimedef get_net(): # construct a MLP net = nn.HybridSequential() with net.name_scope(): net.add(nn.Dense(5, activation="relu")) net.add(nn.Dense(2)) # initialize the parameters net.collect_params().initialize() return net# forwardx = mx.nd.array([[0.1,0.2,0.3]])net = get_net()net.hybridize()print('=== net(x) ===&#123;&#125;'.format(net(x)))net.export('model')############## Re-importing the net ##############from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,3))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([[0.1,0.2,0.3]])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() C++å¯¼å…¥æ¨¡å‹å†é¢„æµ‹ ä»£ç 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include &lt;stdio.h&gt;// Path for c_predict_api#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./simple prediction model/model-symbol.json"; std::string param_file = "./simple prediction model/model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 1; // 1 for feedforward const char* input_key[1] = &#123; "data" &#125;; const char** input_keys = input_key; // input-dims int data_len = 3; const mx_uint input_shape_indptr[2] = &#123; 0, 2 &#125;; const mx_uint input_shape_data[2] = &#123; 1,static_cast&lt;mx_uint&gt;(data_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0==MXPredCreate((const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, &amp;pred_hnd)); assert(pred_hnd); std::vector&lt;mx_float&gt; vector_data = std::vector&lt;mx_float&gt;(data_len); mx_float* p = vector_data.data(); p[0] = .1; p[1] = .2; p[2] = .3; MXPredSetInput(pred_hnd, "data", vector_data.data(), data_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output_index = 0; mx_uint *shape = 0; //shapeç›¸å½“äº1*3çš„å‘é‡ mx_uint shape_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output_index, &amp;shape, &amp;shape_len); size_t size = 1; for (mx_uint i = 0; i &lt; shape_len; ++i) size *= shape[i]; std::vector&lt;float&gt; data(size); assert(0==MXPredGetOutput(pred_hnd, output_index, &amp;(data[0]), size)); // Release Predictor MXPredFree(pred_hnd); // Print Output Data PrintOutputResult(data); return 0;&#125; ç®€å•çš„å¤šè¾“å…¥å¤šè¾“å‡ºç½‘ç»œPythonä»£ç ï¼ˆæ™®é€šç‰ˆæœ¬ï¼‰1234567891011121314151617181920212223from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.Block): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def forward(self,x,y): result1 = nd.relu(self.dense0(x))+nd.relu(self.dense1(y)) result2 = nd.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1] Pythonä»£ç ï¼ˆHybridBlockç‰ˆæœ¬ï¼‰1234567891011121314151617181920212223242526272829303132333435from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.HybridBlock): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def hybrid_forward(self, F,x,y): result1 = F.relu(self.dense0(x))+F.relu(self.dense1(y)) result2 = F.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()net.hybridize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1]net.export('model')print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,3)),('data1',(1,5))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])mod.forward(Batch(data=[x,y]))print mod.get_outputs() C++å¯¼å…¥æ¨¡å‹å†é¢„æµ‹ ä»£ç 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./model-symbol.json"; std::string param_file = "./model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 2; mx_uint num_output_nodes = 2; const char* input_key[2] = &#123; "data0" , "data1" &#125;; const char** input_keys = input_key; //output_key name maybe should modify const char* output_key[2] = &#123; "hybridnet0__plus0" , "hybridnet0_relu2" &#125;; const char** output_keys = output_key; // input-dims int data0_len = 3; int data1_len = 5; const mx_uint input_shape_indptr[3] = &#123; 0,2,4 &#125;; const mx_uint input_shape_data[4] = &#123;1,static_cast&lt;mx_uint&gt;(data0_len),1,static_cast&lt;mx_uint&gt;(data1_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0 == MXPredCreatePartialOut( (const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, num_output_nodes, output_keys, &amp;pred_hnd)); assert(pred_hnd); //ERROR HERE std::vector&lt;mx_float&gt; vector_data0 = std::vector&lt;mx_float&gt;(data0_len); mx_float* p0 = vector_data0.data(); p0[0] = 1;p0[1] = 2;p0[2] = 5; MXPredSetInput(pred_hnd, "data0", vector_data0.data(), data0_len); std::vector&lt;mx_float&gt; vector_data1 = std::vector&lt;mx_float&gt;(data1_len); mx_float* p1 = vector_data1.data(); p1[0] = 5; p1[1] = 3; p1[2] = 1; p1[3] = 4; p1[4] = 5; MXPredSetInput(pred_hnd, "data1", vector_data1.data(), data1_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output0_index = 0; mx_uint *shape0 = 0; //shapeç›¸å½“äº1*3çš„å‘é‡ mx_uint shape0_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output0_index, &amp;shape0, &amp;shape0_len); size_t size0 = 1; for (mx_uint i = 0; i &lt; shape0_len; ++i) size0 *= shape0[i]; mx_uint output1_index = 1; mx_uint *shape1 = 0; //shapeç›¸å½“äº1*5çš„å‘é‡ mx_uint shape1_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output1_index, &amp;shape1, &amp;shape1_len); size_t size1 = 1; for (mx_uint i = 0; i &lt; shape1_len; ++i) size1 *= shape1[i]; std::vector&lt;float&gt; data0(size0); assert(0 == MXPredGetOutput(pred_hnd, output0_index, &amp;(data0[0]), size0)); std::vector&lt;float&gt; data1(size1); assert(0 == MXPredGetOutput(pred_hnd, output1_index, &amp;(data1[0]), size1)); // Print Output Data printf("output0:\n"); PrintOutputResult(data0); printf("output1:\n"); PrintOutputResult(data1); // Release Predictor MXPredFree(pred_hnd); return 0;&#125; è®­ç»ƒæ¨¡æ¿ç”¨ç›®æ ‡æ¨¡å‹ä¸¾ä¾‹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx = gpu()net = nn.HybridSequential()with net.name_scope(): net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(32))net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/TargetModel/validation_normalization_Target.h5', 'r')X_val_h5 = nd.array(val_file["Input"][:]).as_in_context(ctx)y_val_h5 = nd.array(val_file["Output"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/TargetModel/training_normalization_Target.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx)) loss = square_loss(output, batch.label[0].as_in_context(ctx)) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch%100==0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) val_loss = nd.mean(square_loss(net(X_val_h5), y_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('TargetModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") å¯¼å…¥æµ‹è¯•1234567891011import mxnet as mxfrom mxnet.gluon import nnfrom collections import namedtuplesym = mx.symbol.load('TargetModel-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,1+523))])mod.load_params('TargetModel-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([range(1+523)])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() ç”¨è¿æ¥æ¨¡å‹ä¸¾ä¾‹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx=gpu()class JoinModel(nn.HybridBlock): def __init__(self, **kwargs): super(JoinModel, self).__init__(**kwargs) self.encodeNet=nn.HybridSequential() self.decodeNet=nn.HybridSequential() self.fc=nn.HybridSequential() with self.name_scope(): self.encodeNet.add(nn.Dense(128,activation="relu")) self.encodeNet.add(nn.Dense(128)) self.decodeNet.add(nn.Dense(128,activation="relu")) self.decodeNet.add(nn.Dense(32)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(32)) def hybrid_forward(self,F,text,history): temp = self.encodeNet(text) result1 = self.decodeNet(temp) result2 = self.fc(F.concat(history, temp, dim=1)) return [result1,result2]net = JoinModel()net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/JoinModel/validation_normalization_Join.h5', 'r')text_val_h5 = nd.array(val_file["Input1"][:]).as_in_context(ctx)history_val_h5 = nd.array(val_file["Input2"][:]).as_in_context(ctx)UnitVec_val_h5 = nd.array(val_file["Output1"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/JoinModel/training_normalization_Join.h5', 'r') as h5file: text_h5 = h5file["Input1"] history_h5 = h5file["Input2"] UnitVec_h5 = h5file["Output1"] num_examples=text_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter([text_h5,history_h5], UnitVec_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx),batch.data[1].as_in_context(ctx)) loss1 = square_loss(output[0], batch.label[0].as_in_context(ctx)) loss2 = square_loss(output[1], batch.label[0].as_in_context(ctx)) loss = loss1+loss2 loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch % 100 == 0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) res = net(text_val_h5,history_val_h5) val_loss = nd.mean(square_loss(res[0],UnitVec_val_h5)+square_loss(res[1],UnitVec_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('JoinModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") å¯¼å…¥æµ‹è¯•12345678910111213141516import mxnet as mxfrom mxnet import ndimport numpy as np############## Re-importing the net ##############print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('JoinModel-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,524)),('data1',(1,128))])mod.load_params('JoinModel-0000.params')Batch=namedtuple('Batch',['data'])x = nd.random.normal(shape=(1,524))y = nd.random.normal(shape=(1,128))mod.forward(Batch(data=[x,y]),is_train=False)print mod.get_outputs()print sym.list_outputs() é…ç½®C++å¹³å° åœ¨C++/å¸¸è§„ä¸­æ·»åŠ â€œé™„åŠ åŒ…å«ç›®å½•â€ï¼Œå³å·¥ä½œç›®å½•ï¼Œæ–¹ä¾¿å®šä½c_predict_api.hçš„ä½ç½®ã€‚å¦‚æœèƒ½æˆåŠŸ#includeçš„è¯ï¼Œä¸è®¾ç½®ä¹Ÿè¡Œ åœ¨é“¾æ¥å™¨/è¾“å…¥ä¸­å¢åŠ â€œé™„åŠ ä¾èµ–é¡¹â€ï¼Œå³libmxnet.lib ä¿®æ”¹â€œæ´»åŠ¨è§£å†³æ–¹æ¡ˆå¹³å°â€ä¸ºx64 æ‹·è´libmxnet.dllå’Œlibmxnet.libå’Œc_predict_api.håˆ°å·¥ä½œç›®å½• cppæ–‡ä»¶åŠ å…¥#include &lt;c_predict_api.h&gt; C++ä½¿ç”¨æŒ‡å— å¯è¿è¡Œå•è¾“å…¥å•è¾“å‡º é»˜è®¤é‡‡ç”¨é¢„æµ‹æ–¹å¼ å¯è¿è¡Œå¤šè¾“å…¥å¤šè¾“å‡º é»˜è®¤é‡‡ç”¨é¢„æµ‹æ–¹å¼ å¯è¿è¡Œå¤šè¾“å…¥å¤šè¾“å‡ºï¼Œä½†æ˜¯åœ¨è¾“å‡ºç«¯å£å¯ä»¥åªè¾“å‡ºä¸€ä¸ªç«¯å£çš„æ•°æ® ä¿®æ”¹é¢„æµ‹æ”¯æŒä¸€ä¸ªmini-batchåªéœ€è¦ä¿®æ”¹input_shape_dataä¸­çš„batch_sizeï¼Œå¹¶ä¸”å°†ä¸€ä¸ªmini-batchçš„è¾“å…¥æ•°æ®å‹å¹³é€è¿›ç½‘ç»œã€‚åœ¨è®¾ç½®è¾“å…¥è¾“å‡ºç«¯å£çš„vectorçš„å¤§å°æ—¶å€™éƒ½è¦æŠŠå®ƒè®¾ç½®ä¸ºä¸€ä¸ªbatchæ•°æ®é•¿åº¦çš„batch_sizeå€ MXNetæºç é˜…è¯»io.pyä½äºE:\Anaconda\envs\gluon\Lib\site-packages\mxneté˜…è¯»å¦‚ä½•è‡ªå®šä¹‰è¿­ä»£å™¨]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Python</tag>
        <tag>MXNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mathematica]]></title>
    <url>%2F2018%2F07%2F27%2FMathematica%2F</url>
    <content type="text"><![CDATA[è®¾ç½®é—®é¢˜æ²¡æœ‰å›¾å½¢åŒ–ç•Œé¢çš„æœºå™¨å¯¼å‡ºå›¾åƒè®¡ç®—æœºæ˜¯LinuxæœåŠ¡å™¨, æ— å›¾å½¢åŒ–ç•Œé¢é“¾æ¥How to save Image or Graphics in Terminal? sudo apt-get install xvfb xvfb-run wolframæ­¤æ—¶è¿è¡Œè¿™ä¸ªä»£ç å°±æ­£å¸¸äº† 12p=Graphics@Circle[];Export["test.jpg",p]; çŠ¶æ€æ æ˜¾ç¤ºæ—¶é—´æ ¼å¼-&gt;é€‰é¡¹è®¾ç½®ï¼ˆå¿«æ·é”®Ctrl+Shift+Oï¼‰ï¼Œæ˜¾ç¤ºé€‰é¡¹å€¼é€‰æ‹©å…¨å±€åå¥½ï¼Œæœç´¢ EvaluationCompletionActionï¼Œå°†å…¶è®¾ç½®ä¸ºâ€œShowTimingâ€,ç¬”è®°æœ¬ä¸‹æ–¹çš„çŠ¶æ€æ å°±ä¼šæ˜¾ç¤ºæ¯æ¬¡è¿è¡Œä»£ç çš„æ¶ˆè€—æ—¶é—´äº†ã€‚ å½“ç”¨åˆ°GPUå¹¶ä¸”æ‰§è¡Œwolframscriptçš„è¯­æ³•æ˜¯ï¼šCUDA_VISIBLE_DEVICES=1 xvfb-run wolframscript -file test.wl åŸºç¡€çŸ¥è¯†åŸå­è¡¨è¾¾å¼ä¸èƒ½æ›¿æ¢å¤´éƒ¨å› ä¸º1æ˜¯åŸå­è¡¨è¾¾å¼ï¼Œæ‰€ä»¥fä¸èƒ½æ›¿æ¢æ‰å®ƒçš„å¤´éƒ¨1234Apply[f, &#123;&#123;g[1], g[a]&#125;, &#123;g[2], g[b]&#125;, &#123;g[3], g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;f[1], f[a]&#125;, &#123;f[2], f[b]&#125;, &#123;f[3], f[c]&#125;&#125; *)Apply[f, &#123;&#123;1, g[a]&#125;, &#123;2, g[b]&#125;, &#123;3, g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;1, f[a]&#125;, &#123;2, f[b]&#125;, &#123;3, f[c]&#125;&#125; *) å‡½æ•°å¼æŒ‡ä»¤Gatherå°†ç›¸åŒå…ƒç´ æ”¶é›†åœ¨ä¸€èµ·12345Gather[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First[#1] == First[#2] &amp;](*or*)GatherBy[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First](*&#123;&#123;&#123;a, 1&#125;, &#123;a, 2&#125;&#125;, &#123;&#123;b, 1&#125;, &#123;b, 3&#125;&#125;, &#123;&#123;d, 1&#125;&#125;&#125;*) è¡¨æ ¼æ’ç‰ˆ æ–°ç‰ˆå¯ä»¥ä¸ç”¨è®¾ç½®Partition,Gridç»„åˆèµ·æ¥ç”¨é‚£ä¹ˆéº»çƒ¦ï¼Œå› ä¸ºPartitionè¦è€ƒè™‘æ˜¯æ€ä¹ˆåˆ’åˆ†çš„Multicolumn[Range[50], 6] æ—§ç‰ˆGrid@Partition[Range[50], 6, 6, 1, &quot;&quot;] æ•°å­¦è¿ç®—æ±‚å‡ºæœ€å¤§/å°å…ƒç´ çš„ä½ç½®æ±‚å‡ºæœ€å°å…ƒç´ çš„ä½ç½®ç”¨Ordering[lis, 1];æ±‚å‡ºæœ€å¤§å…ƒç´ çš„ä½ç½®ç”¨Ordering[lis, -1] çŸ©é˜µé‡å¤å†æ‹¼æ¥ ç±»ä¼¼numpyçš„tailå‡½æ•°1ArrayFlatten[&#123;ReplicateLayer[4]@mat&#125;] // TraditionalForm æ•°å­¦è¯æ˜ æ–‡ä»¶ç®¡ç†åˆ—å‡ºæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶åˆ—å‡ºå½“å‰ç›®å½•å’Œå­ç›®å½•ä¸‹æ‰€æœ‰åç¼€ä¸ºnbçš„æ–‡ä»¶1FileNames["*.nb","*",Infinity] å¾—åˆ°BaseName12FileBaseName["C:\\Users\\xzhou\\Desktop\\test.gif"](*test*) ä¿å­˜mmaè¡¨è¾¾å¼123456FilePrint @ Export["test.wl", Solve[x^2 + a x + 1 == 0, x]](*Or*)file = "test.wl"If[FileExistsQ[#], DeleteFile[#]]&amp; @ file;FilePrint @ Save[file, Solve[x^2 + a x + 1 == 0, x]]; å¯è§†åŒ–CoordinateBoundingBoxArrayè¾“å…¥è¾¹ç•Œåæ ‡ï¼Œè‡ªåŠ¨å‡åŒ€å¡«å……è¾¹ç•Œå†…çš„ç‚¹åæ ‡12CoordinateBoundingBoxArray[&#123;&#123;3, -1&#125;, &#123;8, 2&#125;&#125;];Graphics[Point[Flatten[%, 1]], Frame -&gt; True] åœ¨MatrixPlotå’ŒGraphicsä¸­æ’å…¥æ–‡å­—è€ƒè™‘Epilogé€‰é¡¹å’ŒInsetå›¾å…ƒ è‡ªåŠ¨ç»™æ›²çº¿å›¾æ‰“æ ‡ç­¾1ListLinePlot[RandomReal[1, 26] -&gt; CharacterRange["a", "z"]] éŸ³é¢‘å‡½æ•°è¯­éŸ³åˆæˆSpeakå¯ä»¥è®©Mmaè¯´è¯ï¼ŒSpokenStringå¯ä»¥æ˜¾ç¤ºè¯´è¯çš„å†…å®¹ è®©Audioè‡ªåŠ¨æ’­æ”¾å£°éŸ³ï¼šæœ€åçš„å‚æ•°â€Playâ€å¯ä»¥æ¢æˆPause Stopä¹‹ç±»çš„12au = ExampleData[&#123;"Sound", "Violin"&#125;];Audio`Internals`Execute[ Audio`Internals`GetAudioManager[ Audio`AudioInformation[au, "AudioID"]], "Play"] å¾—åˆ°Audioæ–‡ä»¶æ­¤æ—¶çš„æ’­æ”¾ä½ç½®1id =Audio`AudioInformation[song, "AudioID"];mngr = Audio`Internals`GetAudioManager[id];Dynamic@Audio`AudioDump`getGUIInfo[mngr, "AudioPosition"] è®¡ç®—éŸ³é¢‘çš„èƒ½é‡123456a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "RMSAmplitude"](*å®é™…ä¸Šåº¦é‡çš„æ˜¯å‡æ–¹è¯¯å·®a // AudioData // #^2 &amp; // Mean // Sqrt*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Power"](*å®é™…ä¸Šåº¦é‡çš„æ˜¯ a // AudioData // #^2 &amp; // Mean*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Loudness"](*å®é™…ä¸Šåº¦é‡çš„æ˜¯ a // AudioData // #^2 &amp; // Mean // #^0.67 &amp;*) å¸¸ç”¨æ›¿æ¢Audio Sound1234(*Audio-&gt;Sound*)Audio@s(*Sound-&gt;Audio*)Sound[SampledSoundList[First@AudioData[#], QuantityMagnitude@AudioSampleRate@#]]@a List Association1234(*List-&gt;Association*)Association[&#123;1 -&gt; 2, 2 -&gt; 3&#125;](*Association-&gt;List*)Normal@&lt;|1 -&gt; 2, 2 -&gt; 3|&gt; æ›¿æ¢123456(*å‡½æ•°å¼ &#123;1-&gt;2,2-&gt;3&#125; -&gt; &#123;&#123;1,2&#125;,&#123;2,3&#125;&#125;*)List@@@&#123;1-&gt;2,2-&gt;3&#125;(*è§„åˆ™å¼ è°¢è°¢xzcyrå’ŒAlexander0620æä¾›çš„è§£æ³•*)&#123;1 -&gt; 2, 2 -&gt; 3&#125; /. Sequence[x_ -&gt; y_] -&gt; &#123;x, y&#125;(*æˆ–è€…*)&#123;1 -&gt; 2, 2 -&gt; 3&#125; /. Rule -&gt; List Datasetæ·±å…¥ã€é€€å‡ºè¿ç®—ç¬¦å€¼å¾—æ³¨æ„çš„æ˜¯TakeLargestByæ˜¯æ·±å…¥è¿ç®—ç¬¦ï¼ŒTakeLargestæ˜¯é€€å‡ºè¿ç®—ç¬¦ã€‚ åœ¨åé¢çš„è¿ç®—ç¬¦åº”ç”¨åˆ°æ›´æ·±ä¸€å±‚ä¹‹å‰ï¼Œâ€œæ·±å…¥â€è¿ç®—ç¬¦è¢«åº”ç”¨åˆ°åŸå§‹æ•°æ®é›†ç›¸åº”çš„éƒ¨åˆ†. æ·±å…¥è¿ç®—ç¬¦çš„ç‰¹ç‚¹æ˜¯åœ¨ä½œç”¨äºæŸä¸€å±‚æ—¶ï¼Œå®ƒä»¬ä¸ä¼šæ”¹å˜æ•°æ®æ›´æ·±å±‚æ¬¡çš„ç»“æ„. è¿™ç¡®ä¿åé¢çš„è¿ç®—ç¬¦æ“ä½œæ—¶ï¼Œå­è¡¨è¾¾å¼çš„ç»“æ„å’ŒåŸå§‹æ•°æ®é›†çš„ç›¸åº”å±‚æ¬¡æ˜¯ä¸€æ ·çš„. æœ€ç®€å•çš„æ·±å…¥è¿ç®—ç¬¦æ˜¯ Allï¼Œå®ƒé€‰å–æŸä¸ªç»™å®šå±‚çš„æ‰€æœ‰éƒ¨åˆ†ï¼Œå› æ­¤ä¸ä¼šæ”¹å˜è¯¥å±‚æ•°æ®çš„ç»“æ„ åœ¨æ‰€æœ‰éšåçš„è¿ç®—ç¬¦å®Œæˆå¯¹æ·±å±‚æ•°æ®çš„æ“ä½œåï¼Œâ€œé€€å‡ºâ€è¿ç®—ç¬¦è¢«åº”ç”¨.å› æ­¤dataset[f,g]æ˜¯Query[f, g] // Normal,ä¹Ÿå°±æ˜¯Map[g] /* f .æ·±å…¥è¿ç®—ç¬¦å¯¹åº”äºåŸå§‹æ•°æ®çš„å±‚ï¼Œè€Œé€€å‡ºè¿ç®—ç¬¦å¯¹åº”äºç»“æœçš„å±‚. å’Œæ·±å…¥è¿ç®—ç¬¦ä¸åŒï¼Œé€€å‡ºè¿ç®—ç¬¦ä¸å¿…ä¿æŒæ‰€æ“ä½œæ•°æ®çš„ç»“æ„. å¦‚æœä¸€ä¸ªè¿ç®—ç¬¦æ²¡æœ‰è¢«æ˜ç¡®æŒ‡å®šä¸ºæ·±å…¥è¿ç®—ç¬¦ï¼Œå‡å®šå…¶ä¸ºé€€å‡ºè¿ç®—ç¬¦ data[SortBy[#x - #y &amp;], Total, #^2 &amp;]æ˜¯æ·±å…¥ã€é€€å‡º1ã€é€€å‡º2è¿ç®—ç¬¦ï¼Œå› æ­¤å…ˆåº”ç”¨æ·±å…¥è¿ç®—ç¬¦ï¼Œå†åº”ç”¨#^2 &amp;ï¼Œå†åº”ç”¨Total æ•°æ®åˆ†ææˆ–å¤„ç†åˆ©ç”¨SQLè¯­æ³•æŸ¥è¯¢æ•°æ®sales = SemanticImport[&quot;ExampleData/RetailSales.tsv&quot;]sales[All, &quot;Sales&quot;]å¾—åˆ°Salesåˆ—çš„æ‰€æœ‰æ•°æ®å› ä¸ºAllæ˜¯æ·±å…¥è¿ç®—ç¬¦ï¼Œå¯ä»¥å®‰å…¨çš„æ›´æ¢ä¸ºå…¶ä»–æ·±å…¥è¿ç®—ç¬¦ï¼Œå¦‚sales[Mean, &quot;Sales&quot;] // Nè¿™æ—¶å€™å¦‚æœæƒ³å†é’ˆå¯¹æœˆä»½å’Œæ˜ŸæœŸå‡ æ’åºå¯ä»¥è¿™æ ·ï¼š12sales[GroupBy[DateValue[#Date, "Month"] &amp;], GroupBy[DateValue[#Date, "DayName"] &amp;], Mean, "Sales"] èšç±» ClusteringComponentsçš„ç¬¬äºŒä¸ªå‚æ•°æ„æ€æ˜¯èšç±»ä¸ªæ•°ä¸º3ç±»ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°å°†ç¬¬ä¸€å±‚æ•°æ®è§†ä¸ºä¸€ä¸ªæ ·æœ¬ å½’ä¸€åŒ–æ•°æ®å¯¹æ•°æ®ï¼ˆçŸ©é˜µï¼‰åšå½’ä¸€åŒ–ï¼Œæ•°æ®æ¯è¡Œæ˜¯ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªç‰¹å¾å‡å€¼æ–‡ä»¶å­˜å‚¨çš„ä¹Ÿæ˜¯çŸ©é˜µã€‚ç¬¬ä¸€è¡Œæ˜¯æœ€å°å€¼ï¼Œç¬¬äºŒè¡Œæ˜¯æœ€å¤§å€¼è‹¥åªå¯¹çŸ©é˜µç¬¬ä¸€ç»´å½’ä¸€åŒ–1data1[[All, 1]] = (data1[[All, 1]] - meanInput[[1, 1]])/(meanInput[[2, 1]] - meanInput[[1, 1]]); è‹¥å¯¹çŸ©é˜µçš„æ¯ä¸€ç»´åšå½’ä¸€åŒ–1mat = (# - meanOutput[[1]])/meanOutput[[2]] &amp; /@ mat; å®ç”¨å°åŠŸèƒ½ç¾åŒ–è¾“å‡ºGeneralUtilities`PrettyFormå¯ä»¥ç¾åŒ–è¾“å‡º å¯¼å‡ºçŸ¢é‡å›¾SVGå’Œwmfæ–‡ä»¶å¯ä»¥è¾“å‡ºçŸ¢é‡å›¾ï¼Œwmfé€‚åˆvisio å°†PDFä¸­çš„æ®µè½å˜æˆä¸€è¡Œï¼Œæ–¹ä¾¿è°·æ­Œç¿»è¯‘ä½¿ç”¨å…ˆå¤åˆ¶æ®µè½å†ç²˜è´´è¿›mmaæ‰§è¡Œä»¥ä¸‹ä»£ç 1StringDelete[text, "\n"] // CopyToClipboard å½“ç„¶CopyToClipboardå¯ä»¥ç›´æ¥æ‹·è´æ•°æ®è‡³å‰ªè´´æ¿ï¼Œä¹Ÿå¯¹å¤åˆ¶å›¾ç‰‡æ˜¯æå¥½çš„ å¯¼å‡ºæ•°å­¦å…¬å¼è‡³Stack Exchangeä¾‹å¦‚http://math.stackexchange.comå…¬å¼é€‰æ‹©å¤åˆ¶ä¸ºLatexæ ¼å¼ ç„¶ååœ¨å‰ååŠ ä¸Š$å°±è¡Œäº†1$c=\sqrt&#123;a^2-2 a b \cos (\theta )+b^2&#125;$ å¯¼å‡ºå«æœ‰Alphaé€šé“çš„å›¾ç‰‡12img//Binarize//ColorReplace[#,Black-&gt;Red]&amp;Export["img.gif",%,"TranspararentColor"-&gt;White] å¯¼å…¥å¯¼å‡ºå¯¼å…¥å¯¼å…¥lstæ–‡ä»¶ï¼ˆæ¯è¡Œå‡ä¸ºæ•°å­—æ„æˆï¼‰Import[filename,&quot;List&quot;]å¯¼å…¥lstæ–‡ä»¶ï¼ˆæ¯è¡Œå‡ä¸ºå­—ç¬¦ä¸²æ„æˆï¼‰Import[filename,&quot;Lines&quot;]å¯¼å…¥çº¯æ–‡æœ¬æ„æˆçš„çŸ©é˜µ Import[filename,&quot;Table&quot;]å¯¼å…¥æµ®ç‚¹æ•°äºŒè¿›åˆ¶æ–‡ä»¶ BinaryReadList[filename,&quot;Real32&quot;] å¦‚æœä¸€äº›tsvæ–‡ä»¶å¯¼å…¥ä¹±ç æ¯”å¦‚ä½¿ç”¨Import[filename,&quot;Table&quot;å¯ä»¥å°è¯•123Import[&quot;/Users/xzhou/python/nvshens/Girls.lst&quot;, &quot;TSV&quot;](*Or*)StringSplit[StringSplit[#, &quot;\n&quot;], &quot;\t&quot;] &amp; @ Import[filename,&quot;Text&quot;,Character-&gt;&quot;UTF8&quot;] æ–‡ä»¶æµæ§åˆ¶ä»¥äºŒè¿›åˆ¶æ–‡ä»¶å½¢å¼å¯¼å…¥Importä¸ä¼šå¼•å…¥æ–°çš„æµï¼Œç®€å•ä½†æ˜¯çµæ´»æ€§ä½12Import["test.exe", "Byte"] // LengthStreams[] // Length (*2ï¼Œè¯æ˜åªæœ‰è¾“å‡ºæµstdoutå’Œé”™è¯¯æµstderr*) OpenRead å¦‚æœç”¨å®Œå…³é—­æµä¹Ÿä¸ä¼šå¼•å…¥æ–°çš„æµï¼Œç¨å¤æ‚ä½†æ˜¯çµæ´»æ€§é«˜1234567file = OpenRead["test.exe", BinaryFormat -&gt; True];Length@Reap[ While[(tempRecord = BinaryRead[file]) =!= EndOfFile, Sow@tempRecord]][[2, 1]]Close[file];Streams[] // Length (*2ï¼Œè¯æ˜åªæœ‰è¾“å‡ºæµstdoutå’Œé”™è¯¯æµstderr*) ä¸ç®¡æ˜¯BinaryReadListè¿˜æ˜¯BinaryReadéƒ½ä¼šæ”¹å˜æµæŒ‡é’ˆçš„ä½ç½®ï¼š Mathemticaå‘æ–‡ä»¶è¿½åŠ äºŒè¿›åˆ¶æ•°æ®123456file = "test.dat";str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[12], "Real32"];BinaryWrite[str, Range[15,30], "Real32"];Close[str]; BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30} ç»§ç»­è¿½åŠ 12345str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[5], "Real32"];BinaryWrite[str, Range[10, 15], "Real32"];Close[str];BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 10, 11, 12, 13, \14, 15} ä¸å¯¼å‡ºä¹ŸæŸ¥çœ‹å¯¼å‡ºçš„æ•ˆæœæ¯”å¦‚ExportString[{1, {1, 2, 3}}, &quot;Table&quot;]è¾“å‡ºçš„æ•ˆæœå°±æ˜¯Export[&quot;test.txt&quot;,{1, {1, 2, 3}}, &quot;Table&quot;]æ‰“å¼€åçš„æ•ˆæœ å•å…ƒ ç¬”è®°æœ¬åœ¨å•å…ƒä¸­å¯ç”¨åŠ¨æ€1TextCell[Dynamic[ Refresh[DateString[], UpdateInterval -&gt; 1]], "Subsection"] æ—¶åºæ•°æ®TimeSeriesçš„å¤´éƒ¨ä¾ç„¶æ˜¯TemporalData1234v = &#123;2, 1, 6, 5, 7, 4&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; ts = TimeSeries[v, &#123;t&#125;]Head[ts](* TemporalData *) ä¸¤æ¡è·¯å¾„ä½¿ç”¨ TemporalDataè€Œä¸æ˜¯TimeSeries1234s1 = &#123;2, 1, 6, 5, 7, 4&#125;; s2 = &#123;4, 7, 5, 6, 1, 2&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; td = TemporalData[&#123;s1, s2&#125;, &#123;t&#125;] Differenceså’ŒAccumulateå¯ä»¥ç”¨äº TemporalDataï¼Œä½†æ˜¯è¦æ³¨æ„é‡‡æ ·æ˜¯å¦å‡åŒ€çš„é—®é¢˜]]></content>
      <categories>
        <category>ç¼–ç¨‹</category>
      </categories>
      <tags>
        <tag>Mathematica</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow]]></title>
    <url>%2F2018%2F07%2F26%2FTensorflow%2F</url>
    <content type="text"><![CDATA[Kerasä¸Tensorflowè”åŠ¨123456789101112131415161718192021222324252627282930313233343536import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist_data = input_data.read_data_sets('MNIST_data/', one_hot=True)# Building modelimg = tf.placeholder(tf.float32, shape=(None, 784))labels = tf.placeholder(tf.float32, shape=(None, 10))x = tf.keras.layers.Dense(128, activation='relu')(img)x = tf.keras.layers.Dense(128, activation='relu')(x)prediction = tf.keras.layers.Dense(10)(x)loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))train_optim = tf.train.AdamOptimizer().minimize(loss)#Print model name and shapefor i in tf.trainable_variables(): print '&#123;&#125;\t&#123;&#125;\t&#123;&#125;'.format(i.name,i.shape,i.dtype)#dense/kernel:0 (784, 128) &lt;dtype: 'float32_ref'&gt;#dense/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_1/kernel:0 (128, 128) &lt;dtype: 'float32_ref'&gt;#dense_1/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_2/kernel:0 (128, 10) &lt;dtype: 'float32_ref'&gt;#dense_2/bias:0 (10,) &lt;dtype: 'float32_ref'&gt;# Train modelwith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for _ in range(1000): batch_x, batch_y = mnist_data.train.next_batch(50) sess.run(train_optim, feed_dict=&#123;img: batch_x, labels: batch_y&#125;) acc_pred = tf.keras.metrics.categorical_accuracy(labels, prediction) pred = sess.run(acc_pred, feed_dict=&#123;labels: mnist_data.test.labels, img: mnist_data.test.images&#125;) print('accuracy: %.3f' % (sum(pred)/len(mnist_data.test.labels))) Tensorflowå¦‚ä½•å¤„ç†è®­ç»ƒæ¨¡å¼ã€æµ‹è¯•æ¨¡å¼DropOutå±‚å’ŒBNå±‚éƒ½æœ‰è®­ç»ƒæ¨¡å¼ã€æµ‹è¯•æ¨¡å¼ã€‚DropOutå±‚ï¼šè®¾ç«‹ä¸€ä¸ªplaceholderï¼Œè®¾ç½®è®­ç»ƒæ—¶ä¸€ä¸ªæ•°ï¼Œæµ‹è¯•æ—¶è®¾ç½®ä¸º0phase = tf.placeholder(tf.bool, name=&#39;phase&#39;)BNå±‚ï¼š Boardcastingæœºåˆ¶å¯ä»¥çœ‹åˆ°bçš„ç»´åº¦ç«Ÿç„¶å’Œaçš„æœ€åä¸€ç»´ä¸€è‡´å› ä¸ºtf.nn.conv2dåªè®¡ç®—å·ç§¯çš„éƒ¨åˆ†ï¼Œä¸è‡ªåŠ¨æ·»åŠ biasåç½®ã€‚æ‰€ä»¥è¦è¿™æ ·tf.nn.relu(tf.nn.conv2d(x,w)+bias)ï¼Œå…¶ä¸­biasçš„åŠ æ³•éœ€è¦ä½¿ç”¨boardcasting 123456import tensorflow as tfa=tf.constant(1,shape=[2,3,5])b=tf.constant(range(5))with tf.Session() as sess: tf.global_variables_initializer().run() print sess.run(a+b) [[[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]] [[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]]] æ¨¡å‹ç›¸å…³è½½å…¥æ¨¡å‹1234trainable = tf.trainable_variables()optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt') è½½å…¥å¤šæ¨¡å‹ äº¤æ›¿å¾ªç¯ä¸åŒéƒ¨åˆ†123456789101112131415161718192021222324trainable = tf.trainable_variables()trainable_DNN = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"DNN_part")trainable_WaveNet = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"wavenet_part")optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)optim_DNN = optimizer.minimize(loss, global_step=global_step, var_list=trainable_DNN)optim_WaveNet = optimizer.minimize(loss, global_step=global_step, var_list=trainable_WaveNet)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt')DNN_saver = tf.train.Saver(trainable_DNN)DNN_saver .restore(sess, './logdir/DNN_part/Unit2Vec.ckpt')WaveNet_saver = tf.train.Saver(trainable_WaveNet)WaveNet_saver.restore(sess, './logdir/WaveNet_part/Unit2Vec.ckpt')#part 1-&gt;3-&gt;2-&gt;3-&gt;2-&gt;3...if step &lt; 10: #turn round every 10 steps #part 1 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim])elif int(step/10) % 2 == 0: #part 2 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_WaveNet])elif int(step/10) % 2 == 1: #part 3 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_DNN])else: raise ValueError(x) é˜Ÿåˆ—æœºåˆ¶å…¥é˜Ÿçš„æ–¹å¼æœ‰ä¸¤ç§ï¼Œenqueueå’Œenqueue_manyã€‚ä¸€èˆ¬é‡‡å–ç¬¬ä¸€ç§å‡ºé˜Ÿçš„æ–¹å¼æœ‰ä¸¤ç§ï¼Œdequeueå’Œdequeue_manyã€‚ä¸€èˆ¬é‡‡å–ç¬¬äºŒç§ï¼Œè¿™ç›¸å½“äºdequeueå‡ºæ¥çš„æ•°æ®æ˜¯ä¸€ä¸ªbatch RandomShuffleQueueåˆ›å»ºä¸€ä¸ªéšæœºé˜Ÿåˆ—ï¼Œè¡¨ç¤ºå‡ºé˜Ÿçš„æ˜¯éšæœºçš„ï¼Œä½†æ˜¯å½“ä½¿ç”¨RandomShuffleQueueæ—¶å¦‚æœshapeä¸æ˜ç¡®æŒ‡å®šå…·ä½“å¤§å°ï¼Œdequeue_manyæ˜¯ç¦ç”¨çš„ã€‚ enqueueè¿™é‡Œé¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª10ä¸ªç®±å­ï¼ˆæ¯ä¸ªç®±å­å¯ä»¥æ”¾ä¸¤ä¸ªç‰©å“ï¼Œç¬¬ä¸€ç§ç‰©å“æ˜¯52çš„çŸ©é˜µï¼Œç¬¬äºŒç§æ˜¯53çš„çŸ©é˜µï¼‰çš„é˜Ÿåˆ—ï¼Œè¦æ±‚min_after_dequeueä¸º7ä¸ªç®±å­ï¼Œä¹Ÿå°±æ˜¯æœ€å¤šåªå¯ä»¥dequeå‡ºä¸‰ä¸ªç®±å­ã€‚å¾ªç¯ä¸­å…¥é˜Ÿäº†åæ¬¡ï¼Œä½¿å¾—é˜Ÿåˆ—ä¸ºæ»¡ç®±çŠ¶æ€ï¼Œæ‰€ä»¥dequeue_many(3)åˆšå¥½ä¸é˜»å¡ã€‚ 12345678910111213141516171819import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=7, dtypes=[tf.int32, tf.int32], shapes=[(5,2),(5,3)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[5,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[5,3])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data1 = np.arange(i,i+10).reshape(-1,2) data2 = np.arange(i,i+15).reshape(-1,3) sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) [array([[[ 3, 4], [ 5, 6],[ 7, 8], [ 9, 10], [11, 12]], [[ 9, 10],[11, 12],[13, 14], [15, 16], [17, 18]], [[ 5, 6],[ 7, 8], [ 9, 10], [11, 12], [13, 14]]], dtype=int32), array([[[ 3, 4, 5],[ 6, 7, 8],[ 9, 10, 11],[12, 13, 14],[15, 16, 17]], [[ 9, 10, 11],[12, 13, 14],[15, 16, 17],[18, 19, 20],[21, 22, 23]], [[ 5, 6, 7],[ 8, 9, 10],[11, 12, 13],[14, 15, 16],[17, 18, 19]]], dtype=int32)] å¯ä»¥çœ‹åˆ°è¿”å›ä¸¤ç§ç®±å­ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šå°†è¿™ä¸ªè¿”å›å€¼èµ‹å€¼ç»™tuples,æ¯”å¦‚æŠŠä»£ç æœ€åä¸€å¥æ”¹ä¸º(col2,col3) = sess.run(dequeue)ã€‚è¿™æ ·col2å’Œcol3å°±å¯ä»¥ä½œä¸ºæ•°æ®ä¾›ç»™ç½‘ç»œä½¿ç”¨ enqueue_manyè¿™é‡Œé¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª10ä¸ªç®±å­ï¼ˆæ¯ä¸ªç®±å­æ”¾ä¸¤ç§ç‰©å“ï¼Œç¬¬ä¸€ä¸ªç‰©å“æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º2çš„æ•°ç»„ï¼Œç¬¬äºŒä¸ªç‰©å“æ˜¯é•¿åº¦ä¸º3çš„æ•°ç»„ï¼‰çš„éšæœºé˜Ÿåˆ—ã€‚ä½¿ç”¨enqueue_manyç›¸å½“äºä¸€æ¬¡æ€§å¡«å……å¤šä¸ªç®±å­ã€‚ç°åœ¨ä¸€æ¬¡æ€§å¡«å……10ä¸ªç®±å­è®©é˜Ÿåˆ—æ»¡ç®±ï¼Œå› ä¸ºmin_after_dequeueæ˜¯7æ‰€ä»¥æœ€å¤šåªèƒ½å¼¹å‡º3ä¸ªç®±å­,å¦åˆ™é˜»å¡ã€‚ 123456789101112131415161718import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=7, dtypes=[tf.int32, tf.int32], shapes=[(2,),(3,)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[10,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[10,3])enqueue_op = input_queue.enqueue_many([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue data1 = np.arange(20).reshape(10,2) data2 = np.arange(30).reshape(10,3) sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) PaddingFIFOQueueæ”¯æŒå˜åŒ–çš„shapeï¼ŒåŒæ—¶æ”¯æŒdequeue_many!12345678910111213141516171819import tensorflow as tfimport numpy as npinput_queue = tf.PaddingFIFOQueue(capacity=10, dtypes=[tf.int32, tf.int32], shapes=[(None,2),(None,3)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[None,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[None,3])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data1 = np.arange(2*(i+1)).reshape(-1,2)+i data2 = np.arange(3*(i+1)).reshape(-1,3)+i sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) [array([[[0, 1],[0, 0],[0, 0]], [[1, 2],[3, 4],[0, 0]], [[2, 3],[4, 5],[6, 7]]], dtype=int32), array([[[ 0, 1, 2],[ 0, 0, 0],[ 0, 0, 0]], [[ 1, 2, 3],[ 4, 5, 6],[ 0, 0, 0]], [[ 2, 3, 4],[ 5, 6, 7],[ 8, 9, 10]]], dtype=int32)] å‘ç°äº†ä»€ä¹ˆå§ï¼Œå°±æ˜¯å®ƒè¡¥é›¶äº†ã€‚å°å°è¯´äº›é¢˜å¤–è¯ï¼Œä½ è§è¿‡np.array([[1],[1,2],[1,2,3]])çš„è¿”å›å€¼å—ï¼Ÿæ²¡å§ï¼Œæ˜¯Objectè€Œä¸æ˜¯int64ã€‚å› ä¸ºnumpyä¸æ”¯æŒï¼Œä½†æ˜¯pythonæœ¬èº«æ”¯æŒ[[1],[1,2],[1,2,3]]ã€‚è¿™å°±ä¸å¦‚Mathematicaäº†,è¡¨æ‰¬ä¸€ä¸‹é¡ºä¾¿æ¨èè¿™ä¸ªè¯­è¨€ï¼ å¦‚æœæ”¹æˆdequeue = input_queue.dequeue_many(1)ï¼Œä¸€æ¬¡åªå‡ºä¸€ä¸ªç®±å­é‚£ä¹ˆå°±ä¸ä¼šå‡ºç°è¡¥é›¶æƒ…å†µäº†ã€‚æ‰€ä»¥è¡¥é›¶å‘ç”Ÿåœ¨sess.run(dequeue)çš„æ—¶å€™ ç”šè‡³å®ƒè¿˜æ”¯æŒshapeå®Œå…¨ä¸å®šçš„æƒ…å†µ12345678910111213141516import tensorflow as tfimport numpy as npinput_queue = tf.PaddingFIFOQueue(capacity=10, dtypes=[tf.int32], shapes=[(None,None)])placeholder = tf.placeholder(dtype=tf.int32, shape=[None,None])enqueue_op = input_queue.enqueue([placeholder])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data = np.arange((i+1)**2).reshape(i+1,i+1)+i sess.run(enqueue_op,feed_dict=&#123;placeholder:data&#125;) print sess.run(dequeue) [[[ 0 0 0] [ 0 0 0] [ 0 0 0]] [[ 1 2 0] [ 3 4 0] [ 0 0 0]] [[ 2 3 4] [ 5 6 7] [ 8 9 10]]] å‡½æ•°ï¼šä¼šè¯æ³¨å†Œï¼šsess=tf.InteractivateSession()è¡¨ç¤ºå°†æ˜¯è¿™ä¸ªåˆ›å»ºçš„sessionä½œä¸ºéšåé»˜è®¤çš„sessionï¼Œä¹‹åçš„è¿è¡Œä¹Ÿè¿ç®—ä¹Ÿåœ¨è¿™é‡Œé¢è¿›è¡Œ åˆ—å‡ºå½“å‰æ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨çš„deviceä½¿ç”¨çš„æ˜¯tf.Session(config=tf.ConfigProto(log_device_placement=True)) å„ç§losså‡½æ•°tf.losses.mean_squared_errorç†è§£123456789101112131415161718192021import tensorflow as tfimport numpy as npshape_obj = (5,6,3)Y1 = tf.random_normal(shape=shape_obj)Y2 = tf.random_normal(shape=shape_obj)loss1 = tf.reduce_sum(tf.pow(Y1 - Y2, 2)) / (reduce(lambda x, y: x*y, shape_obj))loss2 = tf.reduce_mean(tf.squared_difference(Y1, Y2))loss3 = tf.losses.mean_squared_error(predictions=Y1, labels=Y2)loss4 = tf.nn.l2_loss(Y1 - Y2)with tf.Session() as sess: #ä¸éœ€è¦åˆå§‹åŒ– lis = sess.run([Y1, Y2, loss1, loss2, loss3, loss4]) Y1, Y2 = lis[:2] #Y1, Y2 print lis[2:] #loss1, loss2, loss3, loss4 lis=[] for i in range(shape_obj[-1]): lis.append(np.mean(np.square((Y1[:,:,i]-Y2[:,:,i])))) print np.mean(lis) [2.0185342, 2.0185342, 2.0185342, 90.83404]2.018534 å¯ä»¥çœ‹åˆ°tfæŠŠæœ€åä¸€ç»´ï¼ˆshape_obj æ˜¯äºŒç»´ä¹Ÿæ˜¯ä¸€æ ·ï¼‰å½“åšbatch_axisï¼Œè€Œä¸”lossæ²¡æœ‰é™¤ä»¥2åœ¨Gluoné‡Œå°±ç›¸å½“äºï¼šloss1=gluon.loss.L2Loss(batch_axis=-1)*2è¿˜å‘ç°ä¸€ä¸ªé—®é¢˜å°±æ˜¯sess.run(æƒ³è¦çš„å¿…é¡»å†™åœ¨ä¸€èµ·)ï¼Œå¦‚æœsess.run(loss1);sess.run(loss1)ç»“æœä¹Ÿä¼šä¸ä¸€æ ·ï¼Œå› ä¸ºæ¯è¿è¡Œä¸€æ¬¡runè®¡ç®—å›¾å°±è¿è¡Œä¸€æ¬¡ï¼Œå› ä¸ºæ¯æ¬¡è¿è¡Œçš„éšæœºæ•°ä¸ä¸€æ ·ï¼Œç»“æœè‡ªç„¶ä¹Ÿä¸ä¸€æ · 12345678910111213141516import mxnet as mxfrom mxnet import gluonimport numpy as np#Indicate 2-th dims as batch_axisloss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,5,4))b=mx.nd.random.uniform(0, 10,shape=(3,5,4))print loss1(a,b)#[ 4.95132017 11.42089748 7.28211212 6.8867259 6.93179274]#&lt;NDArray 5 @cpu(0)&gt;lis=[]for i in range(5): lis.append(1./2*np.mean(np.square((a[:,i,:]-b[:,i,:]).asnumpy())))print lis#[4.9513201713562012, 11.420897483825684, 7.282111644744873, 6.886725902557373, 6.9317927360534668] tf.losses.sparse_softmax_cross_entropyç†è§£sparse_softmax_cross_entropyè¦æ±‚labelsæ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨å½¢å¼ï¼ŒèŒƒå›´æ˜¯[0, num_classes], logitsæ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æ®ï¼Œå­˜å‚¨çš„æ˜¯ç½‘ç»œè¾“å‡ºçš„å€¼ MXNetå’Œtfç»“æœä¸€æ ·ï¼Œè¯´æ˜åœ¨äºŒç»´æ•°æ®çš„æ—¶å€™ï¼Œéƒ½æ˜¯å°†ç¬¬ä¸€ç»´ä½œä¸ºbatch_axis,ç±»åˆ«æ€»æ•°å¯ä»¥ä»Y1.shape[1]çŸ¥é“123456789101112131415161718import tensorflow as tfimport numpy as npY1 = tf.constant(np.arange(50).reshape((5,10)),dtype=tf.float32)Y2 = tf.constant([5,3,2,9,1])Y3 = tf.one_hot(Y2, depth = Y1.shape[1])loss1 = tf.losses.sparse_softmax_cross_entropy(logits=Y1, labels=Y2)loss2 = tf.losses.softmax_cross_entropy(logits=Y1, onehot_labels=Y3)loss3 = tf.nn.softmax_cross_entropy_with_logits(logits=Y1, labels=Y3)loss4 = tf.reduce_mean(loss3)with tf.Session() as sess: [loss1,loss2,loss3,loss4] = sess.run([loss1,loss2,loss3,loss4]) print loss1,loss2 #5.4586296, 5.4586296 print loss3.shape #(5,) print np.mean(loss3) #5.4586296 print loss4 #5.4586296''' ç”¨MXNetæ¥éªŒè¯1234567import mxnet as mximport numpy as nploss=mx.gluon.loss.SoftmaxCrossEntropyLoss()a=mx.nd.array(np.arange(50).reshape((5,10)))b=mx.nd.array([5,3,2,9,1])print loss(a,b)print mx.nd.mean(loss(a,b))#5.45862961 ç¥ç»ç½‘ç»œå‡½æ•°tf.one_hot()tf.one_hot([[0,1],[2,3]],depth=5)å¾—åˆ°çš„æ•°æ®ç»´åº¦æ˜¯(2,2,5)tf.one_hot([[[0,1],[2,3]],[[0,1],[2,3]]],depth=5)å¾—åˆ°çš„æ•°æ®ç»´åº¦æ˜¯(2,2,2,5) tf.uniqueå’Œtf.unique_with_countså‡½æ•°12345678910111213import tensorflow as tfimport numpy as npY1 = tf.constant([1,1,2,4,4,3,3,7])Y2 = tf.unique(Y1)Y3 = tf.unique_with_counts(Y1)with tf.Session() as sess: [Y2,Y3] = sess.run([Y2,Y3]) print Y2 #Y2:Unique(y=array([1, 2, 4, 3, 7], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 3, 4], dtype=int32)) print Y3 #Y3:UniqueWithCounts(y=array([1, 2, 4, 3, 7], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 3, 4], dtype=int32), count=array([2, 1, 2, 2, 1], dtype=int32)) å®ç°å·¦ç§»ä¸€ä¸ªæ•°ï¼Œæœ€å³è¡¥é›¶å°†[[0],[1],[2],[3]]-&gt;[[1],[2],[3],[0]]12345678import tensorflow as tfencoded = tf.reshape(tf.constant(range(4)),[1,-1,1])shifted = tf.slice(encoded, [0, 1, 0],[-1, tf.shape(encoded)[1] - 1, -1])shifted = tf.pad(shifted, [[0, 0], [0, 1], [0, 0]])with tf.Session() as sess: print sess.run([encoded,shifted]) tf.conv1Dè¾“å…¥çš„shapeæ˜¯ï¼ˆbatch_size, width1, in_channelï¼‰å·ç§¯æ ¸çš„shapeæ˜¯ ï¼ˆfilter_width, in_channel, out_channelï¼‰è¾“å‡ºæ˜¯ï¼ˆbatch_size, width2, out_channelï¼‰123456789101112import tensorflow as tfimport numpy as npx = tf.Variable(np.arange(320).reshape(8,10,4).astype(np.float32))k = tf.Variable(tf.contrib.layers.xavier_initializer_conv2d()(shape=[5,4,16]))conv = tf.nn.conv1d(x, k, stride=1, padding='VALID', data_format='NWC')with tf.Session() as sess: sess.run(tf.global_variables_initializer()) [a, b] = sess.run([x, conv]) print a.shape, b.shape #(8, 10, 4) -&gt; (8, 6, 16) å›¾åƒå¤„ç†å®Œæ•´èŒƒä¾‹1234567891011121314import tensorflow as tfimport numpy as npfrom PIL import Imageimg = Image.open("1620.jpg")img.show()w, h = img.sizeimg = np.expand_dims(img, 0)bi_image_bilinear = tf.image.resize_bilinear(img, size=(int(h*3), int(w*3)))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: bi_result = sess.run(bi_image_bilinear)Image.fromarray(np.uint8(bi_result)).show() tf.image.resize*tf.image.resize_nearest_neighbor [0 1 2] -&gt; [0 0 1 1 2 2]tf.image.resize_bilinear [0 1 2] -&gt; [0 0.5 1 1.5 2 2 ]tf.image.resize_bicubic [0 0.40625 1 1.59375 2 2.09375]123456789import tensorflow as tfimport numpy as npimg = np.arange(3).reshape((1,1,3,1))bi_image_bilinear = tf.image.resize_bilinear(img, size=(1,6))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: print sess.run(bi_image_bilinear)]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2018%2F07%2F26%2FLinux%2F</url>
    <content type="text"><![CDATA[å‘½ä»¤è¡ŒæŒ‡ä»¤Linuxè¦æŸ¥çœ‹æ‰€æœ‰å’Œpdfç›¸å…³çš„å‘½ä»¤ å¯ä»¥è¾“å…¥pdf å†æŒ‰Tabé”® ç›®å½• ls -lçœ‹å½“å‰ç›®å½•ä¸‹æ–‡ä»¶çš„åŸºæœ¬å±æ€§ ls -açœ‹éšè—æ–‡ä»¶ treeå¯ä»¥çœ‹åˆ°ç›®å½•æ ‘ç»“æ„ åˆ é™¤æ–‡ä»¶å¤¹ rm -rf xxx sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/å°†è¿œç¨‹æœåŠ¡å™¨88çš„æ–‡ä»¶å¤¹/home/xzhou/projectæŒ‚è½½åˆ°æœ¬æœºçš„88_mount/ç›®å½•ä¸‹ï¼Œå–æ¶ˆæŒ‚è½½fusermount -u 88_mount/.æ³¨æ„ç®¡ç†å‘˜ä¸‹éœ€è¦sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/ -o allow_other ln -s /tmp/test1.txt test2.txt å°†åœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºç¬¦å·æ–‡ä»¶â€œtest2.txtâ€ï¼Œln -s /tmp/test1.txt å°†åœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºç¬¦å·æ–‡ä»¶â€œtest1.txtâ€ã€‚åˆ é™¤é“¾æ¥ç¬¦å·æ–‡ä»¶è¯­æ³•æ˜¯rm fileæˆ–è€…rm dir æ–‡å­—å¤„ç† Linuxç³»ç»Ÿä¸­çš„wc(Word Count)å‘½ä»¤çš„åŠŸèƒ½ä¸ºç»Ÿè®¡æŒ‡å®šæ–‡ä»¶ä¸­çš„å­—èŠ‚æ•°ã€å­—æ•°ã€è¡Œæ•°ï¼Œå¹¶å°†ç»Ÿè®¡ç»“æœæ˜¾ç¤ºè¾“å‡º PDFç›¸å…³PDF-&gt;TXTpdftotextå¯ä»¥å¾—åˆ°pdfå¯¹åº”çš„çº¯æ–‡æœ¬ç‰ˆæœ¬ å­—ä½“åµŒå…¥å¼ºåˆ¶å­—ä½“åµŒå…¥ï¼š12pdf2ps template.pdfps2pdf -dPDFSETTINGS=/prepress template.ps file.pdf éªŒè¯ï¼špdffonts template.pdfå¯ä»¥çœ‹åˆ°æ‰€æœ‰å­—ä½“å·²è¢«åµŒå…¥ å›¾åƒå¤„ç†Macéœ€è¦ brew install imagemagickæ‰èƒ½ä½¿ç”¨convert gifè½¬ä¸€äº›åˆ—å›¾ç‰‡ï¼ˆå¸§ä¸ºå•ä½ï¼‰ convert test.gif test%05d.pngä¸€ç³»åˆ—pngè½¬è§†é¢‘ ffmpeg -i test%05d.png test.mp4 å¦‚æœéœ€è¦å°†è§†é¢‘é€Ÿåº¦å˜æ…¢è¦åŠ é€‰é¡¹ -filter:v &quot;setpts=2.0*PTS&quot;è¦è®©ç¬¦åˆMP4V2æ ¼å¼éœ€è¦åŠ é€‰é¡¹ -brand mp42æ¯”å¦‚ffmpeg -i test%05d.png -filter:v &quot;setpts=2.0*PTS&quot; -brand mp42 test.mp4 ç³»ç»ŸæŒ‡ä»¤ getconf LONG_BITå¾—åˆ°Linuxç³»ç»Ÿæ˜¯x86è¿˜æ˜¯x32 cat /proc/driver/nvidia/versionæŸ¥çœ‹CUDAé©±åŠ¨ç‰ˆæœ¬ who -b æŸ¥çœ‹æœ€åä¸€æ¬¡ç³»ç»Ÿå¯åŠ¨çš„æ—¶é—´ who -r æŸ¥çœ‹å½“å‰ç³»ç»Ÿè¿è¡Œæ—¶é—´ æŸ¥çœ‹æ‰€ç”¨çš„æ¡Œé¢ç¯å¢ƒ env|grep DESKTOP= lsb_release -aæŸ¥çœ‹ç³»ç»Ÿç‰ˆæœ¬(æ²¡æœ‰å°±ç”¨yum install lsbæˆ–è€…cat /etc/os-release) å…³æœº shutdown -r now å¢åŠ ç”¨æˆ· å…ˆç™»å½•rootç”¨æˆ· adduser xzhou passwd xzhou ä¼¼ä¹ä¸éœ€è¦ å› ä¸ºç¬¬ä¸€æ­¥è¾“å…¥äº†å¯†ç å¢åŠ ç½‘ç»œèµ„æºå…±äº«æ–‡ä»¶å¤¹ sudo nano /etc/samba/smb.conf sudo smbpasswd -a xzhou sudo service smbd restart æ˜¾å¡ GPUè®¡ç®— watch -n 1 nvidia-smi æ¯ç§’åˆ·æ–°ä¸€æ¬¡ nvidia-smi è¿›ç¨‹ ps ax | grep python å¯ä»¥çœ‹åˆ°å…¶ä»–äººåœ¨è¿è¡Œçš„Pythonä»£ç  å·²çŸ¥PIDæŸ¥çœ‹æŒ‡ä»¤æ‰€åœ¨ç›®å½•ï¼šlsof -p PID|grep cwd kill -s 9 PID å¼ºåˆ¶æ€æ­»è¿›ç¨‹æ ‡è¯†å·PIDçš„è¿›ç¨‹ å·²çŸ¥PIDå¦‚ä½•æŸ¥çœ‹å®Œæ•´æŒ‡ä»¤:ps PID å·²çŸ¥ç«¯å£æŸ¥è¿›ç¨‹æ˜¯ lsof â€“i:ç«¯å£å· å·¥å…· å®æ—¶æŸ¥çœ‹ç½‘é€Ÿ sudo apt-get install nethogs &amp; sudo nethogs æŸ¥çœ‹å…¬ç½‘IP curl api.ipify.org æŸ¥çœ‹ç§æœ‰IP ifconfig å®‰è£…VNC-serverps -ef|grep -i vnc æŸ¥çœ‹æ­£åœ¨è¿è¡Œçš„vncserverçš„è¿›ç¨‹vncserver -kill :1 #å…³é—­è¿™ä¸ªè¿æ¥vncserver :1 é‡å¯vncserver ç¾åŒ–å’Œæ±‰åŒ–manæ±‰åŒ– sudo apt-get install sudo !!-zh æŸ¥çœ‹man æ‰‹å†Œå®‰è£…åˆ°å“ªé‡Œï¼Œdpkg -L manpages-zh | lessæŸ¥çœ‹åˆ°å®‰è£…åœ¨/usr/share/man/zh_CN è®¾ä¸€ä¸ªä¸­æ–‡manåˆ«å, ä¿®æ”¹ ~/.bashrc æ·»åŠ ä¸€ä¸ªalias :alias cman=&#39;man -M /usr/share/man/zh_CN&#39;ï¼Œæˆ–è€…ç”¨å‘½ä»¤sed -i &#39;$a alias cman=&quot;man -M /usr/share/man/zh_CN&quot;&#39; .bashrc(åœ¨æœ€åä¸€è¡Œåå¢åŠ ä¸€è¡Œï¼Œå¹¶å†™å…¥æ–‡ä»¶) source ~/.bashrc é‡å¯ç»ˆç«¯ cman lså°±æ˜¯æ±‰åŒ–çš„manï¼Œman lså°±æ˜¯è‹±æ–‡çš„man##ç¾åŒ– sudo apt-get install most ä¿®æ”¹ ~/.bashrc æ·»åŠ ä¸€ä¸ªç¯å¢ƒå˜é‡ :export PAGER=&quot;/usr/bin/most -s&quot;,æˆ–è€…ç”¨å‘½ä»¤sed -i &#39;$a export PAGER=&quot;/usr/bin/most -s&quot;&#39; .bashrc(åœ¨æœ€åä¸€è¡Œåå¢åŠ ä¸€è¡Œï¼Œå¹¶å†™å…¥æ–‡ä»¶) source ~/.bashrc é‡å¯ç»ˆç«¯ man lså°±æ˜¯è‹±æ–‡çš„ç¾åŒ–ç‰ˆçš„man å°æŠ€å·§è®©ä¸Šä¸€ä¸ªå‘½ä»¤ä»¥ç®¡ç†å‘˜èº«ä»½æ‰§è¡Œapt-get install rangerç„¶åæŠ¥æƒé™ä¸è¶³å†æ•²å…¥sudo !!è¿è¡Œä¸Šä¸€æ¡å‘½ä»¤ å¿«æ·é”®å‘½ä»¤è¡Œæ—¥å¸¸ç³»å¿«æ·é”® CTRL + U - å‰ªåˆ‡å…‰æ ‡å‰çš„å†…å®¹CTRL + K - å‰ªåˆ‡å…‰æ ‡è‡³è¡Œæœ«çš„å†…å®¹CTRL + Y - ç²˜è´´CTRL + E - ç§»åŠ¨å…‰æ ‡åˆ°è¡Œæœ«CTRL + A - ç§»åŠ¨å…‰æ ‡åˆ°è¡Œé¦–ALT + F - è·³å‘ä¸‹ä¸€ä¸ªç©ºæ ¼ALT + B - è·³å›ä¸Šä¸€ä¸ªç©ºæ ¼ALT + Backspace - åˆ é™¤å‰ä¸€ä¸ªå•è¯CTRL + W - å‰ªåˆ‡å…‰æ ‡åä¸€ä¸ªå•è¯Shift + Insert - å‘ç»ˆç«¯å†…ç²˜è´´æ–‡æœ¬ æš‚åœå¹¶åœ¨åå°è¿è¡Œå‘½ä»¤CTRL + Z - æš‚åœåº”ç”¨ç¨‹åºï¼ˆæ¯”å¦‚æ­£åœ¨ç”¨nanoç¼–è¾‘test.txtï¼‰fg - é‡æ–°å°†ç¨‹åºå”¤åˆ°å‰å°jobs - æŸ¥çœ‹ä»»åŠ¡æ•°ç›®åªè¦æŒ‰CTRL + Zï¼Œå‰å°çš„å‘½ä»¤å°±ä¼šæš‚åœï¼Œç”»é¢å°±åˆ‡å›åˆ°å‘½ä»¤è¡Œäº†ã€‚ç„¶åä½ å°±èƒ½è¿è¡Œä½ æƒ³è¦è¿è¡Œçš„å‘½ä»¤ï¼Œç­‰å‘½ä»¤è¿è¡Œå®Œååœ¨ç»ˆç«¯çª—å£è¾“å…¥fgå°±å¯ä»¥å›åˆ°å…ˆå‰æš‚åœçš„ä»»åŠ¡ ä¸‹è½½è§†é¢‘ä½¿ç”¨you-getå’Œyoutube-dlä»¥åŠç¡•é¼ ä»Youtubeè§†é¢‘ä¸­ä¸‹è½½éŸ³é¢‘ï¼ˆwavæ ¼å¼ï¼‰æ”¯æŒbç«™youtube-dl â€“extract-audio â€“audio-format wav URL æ¯”å¦‚æˆ‘æƒ³ä¸‹è½½è¿™ä¸ªæƒ…éå¾—å·²çš„éŸ³é¢‘ ä½¿ç”¨python3å®‰è£…you-get you-get http://www.miaopai.com/show/R~22buLsn55r7IVQKvMjZ4Le2mJ7PS7BqxjbAg__.htm ffmpeg -i é˜¿å¡è´æ‹‰ç‰ˆæƒ…éå¾—å·².mp4 -f mp3 -vn é˜¿å¡è´æ‹‰ç‰ˆæƒ…éå¾—å·².mp3å‚æ•°è§£é‡Šï¼š-i è¡¨ç¤ºinputï¼Œå³è¾“å…¥æ–‡ä»¶-f è¡¨ç¤ºformatï¼Œå³è¾“å‡ºæ ¼å¼-vnè¡¨ç¤ºvedio notï¼Œå³è¾“å‡ºä¸åŒ…å«è§†é¢‘ play é˜¿å¡è´æ‹‰ç‰ˆæƒ…éå¾—å·².mp3 (éœ€è¦å®‰è£…soxåº“) åå°ä¸‹è½½è§†é¢‘å¦‚æœç°åœ¨å¾ˆå¤šä¸ªbç«™è§†é¢‘éœ€è¦ä¸‹è½½ï¼Œæ˜¯ä¸æ˜¯å°±æ˜¯CTRL + Z and fg ç»“åˆ youtube-dlï¼Œå®è·µå‘ç°ä¸è¡Œï¼ŒæŒ‚èµ·æ—¶ä¸‹è½½ä¼šæš‚åœã€‚ä¹‹å‰æˆ‘ç©è¿‡æ ‘è“æ´¾ï¼Œå¾ˆå¤šLinuxçŸ¥è¯†éƒ½æ˜¯ä»é‚£é‡Œå­¦åˆ°çš„ æ‰€ä»¥æˆ‘å‘ç°äº†screenå‘½ä»¤. MacOSæ˜¯è‡ªå¸¦çš„,Linuxä½¿ç”¨sudo apt-get install screenå®‰è£… ç»ˆç«¯è¾“å…¥ï¼ˆXshellè½¯ä»¶é‡Œæ“ä½œä¸€æ ·çš„ï¼‰:1screen youtube-dl --extract-audio --audio-format mp3 https://www.bilibili.com/video/av6846882 å®ƒä¼šä¸‹è½½ç¬¬ä¸€ä¸ªè§†é¢‘ï¼Œè¿™æ—¶å€™æŒ‰ä½Ctrl+A+Dä¼šå›åˆ°ç»ˆç«¯ï¼Œä½†æ˜¯è§†é¢‘ä¾ç„¶åœ¨ä¸‹è½½ï¼Œè¿™æ—¶å€™å†æ¬¡ç»ˆç«¯è¾“å‡ºæ–°çš„è§†é¢‘PIDï¼Œå°±ä¼šä¸‹è½½ç¬¬äºŒä¸ªï¼Œä»¥æ­¤ç±»æ¨â€¦ æŸ¥çœ‹æ‰€ä»¥ä»»åŠ¡æ˜¯screen -ls,æ‰€æœ‰è§†é¢‘ä¸€æ—¦å®Œæˆä¸‹è½½ï¼Œscreen -lså°±ä¼šè¾“å‡ºNo Sockets found in bilibala...ã€‚è¯´æ˜ä¸€ä¸ªä»»åŠ¡å®Œæˆå®ƒä¼šè‡ªåŠ¨é€€å‡ºé‚£ä¸ªè™šæ‹Ÿç»ˆç«¯çš„ å¦‚æœæˆ‘ä»¬å…³é—­ç»ˆç«¯ä¸å½±å“screenï¼Œä¸ä¿¡ä½ é‡æ–°æ‰“å¼€ç»ˆç«¯è¯•è¯•screen -ls æ¢å¤ä¸€ä¸ªè™šæ‹Ÿç»ˆç«¯å‘½ä»¤æ˜¯screen -r IDå· Dockerå®¹å™¨ æŸ¥çœ‹å½“å‰æ­£åœ¨è¿è¡Œçš„å®¹å™¨ docker ps æ˜¾ç¤ºå·²ç»é€€å‡ºçš„å®¹å™¨ docker ps -a æ˜¾ç¤ºæ‰€æœ‰é•œåƒ docker images å¯åŠ¨/åœæ­¢æŸä¸ªå®¹å™¨ docker start/stop å®¹å™¨ID åˆ é™¤æŸä¸ªå®¹å™¨ docker rm å®¹å™¨ID åˆ é™¤é•œåƒ docker rmi é•œåƒID å®è·µ åœ¨å®¹å™¨è¿è¡Œå‘½ä»¤ docker run ubuntu cat /etc/os-releaseï¼Œæ²¡æœ‰è¿™ä¸ªé•œåƒåˆ™åˆ›å»ºé•œåƒï¼ˆç”¨å®Œå¯åˆ é™¤å®¹å™¨ï¼‰ å¼€å¯å®¹å™¨äº¤äº’æ¨¡å¼ï¼šdocker run -it ubuntu /bin/bash exité€€å‡º æŸ¥çœ‹å®¹å™¨ID docker ps -a æ‰“å¼€äº¤äº’å¼ç»ˆç«¯ docker start -i å®¹å™¨ID ä»¥åæ¯æ¬¡ä½¿ç”¨å°±ä½¿ç”¨ä¸Šé¢è¿™ä¸ªå‘½ä»¤å°±è¡Œ nanoå¿«æ·é”®]]></content>
      <categories>
        <category>å¸¸è§æŒ‡ä»¤ä»¥åŠç”¨æ³•å¤‡å¿˜å½•</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç´ æç½‘ç«™]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%B4%A0%E6%9D%90%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[å¯è§†åŒ–ç®—æ³• å¯è§†åŒ–ç®—æ³•ç½‘ç«™ æ—§é‡‘å±±å¤§å­¦çš„ç®—æ³•è¯¾ç¨‹çš„å¯è§†åŒ– VisuAlgo æå…¶ç»šä¸½ï¼Œè‰ºæœ¯æ•ˆæœä¼¼çš„å¯è§†åŒ–ï¼Œç”¨äº†D3 ç›¸åº”ä¸­æ–‡ç‰ˆ ç®—æ³•çš„äº’åŠ¨å¯è§†åŒ– github ç½‘é¡µç‰ˆ PCA ä»‹ç»ç®—æ³•çš„Distill å¯è§†åŒ–å½¢å¼çš„è®ºæ–‡ å¯è§†åŒ–K-Means è¿˜æœ‰å…¶ä»–å¾ˆå¤šç®—æ³• äº¤äº’çš„ JavaScriptå¯è§†åŒ–å¥½æƒ³å­¦HTML5 Canvaså‘€ å¥½æ¼‚äº® æ¯”å¦‚å…¨æ˜¯è®¡ç®—æœºç”Ÿæˆçš„å‘€ D3 paper.js å„ç§å¯è§†åŒ–æ–¹æ¡ˆè®²è§£ é˜¿é‡Œå·´å·´çš„å¢¨è€…å­¦é™¢ å¯è§†åŒ–ç¥ç»ç½‘ç»œ è®¡ç®—æœºè§†è§‰å†å²-The Modern History of Object Recognition å¯è§†åŒ–DNN CNN ç®€æ˜“å£°éŸ³ç´ æç½‘ç«™ Find the perfect sound. - soundsnap freesound WebGL 20ä¸ªä¸å¯æ€è®®çš„ WebGL ç¤ºä¾‹å’Œæ¼”ç¤º]]></content>
      <categories>
        <category>æ”¶è—</category>
      </categories>
      <tags>
        <tag>å¯è§†åŒ–</tag>
        <tag>ç½‘ç«™</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F07%2F26%2FPython%2F</url>
    <content type="text"><![CDATA[ä½¿ç”¨ä¸­æ–‡# -*- coding: utf-8 -*- å‘Šè¯‰Pythonè§£é‡Šå™¨ï¼Œç”¨UTF-8ç¼–ç è¯»å–æºä»£ç print u&#39;ä¸­æ–‡&#39; uè¡¨ç¤ºUnicodeå­—ç¬¦ä¸² Pythonè¯´æ˜Pythonä»£ç çš„ç¼©è¿›è§„åˆ™è¯´ï¼šæœ€å¥½ä½¿ç”¨4ä¸ªç©ºæ ¼ipython --pylab å¯¼å…¥äº†numpy(np) å’Œ matplotlib åŸºç¡€çŸ¥è¯†é¢„å¤‡åŸºç¡€çŸ¥è¯† è‹¥è‡ªå®šä¹‰å‡½æ•°æ²¡æœ‰returnï¼Œå‡½æ•°æ‰§è¡Œå®Œæ¯•åè¿”å›None ä¿æŒå­—å…¸é¡ºåºä¸å˜ä½¿ç”¨OrderedDict 123from collections import OrderedDictprint dict([('a', 1), ('b', 2), ('c', 3)]) #Randomprint OrderedDict([('a', 1), ('b', 2), ('c', 3)]) #Ordered å‘½ä»¤è¡Œå‚æ•°ï¼š 12345678import sys if __name__=="__main__": print len(sys.argv) for i in sys.argv: print i,#save as test.py#python test.py #result: 1 2 3 ç”¨râ€™â€¦â€™æ¥æŠ‘åˆ¶è½¬ä¹‰å¦‚path = râ€™C:\xzhou\Desktopâ€™ å…³äºå¸ƒå°”è¿ç®—PythonæŠŠ0ã€ç©ºå­—ç¬¦ä¸²â€™â€™å’ŒNoneçœ‹æˆ Falseå…¶ä»–æ•°å€¼å’Œéç©ºå­—ç¬¦ä¸²éƒ½çœ‹æˆ Trueä¸è¿‡ä¸è¦å®Œå…¨ä¾èµ–è¿™ä¸€ç‚¹ List 123456789L=['Michael', 'Bob', 'Tracy'] # åˆ›å»ºList#å¯ç”¨ç´¢å¼• L [0], L [2], L [-1], L [-3], L [0:3]L [-1::-1] #å¾—åˆ° L çš„é€†åº['Tracy', 'Bob', 'Michael'] L [-1:0:-1] #å¾—åˆ°['Tracy', 'Bob']L .append('Paul') #æ”¹å˜äº†LL .insert(0, 'Paul') # æ”¹å˜äº†L L ç°åœ¨ä¸º['Paul', 'Michael', 'Bob', 'Tracy', 'Paul']L .pop() #è¿”å›'Paul' L ç°åœ¨ä¸º['Paul', 'Michael', 'Bob', 'Tracy'] L .pop(0) #è¿”å›'Bob' L ç°åœ¨ä¸º ['Michael', 'Bob', 'Tracy']L [2] = 'Paul' # L ç°åœ¨ä¸º['Michael', 'Bob', 'Paul'] è¿­ä»£åˆ—è¡¨:123a=range(10)for i in iter(a): print i åˆ—è¡¨çš„æ‹¼æ¥ï¼ˆstr,tupleä¹Ÿå¯ä»¥è¿™æ ·,dictå’Œsetä¸è¡Œï¼‰:123456a = []b = [1,]c = [2,3]print a+b+c #[1,2,3]print c * 2 #[2,3,2,3]print []+[[1,2],[3,4]]+[[5,6],[7,8]] #[[1,2],[3,4],[5,6],[7,8]] TupleTupleæ²¡æœ‰append()æ–¹æ³•ï¼Œä¹Ÿæ²¡æœ‰insert()å’Œpop()æ–¹æ³•ã€‚#è·å–Tupleå…ƒç´ çš„æ–¹å¼å’ŒListä¸€æ ·ï¼Œå¯ä»¥ä½¿ç”¨ t[0]ï¼Œt[-1]ç­‰ç´¢å¼•æ–¹å¼è®¿é—®å…ƒç´ ï¼Œä½†æ˜¯ä¸èƒ½èµ‹å€¼æˆåˆ«çš„å…ƒç´  Tupleå’ŒListä¸€æ ·ï¼Œå¯ä»¥åŒ…å« 0 ä¸ªã€1ä¸ªå’Œä»»æ„å¤šä¸ªå…ƒç´ t = ()å¯¹åº”s=[]t=(1,)å¯¹åº”s=[1], ä¸ºäº†é˜²æ­¢æ­§ä¹‰è€Œä¸ä½¿ç”¨(1) ä¸è¿‡å½“TupleåŒ…æ‹¬éTupleç±»å‹æ—¶å¯æ”¹å˜å¦‚t = (â€˜aâ€™, â€˜bâ€™, [â€˜Aâ€™, â€˜Bâ€™])å¯æ”¹å˜[â€˜Aâ€™, â€˜Bâ€™]å†…çš„å…ƒç´ ä½†t = (â€˜aâ€™, â€˜bâ€™, (â€˜Aâ€™, â€˜Bâ€™))ä¸å¯ä»¥ dictlen(d)å¾—åˆ°å­—å…¸é•¿åº¦d.get(â€˜Bartâ€™)å¾—åˆ°â€™Bartâ€™å¯¹åº”çš„é”®ï¼Œä¸å­˜åœ¨è¿”å›None1234567891011121314151617d = &#123;'a':[1,2],'b':['hello','xiao',3]&#125;print d.items()# éå†é”®for key in d: print key,# éå†é”®å€¼for key, value in d.items(): #åˆ›å»ºè¿­ä»£å™¨ï¼Œæ•ˆç‡æ›´é«˜ print key,value# æ›´å¿«çš„éå†é”®å€¼ï¼Œä¹Ÿçœå†…å­˜for key, value in d.iteritems(): #åˆ›å»ºè¿­ä»£å™¨ï¼Œæ•ˆç‡æ›´é«˜ print key,value# éå†å€¼for v in d.values(): print v,# æ›´å¿«é€Ÿçš„éå†å€¼ï¼Œä¹Ÿçœå†…å­˜for v in d.itervalues(): print v, å¦å¤–å€¼å¾—æ³¨æ„çš„æ˜¯keyåªèƒ½é€‰æ‹©ä¸èƒ½è¢«æ”¹å˜çš„æ•°æ®ç±»å‹å¦‚æ•´æ•°ã€å­—ç¬¦ä¸²ã€Tupleï¼Œä¸èƒ½ç”¨List setç±»å‹å› ä¸ºå¼ºè°ƒçš„äº‹å¹¶é›†ï¼Œæ‰€ä»¥æ’åºæ— è§„å¾‹ä¹Ÿä¸æ”¯æŒç´¢å¼•æ”¯æŒ len(s), â€˜Aâ€™ in s ç­‰ setçš„å†…éƒ¨ç»“æ„å’Œdictå¾ˆåƒï¼Œå”¯ä¸€åŒºåˆ«æ˜¯ä¸å­˜å‚¨valueï¼Œå› æ­¤ï¼Œåˆ¤æ–­ä¸€ä¸ªå…ƒç´ æ˜¯å¦åœ¨setä¸­é€Ÿåº¦å¾ˆå¿«ã€‚setå­˜å‚¨çš„å…ƒç´ å’Œdictçš„keyç±»ä¼¼ï¼Œå¿…é¡»æ˜¯ä¸å˜å¯¹è±¡ï¼Œå› æ­¤ï¼Œä»»ä½•å¯å˜å¯¹è±¡æ˜¯ä¸èƒ½æ”¾å…¥setä¸­çš„ã€‚æœ€åï¼Œsetå­˜å‚¨çš„å…ƒç´ ä¹Ÿæ˜¯æ²¡æœ‰é¡ºåºçš„ã€‚é€‚ç”¨åœºåˆï¼šè®©ç”¨æˆ·è¾“å…¥æ˜ŸæœŸä¸€è‡³æ˜ŸæœŸæ—¥çš„æŸå¤©ï¼Œåˆ¤æ–­ç”¨æˆ·çš„è¾“å…¥æ˜¯å¦æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ˜ŸæœŸï¼Ÿ æ›´æ–°set: å¢åŠ å…ƒç´ æ˜¯s.add(â€˜Aâ€™), åˆ é™¤æ˜¯s.remove(â€˜Aâ€™), åˆ é™¤çš„å…ƒç´ ä¸åœ¨setä¸­ï¼Œremoveä¼šæŠ¥é”™ å®šä¹‰å¯å˜å‚æ•°å‡½æ•°ï¼š 123456def fn(*args): print argsfn() #() fn('a') #('a',)fn('a', 'b') #('a', 'b')fn(['a', 'b']) #(['a', 'b'],) enumerate å¾ˆæœ‰ç”¨çš„å‡½æ•°ï¼Œç”¨äºç´¢å¼•ã€è¿­ä»£ zip()å‡½æ•°å¯ä»¥æŠŠä¸¤ä¸ª list å˜æˆä¸€ä¸ª listï¼Œç±»ä¼¼äºè½¬ç½® 12zip([10, 20, 30], ['A', 'B', 'C'])# [(10, 'A'), (20, 'B'), (30, 'C')] åˆ—è¡¨ç”Ÿæˆå¼ï¼š 1234[x * x for x in range(1, 3)] #[1, 4, 9][x * x for x in range(1, 6) if x % 2 == 0] #[4, 16, 36][m + n for m in 'ABC' for n in '123'] #['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3']&#123;phone:i for i, phone in enumerate(set(y))&#125; æ­é…å­—å…¸å“¦ğŸ˜¯ å˜é‡å¯ä»¥æŒ‡å‘å‡½æ•°ï¼š 123456len=abs#len([1,2,3]) æŠ¥é”™print len(-5) #5 è¯´æ˜å‡½æ•°åå°±æ˜¯æŒ‡å‘å‡½æ•°çš„å˜é‡def g(a,b,f): #é«˜é˜¶å‡½æ•°ï¼ˆå¯ä»¥æ¥å—å‡½æ•°çš„å‡½æ•°ï¼‰ return f(a)+f(b)print g(-3,6,abs) #9 mapå‡½æ•°ï¼ˆåŒMathematicaçš„Mapï¼‰ï¼šmap(lambda i:i**2, [1, 2, 3]) #å¾—åˆ°[1, 4, 9] reduceå‡½æ•°ï¼ˆç±»ä¼¼Mathematicaçš„Foldï¼‰ï¼š 12reduce(lambda i,j:i+j, [1,2,3],10) #16 Fold[#1 + #2 &amp;, 10, &#123;1, 2, 3&#125;]reduce(lambda i,j:i+j, [1,2,3]) #6 Fold[#1 + #2 &amp;, &#123;1, 2, 3&#125;] filterå‡½æ•°ï¼ˆç±»ä¼¼Mathematicaçš„Select ï¼š 123filter(lambda i:i%2==0, range(10)) #[0, 2, 4, 6, 8] filter(lambda str:str and str.strip()&gt;0, [&apos;test&apos;, None, &apos;&apos;, &apos;str&apos;, &apos; &apos;, ...: &apos;END&apos;])#è¾“å‡º[&apos;test&apos;, &apos;str&apos;, &apos;END&apos;] sortedå‡½æ•°å¯ä»¥ç”¨æ¥æ’åº: 123456sorted([1,5,2,5,9]) #è¾“å‡º[1, 2, 5, 5, 9] sorted([1,5,2,5,9],lambda i,j:cmp(j,i)) #è¾“å‡º[9, 5, 5, 2, 1] sorted([1,5,2,5,9],lambda i,j:cmp(i,j)) #è¾“å‡º[1, 2, 5, 5, 9]# Applicationa = ['5_3','2_6','4_9','2_1']sorted(a, key = lambda i: (i.split('_')[0], i.split('_')[1])) è¿”å›å‡½æ•°çš„å‡½æ•° 1234567def calc_prod(lst): def lazy_prod(): return reduce((lambda x,y: x*y),lst) return lazy_prodf = calc_prod([1, 2, 3, 4])print f() é—­åŒ…ï¼š 12345678910def count(): fs = [] for i in range(1, 4): def f(): return i fs.append(f) print fs return fsf1, f2, f3 = count() #f1() f2() f3() éƒ½æ˜¯3 çº¯å‡½æ•°å†…åŠ å…¥æ¡ä»¶åˆ¤æ–­lambda x: -x if x &lt; 0 else x é¢å‘å¯¹è±¡ç¼–ç¨‹ åˆå§‹åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨é”®å€¼å¯¹ï¼š 12345678910class Person(object): def __init__(self, name, gender, birth, **kw): self.name = name self.gender = gender self.birth = birth for k, v in kw.iteritems(): setattr(self, k, v)xiaoming = Person('Xiao Ming', 'Male', '1990-1-1', job='Student')print xiaoming.name #Xiao Mingprint xiaoming.job #Student decoratorè£…é¥°å™¨ 123456789101112131415161718192021def f1(x): return x*2 def decorator(f): def fn(x): print 'Using decorator...\ncall ' + f.__name__+ '()' return f(x) return fn f1 = decorator(f1) print f1(5) @decorator def f2(x): return x*x print f2(5)#æ‰“å°å‡ºäº†ï¼š#Using decorator... #call f1() #10 #Using decorator...#call f2()#25 ç¼–å†™æ— å‚æ•°çš„decoratorè£…é¥°å™¨ç”¨äºè®°å½•å‡½æ•°è¿è¡Œæ•ˆç‡ï¼š 12345678910111213141516import timedef performance(f): def fn(*args, **kw): t1 = time.time() r = f(*args, **kw) t2 = time.time() print 'call %s() in %fs' % (f.__name__, (t2 - t1)) return r return fn@performancedef factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10)#call factorial() in 0.000005s #3628800 åå‡½æ•°ï¼š 12345import functoolssorted_ignore_case = functools.partial(sorted, cmp=lambda s1, s2: cmp(s1.upper(), s2.upper()))print sorted_ignore_case(['bob', 'about', 'Zoo', 'Credit'])#ç¬¬ä¸€ä¸ªcmpæ˜¯sortedå‡½æ•°å‚æ•°ä¸­çš„ä¸€ä¸ªé”®#è¾“å‡º['about', 'bob', 'Credit', 'Zoo'] å¾—åˆ°å…ƒç´ ä½ç½®çš„indexå‡½æ•°ï¼šindex() å‡½æ•°ç”¨äºä»åˆ—è¡¨ä¸­æ‰¾å‡ºæŸä¸ªå€¼ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹çš„ç´¢å¼•ä½ç½®ã€‚æ‰€ä»¥lis.index(min(lis))å¯ä»¥å¾—åˆ°æœ€å°å€¼çš„ç´¢å¼•ï¼Œnumpy.argminå…¶å®å°±æ˜¯å¹²è¿™ä¸ªçš„ å‡½æ•°å¼æ±‚å‡ºåŒä¸€ç±»çš„ä¸ªæ•°ï¼šmmaä»£ç 1&#123;1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4&#125; // Counts // Values pythonä½¿ç”¨è¿­ä»£å™¨å‡½æ•°123from itertools import groupbya = [1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4][len(list(group)) for key, group in groupby(a)] ç´¯åŠ å‡½æ•°python3123456from itertools import accumulatelist(accumulate(range(10)))#[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]import operatorlist(accumulate(range(1,5), operator.mul))#[1, 2, 6, 24] æ˜“é”™ç‚¹ type(round(12.3))æ˜¯floatç±»å‹ x[a:a+N]å®é™…ä¸Šxçš„é•¿åº¦å°±æ˜¯N x[:a]+x[a:]==x 0 % N == 0.0 (N != 0) æ™®é€šæ•°ç»„æ˜¯åœ°å€ä¼ é€’1234567import numpy as npa = np.arange(10)b = a[3:6]b[2] = 1000# aç«Ÿç„¶è¢«bæ”¹å˜äº†ï¼Œæ³¨æ„print "a is "+ str(a) #a is [ 0 1 2 3 4 1000 6 7 8 9] print "b is "+ str(b) #b is [ 3 4 1000] pythonç³»ç»Ÿç®¡ç†ç›¸å…³æŸ¥çœ‹pythonå®‰è£…ç›®å½•123import syspath = sys.executableprint(path) pipå‡çº§åŒ…pip install --pre mxnet-cu80 --upgrade ç¬¬ä¸‰æ–¹åº“scipyåŒ…æ‹¬fft,fftshift,çª—å‡½æ•°ç­‰ä¿¡å·å¤„ç†ç®—æ³• Numpyå¤æ•°è®¡ç®—X=np.array([1-1j, 1+0.000000000000001j, 4+9j],dtype=complex)X.realå¾—åˆ°å®éƒ¨ X.imagå¾—å¸¦è™šéƒ¨X.imag[np.abs(X.imag)&lt;0.1]ç­›é€‰å‡ºç¬¬äºŒä¸ªå…ƒç´ np.unwrap(np.angle(X))å¯ä»¥è§£å·ç»•Xçš„ç›¸ä½ ç´¢å¼•ä¸€èˆ¬ç´¢å¼•a=np.zeros((3,4))a[:,1:3] å¾—åˆ°çš„æ˜¯32çš„çŸ©é˜µa[:,[1]] å¾—åˆ°çš„æ˜¯31çš„çŸ©é˜µa[:, 1 ] å¾—åˆ°çš„æ˜¯(3,)çš„æ•°ç»„ æ ¹æ®æ¡ä»¶ç´¢å¼•ç¬¦åˆæ¡ä»¶åˆ™xå¦åˆ™yAPI:numpy.where(condition[, x, y])1np.where([[True, False], [True, True]], [[1, 2], [3, 4]], [[9, 8], [7, 6]]) array([[1, 8], [3, 4]]) åªæœ‰æ¡ä»¶çš„è¯è¿”å›condition.nonzero() 12x = np.arange(9.).reshape(3, 3)np.where( x &gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) 1x[np.where( x &gt; 3.0 )] # Note: result is 1D. array([ 4., 5., 6., 7., 8.]) 1np.where(x &lt; 5, x, -1) # Note: broadcasting. array([[ 0., 1., 2.], [ 3., 4., -1.], [-1., -1., -1.]]) åˆ é™¤æŸä¸€ç»´åº¦æ•°æ®np.delete(arr, 1, axis=0)12arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])np.delete(arr, 1, 0) array([[ 1, 2, 3, 4], [ 9, 10, 11, 12]]) np.delete(arr, np.s_[::2], 1) ç”¨np.s_æ„é€ ç´¢å¼• array([[ 2, 4], [ 6, 8], [10, 12]]) np.delete(arr, [1,3,5], None) array([ 1, 3, 5, 7, 8, 9, 10, 11, 12]) allå‡½æ•°1234a=np.arange(-3,3)np.all(abs(a)&lt;5) #Truea=np.arange(-3,6)np.all(abs(a)&lt;5) #False æ›´æ”¹æ•°æ®ç±»å‹astypeå‡½æ•°å¦‚a.astype(np.int32) æ™®é€šæ•°ç»„ä¸numpyæ•°ç»„äº’è½¬12np.arange(3).tolist() #to listnp.asarray([0,1,2]) #to numpy axisçš„ç†è§£123456789a=np.arange(20).reshape(2,10) a.sum(axis=0) #array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])np.diff(a,axis=0) #å¾—åˆ°array([[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]]) a.sum(axis=1) #array([ 45, 145])#axis=0æŠŠåˆ—å½“åšæˆå¯¹å¤„ç†çš„å¯¹è±¡#axis=1æŠŠè¡Œå½“åšæˆå¯¹å¤„ç†çš„å¯¹è±¡ å¹¿æ’­æœºåˆ¶1234np.array([1,2])*np.array([3,4]) #np.array([3,8]) è¡Œå‘é‡çš„å†…ç§¯ np.array([1,2])*np.array([[3,4],[5,6]]) #np.array([[3,8],[5,12]]) è¡Œå‘é‡ä¹˜ä»¥çŸ©é˜µ np.array([1,2]).reshape(-1,1)*np.array([[3,4],[5,6]]) #np.array([[3,4],[10,12]]) åˆ—å‘é‡ä¹˜ä»¥çŸ©é˜µ np.array([[1,2],[3,4]])*np.array([[5,6],[7,8]]) #çŸ©é˜µçš„ç‚¹ä¹˜ Element-wisenp.less([1, 2], [2, 2])è¿”å›array([True, False], dtype=bool) è¡Œå‘é‡åˆ—å‘é‡çš„è½¬åŒ–12345np.array([1, 2, 3, 4]).reshape((-1, 1)) # &lt;--- THIS IS THE TRICKnp.array([[5, 4]]).Tnp.array([10,20,30]).shape #(3,) å‘é‡np.array([[10,20,30]]).shape #(1,3) è¡Œå‘é‡ å‡½æ•°å¼ç¼–ç¨‹Outer 123m=np.arange(5);n=np.arange(5);a=np.subtract.outer(m,n) #ç»“æœå’Œmmaä¸€æ · Inner 123a = np.arange(12).reshape((4,3))b = [0,1,2,3]np.inner(a, b) #array([ 5, 14, 23, 32]) ç»“æœåŒMMA æ‹¼æ¥æ ‡å‡†æ•°å­¦å½¢å¼çš„æ‹¼æ¥æŒ‰åˆ—æ‹¼æ¥åŒ…æ‹¬å‘é‡æ‹¼å‘é‡ å‘é‡æ‹¼çŸ©é˜µ çŸ©é˜µæ‹¼çŸ©é˜µ123456a = np.array([1, 2, 3])b = np.array([2, 3, 4])c = np.vstack((a,b))print c #array([[1, 2, 3], [2, 3, 4]])print np.vstack((a,c)) #array([[1 2 3], [1 2 3], [2 3 4]])print np.vstack((c,c)) #array([[1 2 3], [2 3 4], [1 2 3], [2 3 4]]) æŒ‰è¡Œæ‹¼æ¥åŒ…æ‹¬å‘é‡æ‹¼å‘é‡ å‘é‡æ‹¼çŸ©é˜µ çŸ©é˜µæ‹¼çŸ©é˜µ123456a = np.array([[1], [2], [3]])b = np.array([[2], [3], [4]])c = np.hstack((a,b))print c #array([[1, 2], [2, 3], [3, 4]])print np.hstack((a,c)) #array([[1, 1, 2], [2, 2, 3], [3, 3, 4]])print np.hstack((c,c)) #array([[1, 2, 1, 2], [2, 3, 2, 3], [3, 4, 3, 4]]) ä»¿matlabå¼æ‹¼æ¥123456a = np.array([[1, 2], [3, 4]])b = np.array([[5, 6]])np.concatenate((a, b), axis=0)#array([[1, 2], [3, 4], [5, 6]])np.concatenate((a, b.T), axis=1)#array([[1, 2, 5], [3, 4, 6]]) å¤šä¸ªnumpyæ•°ç»„çš„æ‹¼æ¥12np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]#array([[1, 2, 3, 0, 0, 4, 5, 6]]) æ•°æ®çš„å¡«å……12a = [1, 2, 3, 4, 5]np.lib.pad(a, (2, 3), 'edge') array([1, 1, 1, 2, 3, 4, 5, 5, 5, 5]) 12a = [[1, 2], [3, 4]]np.lib.pad(a, ((3, 2), (2, 3)), 'minimum') array([[1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [3, 3, 3, 4, 3, 3, 3], [1, 1, 1, 2, 1, 1, 1], matplotlibåº“ç­‰å€¼çº¿å›¾ ContourPlot12345678910111213141516%matplotlib inlineimport matplotlib.pylab as plt def f(x,y): z = (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) return z n = 256 x = np.linspace(-1,1,n)y = np.linspace(-1,1,n)X,Y = np.meshgrid(x,y) fig = plt.figure()surf1 = plt.contourf(X, Y, f(X,Y))fig.colorbar(surf1) ä¸‰ç»´å›¾ Plot3D123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure()ax = Axes3D(fig)# X, Y valueX = np.arange(-4, 4, 0.25)Y = np.arange(-4, 4, 0.25)X, Y = np.meshgrid(X, Y) # x-y å¹³é¢çš„ç½‘æ ¼Z = np.sin(np.sqrt(X ** 2 + Y ** 2))ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('rainbow')) æŸ±çŠ¶å›¾1234567891011import matplotlib.pyplot as pltimport numpy as npmu, sigma = 100, 15x = mu + sigma * np.random.randn(10000)hist, bins = np.histogram(x, bins=30)width = 0.9 * (bins[1] - bins[0])center = (bins[:-1] + bins[1:]) / 2plt.bar(center, hist, align='center', width=width)plt.show() å…¶ä»–å¯è§†åŒ–åº“ Seabornï¼šSeabornè·Ÿmatplotlibæœ€å¤§çš„åŒºåˆ«å°±æ˜¯å®ƒçš„é»˜è®¤ç»˜å›¾é£æ ¼å’Œè‰²å½©æ­é…éƒ½å…·æœ‰ç°ä»£ç¾æ„Ÿã€‚ç”±äºSeabornæ˜¯æ„å»ºåœ¨matplotlibçš„åŸºç¡€ä¸Šçš„ï¼Œä½ éœ€è¦äº†è§£matplotlibä»è€Œæ¥è°ƒæ•´Seabornçš„é»˜è®¤å‚æ•°ã€‚ ä¸è¦ç”¨Bokehå’Œggplot2ï¼Œå‰ä¸€ä¸ªè¯­æ³•å…¼å®¹ä¸å¥½ï¼Œæ™¦æ¶©éš¾æ‡‚ï¼Œåä¸€ä¸ªä½œè€…å¼ƒå‘äº†ä¸”bugå¤š pygalè¶…ç¾ä¸½ï¼Œè¯­æ³•è¶…ç®€å•ï¼Œå¯ä»¥ç›´æ¥è¾“å‡ºSVGçš„Tooltipå½¢å¼çš„çŸ¢é‡å›¾ï¼Œä½†æ˜¯åªèƒ½è¾“å‡ºSVGæ ¼å¼æ–‡ä»¶ä¸èƒ½ç›´æ¥çœ‹å›¾çš„æ•ˆæœ plotlyå¾ˆç¾ï¼Œä¹Ÿæ˜¯ç¥å™¨ä¹‹ä¸€ï¼è‡´åŠ›äºäº¤äº’å›¾è¡¨çš„åˆ¶ä½œï¼Œä½†æ˜¯å®ƒæä¾›åœ¨åˆ«çš„åº“ä¸­å¾ˆéš¾æ‰¾åˆ°çš„å‡ ç§å›¾è¡¨ç±»å‹ï¼Œæ¯”å¦‚ç­‰å€¼çº¿å›¾ï¼Œæ ‘å½¢å›¾å’Œä¸‰ç»´å›¾è¡¨ã€‚å¦‚ä½•ç¦»çº¿ä½¿ç”¨å‚è§Here! ç¾ç¾å“’~ä½†æ˜¯ç”±äºæˆ‘å¾ˆç†Ÿæ‚‰Mathematicaï¼Œä½œå›¾åŸºæœ¬ä¸Šå°±æ˜¯é å¥¹äº†ã€‚å¦‚æœæ˜¯åŠ¨æ€å›¾ï¼Œæˆ‘ä½¿ç”¨JavaScriptå’ŒD3ã€‚ å¯è§†åŒ–å¤§è§„æ¨¡æ•°æ®é›†çš„åº“ Datashaderå®‰è£…conda install -c bokeh datashader 12345678import datashader as dsimport datashader.transfer_functions as tfimport pandas as pddf = pd.read_csv(&apos;user_data.csv&apos;)cvs = ds.Canvas(plot_width=400, plot_height=400)agg = cvs.points(df, &apos;x_col&apos;, &apos;y_col&apos;, ds.mean(&apos;z_col&apos;))img = tf.shade(agg, cmap=[&apos;lightblue&apos;, &apos;darkblue&apos;], how=&apos;log&apos;) åœ¨Jupyterä¸­ç”»å›¾3Dæ•£ç‚¹å›¾12345678910111213%matplotlib notebookfrom matplotlib import pyplotfrom mpl_toolkits.mplot3d import Axes3Dimport randomfig = pyplot.figure()ax = Axes3D(fig)sequence_containing_x_vals = X[:, 0].asnumpy()sequence_containing_y_vals = X[:, 1].asnumpy()sequence_containing_z_vals = y.asnumpy()ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)pyplot.show() æ˜¾ç¤ºå›¾åƒ123%matplotlib inlineimport matplotlib.pyplot as pltplt.imshow(image_data) æ“ä½œç³»ç»Ÿåº“ os è°ƒç”¨ç³»ç»Ÿcmdçš„lsç¨‹åºæ‰“å°å½“å‰ç›®å½•ï¼Œå¹¶ä¸”è¿”å›æ˜¯å¦æˆåŠŸï¼ˆ0å³ä¸ºæˆåŠŸï¼‰os.system(&#39;ls&#39;) os.mkdir(path)å‡½æ•°åˆ›å»ºç›®å½•ï¼ˆåˆ›å»ºä¸€çº§ç›®å½•) os.makedirs(path)å‡½æ•°åˆ›å»ºå¤šçº§ç›®å½• os.listdir(path)å¯ä»¥å¾—åˆ°ä¸€ä¸ªåŒ…å«å½“å‰ç›®å½•ä¸‹æ–‡ä»¶å’Œå­ç›®å½•çš„Liståˆ—è¡¨ï¼ˆä½†æ˜¯æ˜¯ä¹±åºçš„ï¼Œéœ€è¦sortedï¼‰ os.walk() æ–¹æ³•ç”¨äºé€šè¿‡åœ¨ç›®å½•æ ‘ç§æ¸¸èµ°è¾“å‡ºåœ¨ç›®å½•ä¸­çš„æ–‡ä»¶åï¼Œå‘ä¸Šæˆ–è€…å‘ä¸‹ os.path.split ç”¨äºåˆ†å‰²è·¯å¾„ä¸ºç›®å½•è·¯å¾„å’Œä¸å¸¦åç¼€çš„æ–‡ä»¶å os.path.split å¾—åˆ°ä¸å¸¦åç¼€çš„æ–‡ä»¶å æ˜¾ç¤ºè¿›åº¦æ¡12345678from time import sleepfrom tqdm import tqdmfor i in tqdm(range(100)): sleep(0.01) #ä¹Ÿå¯ä»¥ç”¨äºè¿­ä»£å™¨ ä½†æ˜¯è¦ä¼ totalå‚æ•°å‘Šè¯‰å®ƒè¿­ä»£å™¨çš„å¤§å°for index, batch in tqdm(enumerate(dataiter),total=num_examples/batch_size,unit="mini-batchs"): pass print(&quot;Epoch %d&quot; % epoch)å¯ä»¥æ”¹ä¸ºtqdm.write(&quot;Epoch %d&quot; % epoch) æ‰¾åˆ°æŸä¸€åç¼€çš„æ–‡ä»¶ globåº“12import globprint glob.glob("./source/*.cpp") é€’å½’æŸ¥æ‰¾å¯ä»¥ç”¨glob2åº“,æ³¨æ„ä½¿ç”¨äº† **12import glob2print glob2.glob("./source/**/*.cpp") h5pyä½¿ç”¨æŒ‡å—è¯»å–h5æ–‡ä»¶12345678import h5pyf = h5py.File('test_data_SE.h5', 'r')f.keys()#[u'Input', u'Output']f['Input']#&lt;HDF5 dataset "Input": shape (1681, 2), type "&lt;f8"&gt;f['Input'][:] #å¾—åˆ°æ‰€æœ‰æ•°æ®f.close() å¤šè¿›ç¨‹å’Œå¤šçº¿ç¨‹åº“1234567891011121314151617181920212223import multiprocessingimport osdef square(x): return x*x def Run(cmd): assert(os.system(cmd)==0)def ParallelFunction(func,argList,threads=5): if threads&gt;multiprocessing.cpu_count(): threads=multiprocessing.cpu_count() pool = multiprocessing.Pool(processes=threads) res=pool.map(func, argList) pool.close() return res def ParallelRun(cmds,threads=5): ParallelFunction(Run,cmds,threads=threads)if __name__ == '__main__': print ParallelFunction(square,range(10)) ParallelRun(['time','dir']) ç®€å•ç¤ºä¾‹ ï¼ˆç»“åˆæ·±åº¦å­¦ä¹ ï¼‰åˆ›å»ºä¸€ä¸ªè¾“å…¥ï¼Œä¸€ä¸ªè¾“å‡ºçš„çš„ç½‘ç»œæ‰€éœ€çš„hdf5æ–‡ä»¶ æ–°ç‰ˆ12345678910111213141516171819202122232425import numpy as npimport h5pyimport mxnet as mxN = 1000X = np.random.normal(0, 1, (N, 12))y = np.random.randint(0, 2, N)# write data to filewith h5py.File('myfile.hdf5', "w") as ofile: ofile.create_dataset("X", data=X) ofile.create_dataset("y", data=y)# load data from fileifile = h5py.File('myfile.hdf5', 'r')X_h5 = ifile["X"]y_h5 = ifile["y"]batch_size = 200dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size)for iBatch, batch in enumerate(dataiter): print(iBatch, batch.data[0].asnumpy().shape)ifile.close() æ—§ç‰ˆ12345678910111213141516171819202122232425262728import osimport h5pyimport numpy as npimport structimport randomfloat_size=4input_node=2output_node=1input_file='test_data_SE.dat'out_file='test_data_SE.h5'input_and_output_node=input_node+output_nodewith open(input_file,'rb') as f: f.seek(0,os.SEEK_END) file_len=f.tell()/(float_size*input_and_output_node)with h5py.File(out_file, "w") as f: Input = f.create_dataset('Input', (1681,input_node ),dtype='float', chunks=True) Output = f.create_dataset('Output', (1681,output_node),dtype='float', chunks=True) fin=open(input_file,'rb') index=range(file_len) random.shuffle(index) for i in index: fin.seek(float_size*input_and_output_node*i,os.SEEK_SET) Input[i,:] = np.array(struct.unpack('&lt;'+str(input_node )+'f',fin.read(float_size*input_node))) Output[i,:] = np.array(struct.unpack('&lt;'+str(output_node)+'f',fin.read(float_size*output_node))) fin.close() Pythonå°å·¥å…·æ£€æŸ¥é¡¹ç›®ä»£ç memcpyæ˜¯å¦éƒ½åŒ…å«äº†sizeofä½¿ç”¨äº†glob2åº“ è¿™ä¸ªç›¸æ¯”globä¸ä»…å¯ä»¥æ‰¾åˆ°ç›®å½•ä¸‹çš„ç‰¹å®šåç¼€æ–‡ä»¶è¿˜å¯ä»¥é€’å½’æŸ¥è¯¢å®ƒçš„å­ç›®å½•ä¸‹çš„æ–‡ä»¶1234567891011import glob2files=glob2.glob("./source/**/*.cpp")for file in files: num=0 for line in open(file,'rt'): num=num+1 line=line.strip() if line.startswith('memcpy'): if('sizeof' not in line): print line+'\t\t'+file+'\t'+str(num) å¯ä»¥æ˜¾ç¤ºè¡Œ æ–‡ä»¶å è¡Œå·ï¼Œæ•ˆæœè¿˜æ˜¯ä¸é”™çš„ï¼Œå› ä¸ºå¯ä»¥è‡ªå®šä¹‰å‘€~ å¯¼å…¥å¯¼å‡ºæ•°æ®è¯»å–æ–‡æœ¬æ•°æ®np.loadtxtå¿½ç•¥é¦–è¡Œï¼Œæ•°æ®æ˜¯æµ®ç‚¹æ•°np.loadtxt(&#39;test.txt&#39;,dtype=float,skiprows=1)è¯»å–ç‰¹å®šçš„åˆ—ä½¿ç”¨å‚æ•°usecols,å¤šåˆ—æ˜¯usecols=(1,3)ï¼Œå•åˆ—æ˜¯usecols=(3,) np.genfromtxtåªè¯»å–ç¬¬ä¸€ä¸‰åˆ—æµ®ç‚¹æ•°æ®ä¸”å¿½ç•¥é¦–è¡Œnp.genfromtxt(&#39;test.txt&#39;,dtype=float,usecols=(1,3),skip_header=1) è¯»å–äºŒè¿›åˆ¶æ•°æ®123456789101112#é€Ÿåº¦æ…¢data=np.array(struct.unpack('&lt;'+str(lis_len)+'f',fin.read()))#é€Ÿåº¦å¿«data = np.fromfile(datafile,dtype=np.float32)#ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨è¿™ç¬¬äºŒç§å¿«é€Ÿè¯»å–çš„æ–¹å¼ï¼Œå®šä¹‰å¦‚ä¸‹å‡½æ•°def BinaryRead(datafile,column): data = np.fromfile(datafile,dtype=np.float32) LengthOfFile=len(data) assert(LengthOfFile) assert((LengthOfFile%column)==0) data.shape = [LengthOfFile/column,column] return data å¯¼å‡ºå­—å…¸ï¼ˆä½¿ç”¨JSONï¼‰æ‰“å°åˆ°å±å¹•indentå¯ä»¥æ§åˆ¶ç¼©è¿›å•ä½ï¼Œç¾åŒ–JSONç”¨çš„print json.dumps(mydict, indent=2)è¾“å‡ºåˆ°æ–‡ä»¶12with open('Unit2Vec_tSNE.json', 'w') as outfile: json.dump(mydict, outfile, indent=2) å¯¼å‡ºå­—å…¸ï¼ˆä½¿ç”¨pickleï¼‰å¯ä»¥ä¿å­˜å­—å…¸ã€åˆ—è¡¨ã€numpyæ•°æ®ç­‰pickle.dump(æ•°æ®, æ–‡ä»¶ï¼Œ[ä½¿ç”¨åè®®])è¡¨ç¤ºå°†è¦æŒä¹…åŒ–çš„æ•°æ®ï¼Œä¿å­˜åˆ°æ–‡ä»¶ä¸­ï¼Œä½¿ç”¨åè®®æœ‰3ç§ï¼Œç´¢å¼•0ä¸ºASCIIï¼Œ1æ˜¯æ—§å¼2è¿›åˆ¶ï¼Œ2æ˜¯æ–°å¼äºŒè¿›åˆ¶åè®®ï¼Œä¸åŒä¹‹å¤„åœ¨äºåè€…æ›´é«˜æ•ˆä¸€äº›ã€‚é»˜è®¤çš„è¯dumpæ–¹æ³•ä½¿ç”¨ä½¿ç”¨åè®®0ã€‚1234567891011121314151617181920212223import pickleimport numpy as npdata1 = &#123;'a': [1, 2.0, 3, 4+6j], 'b': ('string', u'Unicode string'), 'c': None&#125;data2 = [1, 2, [3,4,5]]data3 = np.arange(5)with open('data.pkl', 'wb') as output_file: # Using -1 to make it more stable and less file size pickle.dump(data1, output_file, -1) pickle.dump(data2, output_file, -1) pickle.dump(data3, output_file, -1)with open('data.pkl', 'r') as input_fine: data4 = pickle.load(input_fine) data5 = pickle.load(input_fine) data6 = pickle.load(input_fine) print data4 print data5 print np.sum(data6) #0+1+2+3+4==10 Anacondaä½¿ç”¨å¤‡å¿˜å½•å®‰è£…ç¯å¢ƒconda create -n ç¯å¢ƒåconda create -n ç¯å¢ƒå python=3.6 åˆ é™¤ç¯å¢ƒconda remove -n ç¯å¢ƒå â€“all æŸ¥çœ‹æ‰€å¤„ç¯å¢ƒconda info -e å‡çº§Condaconda update conda è§£å†³é”™è¯¯å‡ºç°Intel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.soé”™è¯¯æ‰§è¡Œconda install nomklå°±å¯ä»¥äº†ã€‚åœ¨è®¡ç®—DTWç®—æ³•çš„åº“æ—¶é‡åˆ° è§£å†³h5pyçš„âš ï¸pip install numpy==1.13.0 æ‰¾ä¸åˆ°condaå¯¹äºLinux: å¦‚æœæœ€ç»ˆconda not found åªéœ€è¦ä¿®æ”¹~/.bashrc å¢åŠ  export PATH=â€/home/xzhou/anaconda2/bin:$PATHâ€,ç„¶åsource ~/.bashrcå°±è¡Œäº†å¯¹äºwindow: scriptsæ–‡ä»¶å¤¹è·¯å¾„ä½œä¸ºç¯å¢ƒå˜é‡ ipythonçš„ç¯å¢ƒä¸æ­£å¸¸å½“æ¿€æ´»ä¸€ä¸ªç¯å¢ƒå ipythonçš„sys.executableä¸å¯¹åŠ²åªéœ€è¦conda install ipythonè¿›è¡Œäº†Reactivate the environment or run hash -r (in bash) or rehash (in zsh). å°±è¡Œäº† Condaä¸èƒ½è”ç½‘æ³¨æ„å½“condaä¸èƒ½ç”¨æ—¶å¯ä»¥è€ƒè™‘ä½¿ç”¨æ‰‹æœºUSBå…±äº«ç½‘ç»œï¼Œä½†æ˜¯ä¸€å®šè¦å…³é—­å¾®è½¯è¾“å…¥æ³•ï¼Œä¸ç„¶ä¼šå¯¼è‡´è“å±ã€‚æœ€å¥½ç”¨4Gç½‘ç»œï¼Œæ›´æ–°é¡ºåˆ©ã€‚ä½¿ç”¨ç§‘å¤§é•œåƒ 12345678910# ä¼˜å…ˆä½¿ç”¨æ¸…å conda é•œåƒã€‚conda config --prepend channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/# æˆ–è€…é€‰ç”¨ç§‘å¤§ conda é•œåƒã€‚conda config --prepend channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes# ç§»é™¤é•œåƒconda config --remove channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ å¾…Checkå¦‚æœconda create -n test_env python=2.7 åˆ›å»ºå‡ºçš„ç¯å¢ƒå¹¶ä¸åœ¨envsé‡Œï¼Œé‚£ä¹ˆæ‰§è¡Œconda create â€“prefix /tmp/test-env python=2.7]]></content>
      <categories>
        <category>ç¼–ç¨‹</category>
      </categories>
      <tags>
        <tag>å¯è§†åŒ–</tag>
        <tag>Python</tag>
        <tag>MXNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å¤§è¿ä¹‹è¡Œ]]></title>
    <url>%2F2018%2F07%2F25%2F%E5%A4%A7%E8%BF%9E%E4%B9%8B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer-kWDFiZSw"), narrow: false, autoplay: false, showlrc: false, music: { title: "å•è½¦ç»ƒä¹ æ›²", author: "ç‹é›ç›Ÿ", url: "å•è½¦ç»ƒä¹ æ›².mp3", pic: "/2018/07/25/å¤§è¿ä¹‹è¡Œ/å•è½¦ç»ƒä¹ æ›².jpg", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 2018å¹´7æœˆ20æ—¥ å‘¨äº”ä¸Šåˆåç‚¹é£æœºï¼Œ11.40åˆ°è¾¾å¤§è¿ å‡¯å®æ¥æœºåœºæ¥æˆ‘ï¼Œä¸­åˆåƒäº†è’¸æ±½æµ·é²œï¼Œæµ·èƒ†æµ·èºæµ·å‚ã€‚ åƒå®Œé¥­æ‰“çš„å›å»ï¼Œå°±è¿è‰ä¹Ÿå’Œåˆè‚¥åˆ°ä¸åŒï¼Œä¸æ˜¯å±å±å±å«å¾ˆä¹…ï¼Œè€Œæ˜¯æ–­æ–­ç»­ç»­çš„ï¼Œä¹Ÿè®¸æ˜¯æ°”æ¸©ä¸åƒæˆ‘ä»¬è¿™é‡Œè¿™ä¹ˆç‚çƒ­å§ ä¸‹åˆä»æµ·å†›å¤§è¿èˆ°è‰‡å­¦é™¢å‡ºæ¥åæ²¿ç€æµ·è¾¹ä¸€ç›´èµ° å…ˆè·¯è¿‡è€è™æ»©(è€è™æŠ½è±¡çš„é›•å¡‘ä½äºå¹¿åœºæ­£ä¸­ï¼‰ æ¥ç€è·¯è¿‡äº†æ»¨æµ·è·¯è¿˜æœ‰åŒ—å¤§æ¡¥ï¼ŒæŠŠä»–å®¶å°ç‹—ç‰›ç‰›ä¹Ÿå¸¦å‡ºæ¥é›äº†ã€‚æ™šä¸Šæ‰¾äº†å®¶ä¸œåŒ—èœåƒï¼Œæœ‰ç‰¹è‰²èœç„–å­(å°±æ˜¯ç‚¸è¿‡çš„åœ°ç“œç²‰åšçš„) è¿˜æœ‰é”…åŒ…è‚‰(åƒèµ·æ¥åƒå¦é—¨çš„æ‹”ä¸ï¼Œé…¸ç”œå£çš„)ï¼Œéƒ½åƒä¸å®Œï¼Œåˆ†é‡å¾ˆè¶³ä¹Ÿä¸è´µã€‚åƒå®Œé¥­å»äº†ä¸œæ¸¯ï¼Œæœ‰éŸ³ä¹å–·æ³‰! è¿˜æœ‰æ¬§æ´²é£æƒ…è¡—æ¯”å¦‚å‡¯æ—‹é—¨å¨å°¼æ–¯å•¥çš„ï¼Œäººå¤´æ”’åŠ¨ 2018å¹´7æœˆ21æ—¥ å‘¨å…­æ—©æ™¨å»äº†åƒé²œè‚‰å°ç¬¼åŒ… ç”œå£çš„å¥½åƒäº›æ±Ÿæµ™å£å‘³ï¼Œé²œè™¾é¥ºå­ã€‚ä¹‹åå»åŒ—å¹¿åœºåè½¦å»æ—…é¡º,ä¸»è¦å»äº†ä¸¤ä¸ªæ™¯ç‚¹ä¸€ä¸ªæ˜¯æ—…é¡ºå†›æ¸¯ï¼Œä¸å¤§ï¼Œä½†æ˜¯æœ‰å¾ˆå¤šæµ·é¸¥ã€‚ å¦ä¸€ä¸ªæ˜¯æ—¥ä¿„æ—…é¡ºç›‘ç‹±ï¼Œä¸€ä¸ªçˆ±å›½ä¸»ä¹‰åŸºåœ°ï¼Œå¯çœ‹åˆ°å½“æ—¶ç›‘ç‹±æ¡ä»¶æ˜¯å¤šå·®ï¼ˆç›‘ç‹±å˜›ç…§ç‰‡å°±ä¸æ‹äº†ï¼‰ã€‚ å›å¸‚é‡Œå·²ç»æ˜¯ä¸‹åˆä¸‰ç‚¹ï¼Œæˆ‘åƒäº†é¡¿é“æ¿åçœ‹äº†ç”µå½±ã€Šé‚ªä¸å‹æ­£ã€‹ï¼Œä¹Ÿè®¸æ˜¯å–äº†å’–å•¡çš„åŸå› çœŸæ˜¯ç‰¹åˆ«æƒ³ä¸Šå•æ‰€å‘€ï¼Œè€Œä¸”å§œæ–‡çš„è¿™éƒ¨ç”µå½±å¾ˆéš¾æ‡‚ã€‚æ™šä¸Šå»äº†æ˜Ÿæµ·å¹¿åœºå’Œé™„è¿‘çš„æ²™æ»© æ™šä¸Šä»æ¸¸ä¹å›­å‡ºæ¥åå»äº†çƒ§çƒ¤åº—ï¼Œç¬¬ä¸€æ¬¡å¤§èƒ†ä»å®¹åƒèš•è›¹ï¼Œå¾ˆå¥½åƒï¼Œåªæœ‰å¾®å¾®è‹¦å‘³ï¼Œä¸­é—´ä¸€ä¸ªå°å¿ƒå¿ƒä¸èƒ½åƒã€‚ 2018å¹´7æœˆ22æ—¥ å‘¨æ—¥å»äº†è€è™æ»©æµ·æ´‹å…¬å›­è¿˜æœ‰é¸Ÿè¯­æ—ï¼Œæ„Ÿå—å°±æ˜¯æµ·æ´‹å…¬å›­é‡Œå¤´å¤ªé˜³é‚£ä¹ˆå¤§ï¼Œæåœ°åŠ¨ç‰©è¿˜è¦è¡¨æ¼”ä¹Ÿæ˜¯ä¸€ç§æŠ˜ç£¨ã€‚é¸Ÿè¯­æ—ä¸é”™ï¼Œå„ç§é¸Ÿå¯ä»¥å‡‘è¿‘ä½ ï¼Œå–‚äº†å®ƒä»¬å·§å…‹åŠ›é¢åŒ…ã€‚ è€è™æ»©å…¬å›­é‡Œçš„æ²™æ»©æ¯”æ˜Ÿæµ·å¹¿åœºçš„è½¯ï¼Œç™½å¤©èƒ½çœ‹è§ç»†é•¿çš„å°é±¼åœ¨æµ…æ»©å¤„ï¼ˆæ‰€ä»¥é’“é±¼æŠ“é±¼çš„éƒ½èƒ½è§åˆ°ï¼‰ ä¹‹åæˆ‘åˆå»è€è™æ»©å¹¿åœºäº†ï¼Œå–‚é£Ÿæµ·é¸¥ï¼ŒåŸºæœ¬ä¸Šåˆšå¼€å§‹éƒ½ä¸è¿‡æ¥éƒ½ç¦»æˆ‘å¾ˆè¿œåœ¨å¤©ä¸Šé£ï¼Œä¸è¿‡åªè¦è±¡å¾æ€§çš„æ’’å‡ æ¬¡ï¼Œæµ·é¸¥éƒ½è¿‡æ¥äº†ï¼Œä»–ä»¬ç©ºä¸­æ¥é£Ÿå¾ˆå‰å®³ã€‚ç„¶åå»è§äº†å‡¯å®æœ‹å‹ä¸€èµ·åƒäº†é¥­å–äº†ç‚¹é…’ï¼Œæ™šä¸Šå»äº†å‡¯å®å®¶åƒçš„é¥­ï¼Œé¥­èœä¸»æ‰“æµ·é²œï¼Œä½†æ˜¯åƒä¸æ‰æœ‰äº›å¤šï¼Œç¬¬ä¸€æ¬¡åƒçŸ¥äº†çŒ´ï¼Œå‘³é“ä¸é”™å“¦ï¼Œé«˜è›‹ç™½ï¼Œåˆ«äººéƒ½æ˜¯æŠŠçŸ¥äº†å½“ä¸»é£Ÿåƒã€‚ å‚æ™šèµ°åœ¨è€è™æ»©çš„æµ·è¾¹å¤§é“ä¸Šä¸€ç§å¤æ—¥çš„å®é™ã€‚ æ™šä¸Šåœ¨å¤§é™¢æ•£æ­¥æ˜¯å‡¯å®ä¸çŸ¥æ€ä¹ˆè¯´åˆ°äº†æ³•å›½å¯¹åº”äºä¸­å›½éš¾å¿˜æ˜¥å®µçš„æ›²å­æ˜¯Les demons De Minuitï¼ŒäºŒä¸‰åå¹´çš„è€æ­Œï¼Œæ¯å½“ä»€ä¹ˆæ´»åŠ¨å¤§å®¶å°±å”±è¿™ä¸ªï¼Œæ‰€ä»¥ä»–ä¹Ÿé¡ºä¾¿å­¦å­¦ã€‚èŠ‚å¥æ„Ÿå¾ˆå¥½å¬ æ¥ç€å°±å¤–æ”¾ç€è¿™é¦–æ­Œæ™šä¸Šå»äº†æ˜Ÿæµ·å¹¿åœºï¼Œé¡ºä¾¿ä¹Ÿè¸©æ²™æ»©äº†ï¼Œä¸è¿‡å¾ˆç¡Œè„šã€‚ æ™šä¸Šçš„æ˜Ÿæµ·æ¹¾å¤§æ¡¥å¼€ç¯äº†ï¼Œå¾ˆé•¿ï¼Œæ‰“é€šäº†å¼€å‘åŒºä¸æ˜Ÿæµ·å¹¿åœºçš„è·ç¦»ã€‚ 2018å¹´7æœˆ23æ—¥ å‘¨ä¸€ä»Šå¤©æ—©ä¸Šéšä¾¿åƒäº†ä¸€ç‚¹åå°±å…ˆå»äº†é€ èˆ¹å‚çœ‹åˆ°äº†è¾½å®å·èˆªç©ºæ¯èˆ°ï¼Œåªèƒ½è¿œæœ› å»äº†é‡‘çŸ³æ»©å…¬å›­ï¼Œåšè½»è½¨3å·çº¿èŠ±äº†ä¸€ä¸ªå°æ—¶(8å…ƒ)æ‰åˆ°ï¼Œå¤Ÿè¿œçš„ã€‚ä¸­åˆåƒäº†è‚¯å¾·åŸºï¼Œç›´æ¥åè½¦(20å…ƒ)ååˆ°äº†åœ°è´¨å…¬å›­å…¥å£å¤„ã€‚ç„¶åå°±åˆèµ°å›äº†ä¸‰å·çº¿ç»ˆç‚¹ï¼Œä¸€è·¯ä¸Šé£æ™¯å¾ˆå¥½ï¼Œéƒ½æ˜¯ç¤çŸ³æµ·æ»©ï¼Œç©¿è¡Œåœ¨æ—é—´æ„Ÿè§‰ç‰¹åˆ«ä¸é”™ã€‚ å°±æ˜¯å¤ªçƒ­äº†æˆ‘ä»¬æŠŠè¡£æœå¥—å¤´ä¸Šï¼Œå¥½ä¸€å‰¯æ²™ç‰¹ç‹å­çš„æ ·å­ã€‚ä¸‹åˆä¹°äº†æ°´ç‰¹äº§ï¼Œè¿˜çœ‹åˆ°äº†é³é±¼ æ™šä¸Šåƒäº†é²…é±¼é²œé¥ºç­‰ï¼Œè¿™æ˜¯åŒ—æ–¹ç‰¹äº§ï¼ˆå¬è¯´å±±ä¸œäººä¹Ÿçˆ±åƒï¼‰ 2018å¹´7æœˆ24æ—¥ å‘¨äºŒåé£æœºå›åˆè‚¥]]></content>
      <categories>
        <category>æ—…è¡Œ</category>
      </categories>
      <tags>
        <tag>å¤§è¿</tag>
      </tags>
  </entry>
</search>
