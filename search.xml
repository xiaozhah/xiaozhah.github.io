<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[语音合成工具]]></title>
    <url>%2F2018%2F09%2F15%2F%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[生成上下文信息 linguistic features根据fulllab文件夹和questions属性问题集回答得到linguistic，每个音句一个文件存储在fulllab_answers中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101$| = 1;$labdir = "./labels/fulllab";$que = "./edfiles/questions/questions.hed";$outdir = "./edfiles/questions/fulllab_answers";opendir DIR, $labdir;$i = 1;Get_Ques2Regular($que);foreach $_ ( readdir DIR ) &#123; if (/(.*)\.lab/) &#123; $filename = $1; print $filename, "\t", "$i\n"; $i++; $lab = sprintf("$labdir/$filename.lab"); $out = sprintf("$outdir/$filename.dat"); feature( $lab, $que, $out ); &#125;&#125;closedir DIR;sub Get_Ques2Regular&#123; open( question, "&lt;@_[0]" ) or die "questions.hed can't be open"; %Ques2Regular; while ( $line_question = &lt;question&gt; ) &#123; if ( $line_question eq "\n" ) &#123; next; &#125; else &#123; if ( $line_question =~ /\&#123;(.*)\&#125;/ ) &#123; @phoneall = split( /,/, $1 ); &#125; foreach $phoneone (@phoneall) &#123; $original_phoneone = $phoneone; $phoneone =~ s/\*/\.\*/g; #(*-&gt;.*) $phoneone =~ s/\?/\./g; #(?-&gt;. ) $phoneone =~ s/\$/\\\$/g; #($-&gt;\$) $phoneone =~ s/\@/\\\@/g; #(@-&gt;\@) $phoneone =~ s/\+/\\\+/g; #(+-&gt;\+) $phoneone =~ s/\|/\\\|/g; #(|-&gt;\|) $phoneone =~ s/\^/\\\^/g; #(^-&gt;\^) #(^-&gt;\^) add ^ in the beginning of the line if there is a character $phoneone =~ s/^([a-z])/\^$1/; $Ques2Regular&#123;$original_phoneone&#125; = $phoneone unless exists $Ques2Regular&#123;$original_phoneone&#125;; &#125; &#125; &#125; close(question);&#125;sub feature &#123; open( label, "&lt;@_[0]" ) or die "00000001.lab can't be open"; open( question, "&lt;@_[1]" ) or die "questions.hed can't be open"; open( output, "&gt;@_[2]" ) or die "output.txt is null"; binmode output; while ( $line_label = &lt;label&gt; ) &#123; seek question, 0, 0; while ( $line_question = &lt;question&gt; ) &#123; if ( $line_question eq "\n" ) &#123; next; &#125; else &#123; if ( $line_question =~ /\&#123;(.*)\&#125;/ ) &#123; @phoneall = split( /,/, $1 ); &#125; $temp = 0; foreach $phoneone (@phoneall) &#123; $phoneone = $Ques2Regular&#123;$phoneone&#125;; if ( $line_label =~ /$phoneone/ ) &#123; #print "$phoneone\t$line_label\t$line_question\n"; $temp = 1; print output pack( "f", 1 ); last; &#125; &#125; if ( $temp == 0 ) &#123; print output pack( "f", 0 ); &#125; &#125; &#125; &#125; close(label); close(question); close(output);&#125; Stright工具]]></content>
      <categories>
        <category>语音</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[印度之行]]></title>
    <url>%2F2018%2F08%2F28%2F%E5%8D%B0%E5%BA%A6%E4%B9%8B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[即将飞往印度海得拉巴参加Interspeech2018会议，这个会议是语音语言方面的顶级会议。 这次提交的论文是基于单元挑选的语音合成，主要是通过Embedding(一个固定长向量)表示音素特征从而在路径搜索时可以给予代价函数更多的声学表示，并且改进连接代价有助于提升语音连续性，从而提升传统HMM方法的效果。可参见论文或海报 这个方法也被应用在今年的语音合成比赛Blizzard Challenge中，这个提升了系统的的合成表现力，不过造成了语音稳定性的轻微下降。相比较而言，提升占主要部分，可参见论文The USTC System for Blizzard Challenge 2018 2018年8月31日 周五合肥-&gt;广州广州一晚就住了3个小时，188元，真贵呀！ 2018年9月1日 周六广州-&gt;新德里新德里机场很漂亮，很现代化，各种设施都是国际标准飞机晚上是晚上八点多到的海得拉巴，飞机上的晚餐是传统的印度式餐，芹菜酱做的土豆泥，和合肥1912街区的塔吉餐厅类似，不过更辣一些，也不是国内的那种辣嘴的辣。还看到了双🌈，一个完整的圆形。海得拉巴机场也不错，佛教文化在这盛行，机场里有关于佛，瑜伽的雕塑和艺术品。不过在海得拉巴打的时直接坐在了副驾驶位，才发现这里是靠左行驶，原来是驾驶位尴尬。。。住的四星级酒店离HICC会议地点很近，是85美元一天，住的和国内的快捷酒店类似。不过因为买水走出酒店才发现，比想象的印度还要差，由于大雨下的很急，水往往无法通过下水道排走，全部漫在地上。城市市镇建设非常糟糕，没有人行道和机车道的概念，污水横流，井水外喷，公交车没有门随意上人，估计印度人已经习以为常。看来印度缺的不仅仅是啥《厕所英雄》，也缺下水道英雄。好在印度人比较乐观，也乐于助人，这是不是和信教分不开呢。卖完水就立刻回酒店了，睡觉~ 2018年9月2日 周日今天是Interspeech报道的第一天，上午就去领了会议册，论文集U盘，印度风格的包包，还有属于自己的代表牌等等（可以在Google Play上下载Interspeech2018 App,可以直接看论文） 中午在附近的mainland China吃中国菜,还蛮好吃不过风味还是和中国不完全一样，也不是印度风味，那可以说是混搭吧 下午去参观了葛康达古城遗迹。印度和中国的景点附件不一样，第一不是那种圈地收门票那种、景区外熙熙攘攘没有景点的感觉；第二门票价格不贵（相对于中国而不是印度本地人），300卢比大概30人民币；第三是景区不是分地区收费，而是整个景区就收300卢比，要是鸟巢嘛进去逛一圈一个钱，看天台又是一个钱。。。景区内部本地人比较多，大部分是断壁残垣，以前是皇帝的寝宫，虽然只有500多年但是历经风吹雨打，已经成为不复当时的盛景。但是在🇫🇷埃克斯住的也是500多年历史的房子，外表干净整洁，里面现代化设施俱全。印度🇮🇳还是发展中国家嘛不过海得拉巴这里变天特别快，瞬间就能下起大雨，我没打伞只好躲在岩石下，特别简陋的”雨棚“呀。雨停了还是阴天就接着上山，路上还是挺泥泞的，鞋子上都是泥沙。不过上山之后风景独好，整个海得拉巴都能尽收眼底。虽然淋了一身雨不过雨过天晴后衣服干的也快，阳光照在山下特别美丽。断壁残垣也很美。 2018年9月3日 周一这是Interspeech2018正式开始的第一天，上午参加了开幕仪式，先介绍印度国家的地理状况，接着介绍主办城市海得拉巴，然后是今年会议的接收情况，比如论文接受率呀（今年是50%）、哪个领域投稿论文最多最少呀、每天提交的论文数量呀、每篇文章的修改次数的统计呀等等一些比较好玩的结果。接着是授予ISCA的奖项，一般是对某些领域有特别贡献的专家学者，以及某些领域的开拓者先驱们。所以上午就是感受会场氛围 吃完饭之后就是再去会场听口头报告，oral是语音识别方向的，并不是我研究的领域。不过有一篇文章是说用四元数(n = a + bI + cJ + dK)来代替神经网络参数，似乎还有不错的效果，有意思。之后看了海报是关于语音验证的攻击的，之前也不怎么了解，看了海报和交流之后感觉这个领域还是新兴领域，用的方法还不是那么复杂，也蛮有意思的。语音合成只有主观指标才是硬道理，但是识别和这个攻击验证都是可以用客观指标说话的那就改进网络模型获得更小的错误率呗，语音合成（单元挑选方式的）即使客观指标好主观也不一定听出差异。。。 晚上是印度文化汇演，地点就是在开幕式的Hall3。感觉音乐不如我在三傻大闹宝莱坞那段音乐悠扬婉转好听，不过有些音乐的节奏感还是很不错的。 晚上逛了下超市买到了我一直心心念念的印度神调料-芹菜酱(celery sauce)。但是刚开始自己找不到问了当地人（都挺热情）才发现自己找的不对，应该是mint sauce。看起来这就对了，下次可以用这个酱坑人，哈哈哈~ 总共买了芹菜酱225卢布 + 养乐多红蓝两包装（每包5罐）70*2 == 365卢布。哦对了印度🍆也是奇葩还有这样的，就像小圆球一样。。。 2018年9月4日 周二今天已经是出发的第五天了，上午去了会议中心一趟，听的是统计参数语音合成的口头报告。里面关于这个领域的最新成果可以阅读下。 中午一样在mainland China吃饭，之后去玩了Interspeech会标的所在地，加尔塔(300卢比)。附近人太太多了，然后就是登塔。也是和欧洲很多教堂宫殿一样（比如巴黎香榭丽舍大街的凯旋门）是盘旋向上的，但是规模肯定是不如那个凯旋门大。塔顶可以俯瞰周围然后去了Chowmahalla Palace这个宫殿（200卢比，特别值），和外面完全两个世界，人家是世外桃源这里是壁画秀月？？？，待续 2018年9月5日 周三今天是我的poster时间，因此上午主要的事情就是看别人的海拔。因为上午有一场是关于Voice Conversion and Speech Synthesis。其中Exemplar-based Speech Waveform Genaration和我做的单元挑选有关，还提供了Github地址，同时也是BC比赛CSTR的混合单元挑选系统。顾宇师兄的多任务WaveNet和讯飞源哥的论文也在展示之列。谷歌也有一篇文章说的是TTS系统的一些实验。 下午是我讲poster的时候，围观很多人，感兴趣的也多。 晚上是“百度之夜”，请客在意大利餐厅吃饭，非常高级，看来花费了不少心思，据说和前一天的京东晚宴形成对比，那顿致辞冗长而且还是天天吃的印度餐，没有创意。 2018年9月6日 周四早上去了河边的博物馆，外国人是500卢比，门口看见了一种花很是神奇，叶片竟然是红色的。博物馆总体还是不错的，藏品丰富但是博物馆老旧。晚上去了最大的购物中心，吃了肉卷还有肯德基。买了一个贾尔塔的木版画。 2018年9月7日 周五花了一个上午半个下午参观宝莱坞。非常不错。然后顺便去了一个印度人家，换了摩的还体验了新交通方式。最后去了药店。 2018年9月8日 周六今天上午去微软参加Blizzard Challenge比赛的Workshop这次USTC系统是第一，然后我来介绍我们系统。可是我当时应该注意两点，也是以后需要注意的。 会议地点的空间很小，并不足以形成会场那种巨大的Hall，因此当时应该背下来ppt ppt不应该详细介绍以前的系统，应当以这次新的内容和demo为主 Mac需要搭配一个HDMI转接线，我没带。以及如何投屏事先没有充分了解 造成了几个问题 无法点亮屏幕和音响。 不是站立不够正式]]></content>
      <categories>
        <category>旅行</category>
      </categories>
      <tags>
        <tag>旅行</tag>
        <tag>印度</tag>
        <tag>会议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS]]></title>
    <url>%2F2018%2F08%2F08%2FMacOS%2F</url>
    <content type="text"><![CDATA[我以前舍友叫我机器杀手，我也没有白白浪费这个称号。以前用实验室电脑(windows)的时候，一个月重装过四次，每次都能把电脑给弄成蓝屏，无法开机。之后装在戴尔xps13上的Ubuntu一次插拔U盘把笔记本的主板给烧了。。。后来就有了这台 Mac pro（13寸带Touchbar的版本），看看这个系统能不能经过能不能经过我的摧残还能保持完好😅 目前来看，自从6月中旬入手以来，Mac使用良好。 不过首先就会遇到软件问题，好在MaxOS继承Unix,Linux也继承于Unix。它们很多工具是一样的。所以好用的Linux工具都有Mac版本。Ubuntu用apt-get包管理器，Mac就用brew，一模一样。感觉就是Mac拥有Windows易用的图形化操作系统，界面美观，笔记本轻盈，超级超级静音，又有Linux强大的命令行做后盾。所以使用起来很舒服 使用Linux的过程见Linux。 下载工具Linux用axel, Mac本来想使用winebottler或Crossover来用迅雷，但是初试体验一般，IE7都有问题后来试了Mac版本迅雷，网友说很差没下载，出乎意料的很好用呀！可惜的是没windows的IDMan下载神器。。。 办公软件有微软的Office,兼容性没问题，比苹果自带的Pages兼容性肯定强。因为文章一般Latex写，word等用的简单，目前没问题。 浏览器当然是Chrome，各种插件油猴插件配合百度云就是快]]></content>
      <categories>
        <category>常见指令以及用法备忘录</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>Unix</tag>
        <tag>Apple</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习D3.js可视化]]></title>
    <url>%2F2018%2F08%2F03%2F%E5%AD%A6%E4%B9%A0D3-js%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[之前D3.js所学知识可以从我的博客的逐渐完善聚类效果的可视化中找到因此基础的一些不在此教程中了，以下的一些将参考书本以及网站 数据可视化-使用D3设计交互式图表D3版本4.5.0。目前是5.5.0，在这里暂时不考虑向高版本升级 书本采用人民邮电出版社的《数据可视化-使用D3设计交互式图表》（作者Scott Murray），我的D3入门书也是JavaScript的入门教材。 第五章 读取数据rowConverter作为一个新参数，可以进行逐行的数据预处理 12345678var rowConverter = function(d) &#123; return &#123; Food: d.Food, //No conversion Deliciousness: parseFloat(d.Deliciousness) &#125;;&#125;d3.csv("food.csv", rowConverter, function(data) &#123; console.log(data);&#125;); 第八章 数轴第一版内容首先建立了两个比例尺，又根据数据范围建立相应的坐标轴（ticks是5，但是D3会为了美观而在5附近取值，tickFormat用于格式化坐标轴标签尺度的数据格式，这里是保留一位有效数组）。紧接着创建了g分组，并将它传递给坐标轴（call函数），可以认为这时候坐标轴函数相当于一个魔法师开始打造不一样的g分组了！设置g分组属于类.axis是为了可以在CSS样式表中统一对坐标轴的视觉格式进行管理 123456789101112131415161718192021222324252627282930var xScale = d3.scaleLinear() .domain([0, d3.max(dataset, function(d) &#123; return d[0]; &#125;)]) .range([padding, w - padding * 2]);var yScale = d3.scaleLinear() .domain([0, d3.max(dataset, function(d) &#123; return d[1]; &#125;)]) .range([h - padding, padding]);var formatAsPercentage = d3.format(".1%");var xAxis = d3.axisBottom() .scale(xScale) .ticks(5) .tickFormat(formatAsPercentage);var yAxis = d3.axisLeft() .scale(yScale) .ticks(5) .tickFormat(formatAsPercentage);svg.append("g") .attr("class", "axis") .attr("transform", "translate(0," + (h - padding) + ")") .call(xAxis);//Create Y axissvg.append("g") .attr("class", "axis") .attr("transform", "translate(" + padding + ",0)") .call(yAxis); 第二版增加的内容可以增加时间比例尺d3.extent等于mma的MinMax函数 12345678910111213141516var parseTime = d3.timeParse("%m/%d/%y");//Function for converting CSV values from strings to Dates and numbers//parseInt是JavaScript的函数var rowConverter = function(d) &#123; return &#123; Date: parseTime(d.Date), Amount: parseInt(d.Amount) &#125;;&#125;xScale = d3.scaleTime() .domain( d3.extent(dataset, function(d) &#123; return d.Date; &#125;), ) .range([padding, w - padding]); 第九章 更新、过渡和动画]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>JavaScript</tag>
        <tag>D3.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐渐完善聚类效果的可视化]]></title>
    <url>%2F2018%2F07%2F31%2F%E9%80%90%E6%B8%90%E5%AE%8C%E5%96%84%E8%81%9A%E7%B1%BB%E6%95%88%E6%9E%9C%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[我的目标是可视化一个Embedding矩阵的聚类效果，但是矩阵极大，维数也高。 具体来说就是矩阵是一个矩阵维度是459753*32，每一行对应一个向量，代表单元对应的UnitVector；矩阵对应的标签是459753个，每一个标签记录当前单元对应的其他信息（例如单元的时长、单元所属类别、单元对应的音频文件名），其中最关注的是UnitVector与单元所属类别的关系 也就是已知二进制文件UnitVector矩阵与标签文件 Mathematica最开始采用的方法是Mathematica tSNE降维12345678data=Import["../phone_name_frame_id.csv","Table"];features=Partition[Import["Unit2Vec_UnitVector.dat","Real32"],32];features=DimensionReduce[features,2,Method-&gt;"TSNE"];Export["./explain/Unit2Vec_tSNE.dat",features,"Real32"];byspecies=GroupBy[Thread[features-&gt;data[[All,2]]],Last-&gt;First];file="./explain/Visualization Phone Unit2Vec.wl";If[FileExistsQ[file],DeleteFile@file];Save[file,byspecies] 其中data[[All,2]]就是音素所属类别信息，Unit2Vec_UnitVector.dat是Embedding矩阵。会输出两个文件 第一个Unit2Vec_tSNE.dat是459753*2的已经降维得到的矩阵，这在Javascript才用到的 第二个便于Mathematica可视化 可视化降维的分布123456byspecies=KeySort@Import["Visualization Phone Unit2Vec.wl"];$scheme="Rainbow";ListPlot[Values[byspecies],PlotLegends-&gt;PointLegend[$scheme,Keys[byspecies],LegendMarkerSize-&gt;15],PlotStyle-&gt;Map[(Directive[PointSize[0.0015],ColorData[$scheme][#]]&amp;),Rescale@Range@Length@Keys@byspecies],ImageSize-&gt;650]Export["UnitVector_vis.pdf",Rasterize[Magnify[%,4],"Image"]](*因为点数太多只能先转化为图像后再导出，不然PDF有几百兆*) 可视化混淆矩阵在原始空间计算距离即针对欧式距离最近的单元观察对应的所属类别是否相同来进行可视化 12345678data=Partition[Import["Unit2Vec_UnitVector.dat","Real32"],32];phoneid=Import["../phone_name_frame_id.csv","Table"];nearstData=Nearest[data,DistanceFunction-&gt;EuclideanDistance];Assodata=Association@Thread[data-&gt;Range[Length@data]];ReplaceiablePhone=Table[phoneid[[x]]-&gt;phoneid[[Assodata[nearstData[data[[phoneid[[x,1]]+1]],2][[2]]]]],&#123;x,Length@phoneid&#125;];fileName="./explain/ReplaceiablePhone Unit2Vec_64_epochs50.wl";If[FileExistsQ[fileName],DeleteFile[fileName]];Save[fileName,ReplaceiablePhone] 12345678910111213ReplaceiablePhoneDir="\\\\172.16.46.88\\xzhou\\project\\Yanping13k\\Unit2VecAddDur\\Unit2Vec_64_epochs50\\explain\\ReplaceiablePhone Unit2Vec_64_epochs50.wl";ReplaceiablePhone=Get[ReplaceiablePhoneDir];confusionMatrixData=#[[1,2]]-&gt;#[[2,2]]&amp;/@ReplaceiablePhone;phone=Union@confusionMatrixData[[All,1]];m=Normal@SparseArray@Normal@Counts[&#123;#[[1]],#[[2]]&#125;&amp;/@(confusionMatrixData/.Thread[phone-&gt;Range[Length@phone]])];mNorm=N[m/Total[m,&#123;2&#125;]];t=Transpose@Map[Flatten,&#123;#,Reverse@Transpose@#&#125;&amp;[Table[Range[1,2 #-1,2],&#123;#&#125;]]&amp;[Length@mNorm]]/2;p=MatrixPlot[mNorm,Epilog-&gt;Text@@@Transpose[&#123;Catenate@m,t&#125;],FrameTicks-&gt;&#123;Transpose@&#123;Range[Length@phone],phone&#125;,Transpose@&#123;Range[Length@phone],Total[m,&#123;1&#125;]&#125;,Transpose@&#123;Range[Length@phone],Total[m,&#123;2&#125;]&#125;,Transpose@&#123;Range[Length@phone],phone&#125;&#125;,ImageSize-&gt;1700];Column[&#123;Row[&#123;Rotate["actual class",90 Degree],p&#125;,Alignment-&gt;Center],Spacer@5,"predicted class"&#125;,Alignment-&gt;Center];Export[FileNameJoin@Flatten[&#123;Most@#,"ConfusionMatrixPlot "&lt;&gt;StringSplit[StringSplit[Last@#," "][[2]],"."][[1]]&lt;&gt;".pdf"&#125;&amp;@FileNameSplit[ReplaceiablePhoneDir]],%];p=MatrixPlot[mNorm,FrameTicks-&gt;&#123;Transpose@&#123;Range[Length@phone],Style[#,13]&amp;/@phone&#125;,Transpose@&#123;Range[Length@phone],Rotate[Style[#,13],30Degree]&amp;/@Total[m,&#123;1&#125;]&#125;,Transpose@&#123;Range[Length@phone],Style[#,13]&amp;/@Total[m,&#123;2&#125;]&#125;, Transpose@&#123;Range[Length@phone],Rotate[Style[#,13],30Degree]&amp;/@phone&#125;&#125;,ImageSize-&gt;1700];Column[&#123;Row[&#123;Rotate["actual class",90 Degree],p&#125;,Alignment-&gt;Center],Spacer@5,"predicted class"&#125;,Alignment-&gt;Center];SystemOpen@Export[FileNameJoin@Flatten[&#123;Most@#,"ConfusionMatrixPlotBeautiful_"&lt;&gt;StringSplit[StringSplit[Last@#," "][[2]],"."][[1]]&lt;&gt;".pdf"&#125;&amp;@FileNameSplit[ReplaceiablePhoneDir]],%]; 使用Tensorboard优点 可以交互 可以动态观察聚类情况 可以存储降维的结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445import osimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datafrom tensorflow.contrib.tensorboard.plugins import projectorimport numpy as npdef BinaryRead(datafile,column): data = np.fromfile(datafile,dtype=np.float32) LengthOfFile=len(data) assert(LengthOfFile) assert((LengthOfFile%column)==0) data.shape = [int(LengthOfFile/column),column] return dataLOG_DIR = 'logs'metadata = os.path.join(LOG_DIR, 'metadata.tsv')data_path='Unit2Vec_UnitVector.dat'name='Unit2Vec'aall_data=BinaryRead(data_path,32)UnitVector = tf.Variable(all_data, name=name)txt = open(r"../phone_name_frame_id.csv").readlines()all_label = list(map(lambda i:i.split('\t')[1],txt))all_dur = list(map(lambda i:int(i.split('\t')[3]),txt))mydict=&#123;p:i for i,p in enumerate(sorted(list(set(all_label))))&#125;with open(metadata, 'w') as metadata_file: metadata_file.write('Index\tColorIndex\tPhoneme\tPhoneDur\n') for i,row in enumerate(all_label): metadata_file.write('%d\t%d\t%s\t%d\n' % (i,mydict[row],row,all_dur[i]))with tf.Session() as sess: saver = tf.train.Saver([UnitVector]) sess.run(UnitVector.initializer) saver.save(sess, os.path.join(LOG_DIR, name+'.ckpt')) config = projector.ProjectorConfig() # One can add multiple embeddings. embedding = config.embeddings.add() embedding.tensor_name = UnitVector.name # Link this tensor to its metadata file (e.g. labels). embedding.metadata_path = 'metadata.tsv' # Saves a config file that TensorBoard will read during startup. projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config) PCA 隔离查看相同音素对应的点（使用了正则表达式） tSNE 筛选点并可视化其他特征比如时长 缺点在于 不能听音素对应的声音 tSNE结果不如Mathematica好,而且mma也是完全不知道label信息去做降维的 不能在已经经过tSNE降维并显示所有音素类别的情况下，查看某个音素团的音素时长分布情况。也就是主图不能同时查看多种特征，自定义程度低 D3.js阶段使用D3版本是5.5.0因为我热爱可视化，所以决定学习D3.js，目前最流行的可视化库之一，不仅可以学习前端知识,Javascript还可以通过看别人的可视化项目培养艺术直觉 Github地址见我的Vis-UnitVector 在以下代码中，颜色渲染的方式和以前mathematica一样，只是背景色换成了黑色，更酷了是不是😁之前Mathematica颜色是这样使用的, 就是第二个输出的61种颜色，现在把它转化为了十六进制形式 初期代码简单只能显示静态图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Vis UnitVector&lt;/title&gt; &lt;script type="text/javascript" src="d3/d3.js"&gt;&lt;/script&gt; &lt;style type="text/css"&gt; /* No style rules here yet */ &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;script type="text/javascript"&gt; //Width and height var w = 1170, h=680; var dataset, cur_lab, selectQ = false; // a global d3.json("Unit2Vec_tSNE.json").then(function(json) &#123; dataset = json; visualize(); &#125;); function visualize() &#123; //Create SVG element var svg = d3.select("body") .append("svg") .attr("width", w) .attr("height", h); //创建背景用于触发点击事件（颜色复位） svg.append("rect") .attr("x", 0) .attr("y", 0) .attr("width", w) .attr("height", h) .attr("fill","black") .on("click",function(d)&#123; //触发背景点击事件，复位颜色的事件 d3.selectAll("circle") .attr("fill", function(d) &#123; return color_map(d3.values(d)[0].lab); &#125;); //给文本传空字符串，因为当前点击的是背景而没点击任何点 d3.select("text").text(""); selectQ = false; &#125;); //添加文本显示当前点击的点对应的音素类别 svg.append("text") .attr("x",100) .attr("y",80) .attr("font-size",50); var min_max_x = d3.extent(dataset,function(d)&#123;return d3.values(d)[0].pos[0]&#125;); var min_x = min_max_x[0]; var max_x = min_max_x[1]; var min_max_y = d3.extent(dataset,function(d)&#123;return d3.values(d)[0].pos[1]&#125;); var min_y = min_max_y[0]; var max_y = min_max_y[1]; //创建映射点位置的比例尺 var xScale = d3.scaleLinear().domain([min_x,max_x]).range([0,w]); var yScale = d3.scaleLinear().domain([min_y,max_y]).range([h,0]); var phoneme = ["a", "ai", "an", "ang", "ao", "b", "c", "ch", "d", "e", "ei", "en", "eng", "er", "f", "g", "h", "i", "ia", "ian", "iang", "iao", "ie", "ii", "iii", "in", "ing", "iong", "iou", "j", "k", "l", "m", "n", "o", "ong", "ou", "p", "q", "r", "s", "sh", "sil", "sp", "t", "u", "ua", "uai", "uan", "uang", "uei", "uen", "ueng", "uo", "v", "van", "ve", "vn", "x", "z", "zh"] var color = ["#781c86", "#6d1c90", "#621d99", "#571ea2", "#4e20ab", "#4a27b2","#462eb9", "#4236c1", "#403ec6", "#3f47c9", "#3f51cc", "#3e5acf","#3f63cf", "#416bce", "#4274ce", "#447ccd", "#4783c8", "#498ac4", "#4c90c0", "#4f97bb", "#539bb5", "#56a0ae", "#5aa5a8", "#5ea9a1", "#63ac9a", "#68af93", "#6cb28c", "#72b485", "#78b67e", "#7db877", "#83ba70", "#89bb6b", "#90bc65", "#96bd60", "#9dbe5a", "#a3be56", "#aabd52", "#b0bd4e", "#b7bd4b", "#bdbb48", "#c3ba46", "#c9b843", "#ceb541", "#d3b240", "#d8ae3e", "#dcab3c", "#dfa53b", "#e19f3a", "#e49938", "#e69237", "#e68a35", "#e68133", "#e67832", "#e56e30", "#e4632e", "#e2582c", "#e04e29", "#df4327", "#dd3726", "#dc2c24", "#db2122"] //创建音素与对应颜色的序数比例尺 var color_map = d3.scaleOrdinal() .domain(phoneme) .range(color); //创建一个包含比例尺的字典，可以将音素时长映射在[-2,2]内 var color_map_dict = new Array(); for (var i = 0; i &lt; phoneme.length; i++) &#123; var min_max_dur = d3.extent( dataset.filter(function(d) &#123;return d3.values(d)[0].lab == phoneme[i];&#125;), function(d)&#123;return d3.values(d)[0].dur&#125;); color_map_dict[phoneme[i]] = d3.scaleLinear() .domain([min_max_dur[0],min_max_dur[1]]) .range([-2,2]); &#125; //设置点的相关事件属性 svg.selectAll("circle") .data(dataset) .enter() .append("circle") .attr("cx", function(d) &#123; return xScale(d3.values(d)[0].pos[0]); &#125;) .attr("cy", function(d) &#123; return yScale(d3.values(d)[0].pos[1]); &#125;) .attr("r", 3) .attr("fill", function(d) &#123; return color_map(d3.values(d)[0].lab); &#125;) .call(d3.zoom().on("zoom",function()&#123; svg.attr("transform",d3.event.transform); &#125;)) .on("mouseover",function(d)&#123; var info = d3.values(d)[0] if(selectQ)&#123; if(info.lab == cur_lab) new Audio("wav_phone/"+info.name+".wav").play(); &#125; else new Audio("wav_phone/"+info.name+".wav").play(); //给文本传当前鼠标滑过的音素名 d3.select("text") .text(info.lab) .attr("fill","white"); &#125;) .on("click",function(d)&#123; cur_lab = d3.values(d)[0].lab; //给指定点上彩色，并根据每个单元时长不同上不一样的亮度 //时长越小越按，越大越亮 d3.selectAll("circle").filter(function(d) &#123; return d3.values(d)[0].lab == cur_lab; &#125;) .attr("fill", function(d) &#123; var info = d3.values(d)[0] return d3.rgb(color_map(info.lab)).darker(color_map_dict[info.lab](info.dur)); &#125;) //给其余点上灰色 d3.selectAll("circle").filter(function(d) &#123; return d3.values(d)[0].lab != cur_lab; &#125;) .attr("fill","grey"); selectQ = true; &#125;) ; &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 整体图的展示局部图的展示，选中某一个点之后 没对比没伤害，为什么D3画的图颜色这么好看捏~ 继续探索…比如离某音素最近的音素们是什么样的分布呢？用Mathematica来探索 1234567891011121314151617181920(*导入数据*)data = Partition[ Import["/Users/xzhou/programming/Javascript/Vis-UnitVector/\Unit2Vec_UnitVector.dat", "Real32"], 32];phones = Import[ "/Users/xzhou/programming/Javascript/Vis-UnitVector/phone_name_\frame_id.csv", "Table"][[All, 2]];(*构造最邻近对象，非常快的*)n = Nearest[data];(*建立vector-&gt;对应的索引的字典，也是为了加速运算，不需要每次求Position*)asso = Association[Thread[data -&gt; Range@Length@data]];(*画图，n[data[[i]], 1000]代表求1000近邻*)SeedRandom[23333];Grid@Table[Module[&#123;nearps = phones[[asso[#]]] &amp; /@ n[data[[i]], 1000]&#125;, &#123;phones[[i]], BarChart[Tooltip[#[[2]], #[[1]]] &amp; /@ Normal[Counts[nearps]], ColorFunction -&gt; "Rainbow", BarSpacing -&gt; &#123;0, 0&#125;, Frame -&gt; False, Axes -&gt; False, BarOrigin -&gt; Left, ChartLayout -&gt; "Stacked", PlotRange -&gt; &#123;All, &#123;.5, 1.5&#125;&#125;, AspectRatio -&gt; 1/10, ImageSize -&gt; 500]&#125;], &#123;i, RandomSample[Range@Length[data], 12]&#125;] 可以看到不仅音素内部有时长的体现，音素之间聚类明细，音素的最近邻之间也是距离相近的音素,比如首尾静音sil附近是句内静音sp，辅音旁边是辅音等等 但是Counts[nearps]丢失了序列的前后位置信息，可以提供宏观表示但是细节不够，不能体现第N近是哪个音素。因此修改最后一段代码12345678910111213141516SeedRandom[23333];Grid@Table[ Module[&#123;nearps = phones[[asso[#]]] &amp; /@ n[data[[i]], 1000], col&#125;, (*建立颜色映射*) col = Association[ Thread[Union[nearps] -&gt; Rescale@Range[Length@Union[nearps]]]]; &#123;phones[[i]], BarChart[ Tooltip[Function[&#123;val&#125;, Style[val, ColorData["Rainbow", col[First@#]]]]@Length@#, First@#] &amp; /@ Split[nearps], BarSpacing -&gt; &#123;0, 0&#125;, Frame -&gt; False, Axes -&gt; False, BarOrigin -&gt; Left, ChartLayout -&gt; "Stacked", PlotRange -&gt; &#123;All, &#123;.5, 1.5&#125;&#125;, AspectRatio -&gt; 1/10, ImageSize -&gt; 500]&#125;], &#123;i, RandomSample[Range@Length[data], 12]&#125;] 可以看到细节，也可以看到即使是某个音素的前N最近邻，也不一定同样属于这个音素。也就是还存在比较大的混叠尝试给UnitVector更多信息的话，混叠可以减小]]></content>
      <categories>
        <category>实验项目</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>JavaScript</tag>
        <tag>D3.js</tag>
        <tag>Mathematica</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客更新日志]]></title>
    <url>%2F2018%2F07%2F30%2F%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[2018年7月24日周二我开始着手研究博客。起因是因为印象笔记的最高级会员一个笔记的容量也只有200MB，对于游记里喜欢放照片的我来说太小了。因此决定从使用了五年的印象笔记迁移至我现在这个博客。 曾经我写印象笔记是直接使用，后来使用StackExchange论坛发现了Markdown这种写作方式，于是购买了印象笔记插件“马克飞象”，总体来说不错。 因此新博客站定很重要的一个功能就是支持Markdown。 最先注意到的框架是Hugo,因为自己喜欢的一个可视化设计师Nadieh Bremer的博客使用的就是这个，我非常喜欢网站的主题Victor Hugo。我同时了解到这是一个静态网站生成器，优点是生成速度是同类框架中最快的，安装也简单。但是一开始我就知道我希望自己的网站具备什么，比如旅行博客可以拥有背景音乐，但是搜索了下，资料很少。jekyll和Hexo和Hugo都是静态网站生成器，Hexo生成速度介于三者之间，而且中文文档也很不错，因为使用的是NodeJs所以拓展性是优于Hugo的。 所以选择Hexo这个作为网站框架，主题先暂时配置成主流黑白风格的Next，不过我觉得这种风格太程序员了，之后会换掉。（更换主题在Hexo中很简单） 注意：以下主目录下的_config.yml称为站点配置文件，主目录下的themes目录下的_config.yml称为主题配置文件 与自己的Github关联并托管自己的网站内容在上面，很多博客已有叙述这里不多说。设置Next主题，设置根目录下_config.yml的theme: next,设置主题目录下的_config.yml的Schemes字段更换风格 按照资源文件夹的说法，打开站点配置文件内的post_asset_folder字段,这样不管是图片还是自己本地的音乐都可以直接被Markdown引用。每当dexo new &quot;testPost&quot;,source/_posts_目录下都会出现testPost文件夹以及testPost.md。所以素材放置在testPost中 图片：123&#123;% asset_img test.jpg %&#125;&lt;img src=&quot;test.jpg&quot; width=&quot;50%&quot; height=&quot;%50&quot;&gt; 本地音乐：1&#123;% aplayer &quot;单车练习曲&quot; &quot;王雁盟&quot; &quot;单车练习曲.mp3&quot; &quot;单车练习曲.jpg&quot; %&#125; 网易云音乐：123456&lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&amp;id=28582962&amp;auto=1&amp;height=66"&gt;&lt;/iframe&gt; 对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源。这个稍微有些复杂但是管理资源非常方便的功能可以通过将 config.yml 文件中的 post_asset_folder 选项设为 true 来打开。 设置标签，分类以及文章目录（不要安装hexo-toc插件不然目录不能跳转）设置如我这篇博客toc: true代表打开目录&lt;!-- toc --&gt;设置目录出现的位置comments: true代表打开评论，评论区域，使用韩国“来必力”评论系统，填写主题目录下的_config.yml的livere_uid字段 12345678910---title: 博客更新日志date: 2018-07-30 14:54:12tags: [博客,Hexo]comments: truetoc: truecategories: 博客---&lt;!-- toc --&gt; 2018/7/30 增加搜索功能。修改站点配置文件 search:path: search.xmlfield: postformat: htmllimit: 10000 修改主题配置文件local_search字段的enable，设置为true 增加了以下几个方面： 新增“关于我“页面:去掉主题配置文件menu的about: /about/ || user的注释 修改个人头像:修改主题配置文件avatar字段的url。我这里是/images/icon.jpg 增加站点统计（使用不蒜子）:设置主题配置文件busuanzi_count的enable为true 增加背景图片（修改了themes\next\source\css\_custom\custom.styl文件，图片来源于https://source.unsplash.com/）12345678910111213// Custom styles.body &#123; background:url(https://images.unsplash.com/photo-1533555855029-9341affa632a?ixlib=rb-0.3.5&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;s=7df5c95df1834e4ff9838f6a96c95096&amp;auto=format&amp;fit=crop&amp;w=2380&amp;q=80); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%;&#125;.main-inner &#123; margin-top: 60px; padding: 60px 60px 60px 60px; background: #fff; opacity: 0.9; min-height: 500px;&#125; 自己写了一个Sublime3插件用于复制图片粘贴并用合适格式粘贴进Markdown 在Mac下是Optopn⌥ + Cmd⌘ + c复制文件完整路径, 然后Control⌃+Cmd⌘+v可以得到类似这样的表示 新建插件 复制以下代码12345678910111213141516171819import sublimeimport sublime_pluginimport random, string, os, shutilclass pasteimageCommand(sublime_plugin.TextCommand): def run(self, edit): _filename = self.view.file_name() if _filename != None: old_file_path = sublime.get_clipboard() suffix = os.path.splitext(old_file_path)[1] if os.path.exists(old_file_path): basename = os.path.splitext(_filename)[0] random_string = ''.join(random.sample(string.ascii_letters + string.digits, 8))+suffix new_file_path = os.path.join(basename, random_string) shutil.copyfile(old_file_path, new_file_path) cur_pos = self.view.sel()[0].begin() self.view.insert(edit, cur_pos, '&#123;% asset_img '+os.path.basename(new_file_path)+' %&#125;') else: print("This file hasn't been saved") 绑定快捷键123[ &#123; &quot;keys&quot;: [&quot;ctrl+super+v&quot;], &quot;command&quot;: &quot;pasteimage&quot; &#125;] 之后开启Sublime这个插件就自动加载了 未来可能会设置标签云以及思维导图]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
        <tag>Markdown</tag>
        <tag>Sublime Text3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ and VS]]></title>
    <url>%2F2018%2F07%2F29%2FC%2B%2B%20and%20VS%2F</url>
    <content type="text"><![CDATA[VS知识快捷键Ctrl-K + Ctrl-C 注释一段选择代码Ctrl-K + Ctrl-U 取消一段选择代码的注释Ctrl-K + Ctrl-D 格式化整篇代码 为解决方案创建目录后那么根目录包含 .sln .db git文件夹 solution文件夹: 与工程同名, 放源代码. 以及x64文件夹，用于放编译出来的项目. 在solution文件夹中, 比如项目名是test, 那么源代码就在./test/test/里面, 第一个test指的是解决方案目录, 第二个就是项目名. 包含 所有的源代码, .cpp和.h等等 .vcxproj .vcxproj.filters .vcxproj.user 这也是默认的输入输出的根目录，也就是说，如果程序中打开或新建一个文件，只给文件名的话，就从这个目录打开. 疑问为什么项目总是让我们编译查看工具-&gt;选项-&gt;项目和解决方案-&gt;MSBuild项目生成输出详细级别再把 视图-&gt;输出 中的内容复制到txt中 寻找类似语句“项目不是最新的，因为缺少…”修复后对解决方案或项目选择全部生成。之后运行就正常了 Note: 不是“MSBuild项目生成日志文件详细级别”，那个内容不够丰富，会遗漏一些 修复后不是立即运行，而是对解决方案或项目选择全部生成 如何在VS里添加头文件包含路径项目-&gt;属性-&gt;C++-&gt;附加包路径 C++知识知识注意事项C++内部变量连续存储，意味着先定义了a数组a[100]后定义了b，那么如果a[105]原先是未定义的 但是当把b置0后，a[105]的值也会跟着改变，因为a[105]地址可能就是b的地址 指针初始化a指向整型数组int* a = new int[5]; 初始化a指向5这个整型int* a = new int(5); 拷贝拷贝数组至另一个数组(数组元素为N个)拷贝数组a至数组b：memcpy(b, a, sizeof(float)*N);拷贝数组a至向量b：memcpy(&amp;b[0], a, sizeof(float)*N);拷贝向量a至向量b：memcpy(&amp;b[0], &amp;a[0], sizeof(float)*N); ####拷贝二维数组的一部分（N列）至向量b（N个元素）拷贝二维数组的第一行至向量b：memcpy(&amp;b[0], a, sizeof(float)*N);拷贝二维数组的第二行至向量b：memcpy(&amp;b[0], a+1 sizeof(float)*N);拷贝二维数组的第二行第三个元素开始的N个元素至向量b：memcpy(&amp;b[0], *(a+1)+2,sizeof(float)*N);或者memcpy(&amp;b[0], &amp;a[1][2],sizeof(float)*N);因为&amp;a[i]=a+i，&amp;a[i][j]=*(a+i)+j,在指向行的指针前加 * ,转换为指向列的指针；在指向列的指针前加 &amp; ,转换为指向行的指针； 测量时间123456#include "time.h"clock_t start, end;start = clock();//code hereend = clock();printf("Elapsed time:%f secs.\n", (double)(end - start) / CLOCKS_PER_SEC); 函数 sprintf 12int sprintf( char *buffer, const char *format, [ argument] … )//把格式化的数据写入某个字符串缓冲区buffer中sprintf(szLstFile,"%s\\lists\\phoneme.lst",g_LibCfg.szPrjDir);//把 g_LibCfg.szPrjDir 按照 "%s\\lists\\phoneme.lst"格式转化，并存在 szLstFile 中 sscanf 1int sscanf(const char *buffer,const char *format,[argument ]...); //sscanf会从buffer里读进数据，依照format的格式将数据写入到argument里。 fgets 1char *fgets(char *buf, int bufsize, FILE *stream);//从文件结构体指针stream中读取数据，每次读取一行。读取的数据保存在buf指向的字符数组中，每次最多读取bufsize-1个字符（第bufsize个字符赋'\0'） fgets返回值 成功，则返回第一个参数buf 在读字符时遇到end-of-file，则eof指示器被设置，如果还没读入任何字符就遇到这种情况，则buf保持原来的内容，返回NULL 如果发生读入错误，error指示器被设置，返回NULL，buf的值可能被改变 fscanf 12int fscanf(FILE*stream, constchar*format, [argument...]); //其功能为根据数据格式(format)从输入流(stream)中写入数据(argument)；与fgets的差别在于：fscanf遇到空格和换行时结束，注意空格时也结束，fgets遇到空格不结束。fscanf(fpPhone," %s %s",szTmpStr,szTmpStr);//只会将第二个字符串赋值给szTmpStr fread 1size_t fread ( void * ptr, size_t size, size_t count, FILE * stream );//从文件流指针stream处读count个数据，每个数据大小size个字节，放到ptr中存储。 fwrite 1size_t fwrite ( const void * ptr, size_t size, size_t count, FILE * stream )//fwrite()用来将数据写入文件流中,将ptr指向的数据地址的内容输出至stream文件指针指向的文件 memset 12void *memset(void *s, int ch, size_t n);//函数解释：将s中当前位置后面的n个字节（typedef unsigned int size_t ）用 ch 替换并返回 s//memset：作用是在一段内存块中填充某个给定的值，它是对较大的结构体或数组进行清零操作的一种最快方法 strstr 1extern char *strstr(char *str1, const char *str2);//返回值；若str2是str1的子串，则返回str2在str1的首次出现的地址；如果str2不是str1的子串，则返回NULL。 strncpy 1char *strncpy(char *dest, const char *src, int n)//把src所指向的字符串中以src地址开始的前n个字节复制到dest所指的数组中，并返回dest。 strcpy 1char *strcpy(char *dest, const char *src);//strcpy()会将参数src 字符串拷贝至参数dest 所指的地址。 strcmp 1234extern int strcmp(const char *s1,const char *s2);//当s1&lt;s2时，返回为负数//当s1=s2时，返回值= 0//当s1&gt;s2时，返回正数 memcpy 1void * memcpy ( void * destination, const void * source, size_t num );//从source处读num个字节放到destination指向的内存中去。 assertassert宏能测试传入表达式的真假值，当表达式为真(true)，则不会有任何反应；当表达式为假(false)，则函数将输出错误信息，并中断程序的执行。 疑问如何在sprintf函数中使用string？sprintf是C++继承自C语言的函数，无法直接支持string类型，所以要先把string类型转为基础类型，也就是char*。这里需要使用string类的成员函数c_str();该成员函数功能为，将string的内容转为C语言的字符数组表达形式。所以用sprintf将string对象str，输出的char[]数组array中的代码可以写作： sprintf(array, &quot;%s&quot;, str.c_str());除此外，还可以用strcpy函数，使代码更简单：strcpy(array, str.c_str()); 实际例子建立二维数组1234567891011//开辟内存float **ppTrgAnswer_Data = new float*[nTrgPhoneNum];for (int i = 0; i &lt; nTrgPhoneNum; i++)&#123; ppTrgAnswer_Data[i] = new float[MAX_QUES_NUM]; memset(ppTrgAnswer_Data[i], 0, sizeof(float)*MAX_QUES_NUM);&#125;//释放内存for (i = 0; i &lt; nTrgPhoneNum; i++) delete[] ppTrgAnswer_Data[i];delete[] ppTrgAnswer_Data;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Visual Studio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MXNet]]></title>
    <url>%2F2018%2F07%2F27%2FMXNet%2F</url>
    <content type="text"><![CDATA[MXNet环境指南 打开mxnet source activate gluon # 注意Windows下不需要 source退出环境 source deactivate GPU版本进入环境后如果用指定的卡可以 CUDA_VISIBLE_DEVICES=2 python，这样数据只能分配在一个GPU上 CUDA_VISIBLE_DEVICES=2 jupyter notebook ，进入jupyter后再导入mxnet，如果使用GPU训练，也只训练在一块卡上 升级 pip install --pre mxnet-cu80 --upgrade或者pip install --pre mxnet --upgrade 可以不让MXNet占用过多显存，设置保留的百分数 export MXNET_GPU_MEM_POOL_RESERVE=5 安装依赖库：jupyter，matplotlib，pandas，requests，mxnet MXNet如何处理训练模式和测试模式Gluon：若在通过网络的代码met(…)被with autograd.record()包裹，那么这时候Gluon知道是训练模式。如果没有则是测试模式。可以参见在论坛的帖子得到一些证明MNNet：默认是训练模式，测试模式需要指明mod.forward(Batch([x]),is_train=False)C++：默认是测试模式 MXNet训练，C++使用基本流程 在python中训练MXNet模型 在python中导入模型，并进行预测 在C++中导入模型（在小例子上进行验证两个接口结果一致） 在C++项目中使用模型 工程小例子层的使用RNN循环神经网络的使用12345678910layer = mx.gluon.rnn.RNN(100, 3)#只知道每个time-steps的输出维度是100，有三个隐层，具体几个time-steps未知layer.initialize()input = mx.nd.random_uniform(shape=(6, 8, 10))# 默认TNC模式，方便取到跨batch的数据# 代表time-steps是6，每个time-steps对应的输入维度是10，batch_size为8# 6*10-&gt;6*100# by default zeros are used as begin stateoutput = layer(input)print output.shape Embedding层 提取权重1net.weight.data().asnumpy() 关于提高GPU利用率可以尝试将数据全部放进内存，如果是不规则数据集，numpy处理不了可以用python自带的数组处理 MXNet常用函数nd.concatenate（被弃用,改为nd.concat）123456789101112print img_list[0].shape #(1L, 3L, 64L, 64L) 每个都是这样的形状print len(img_list) #13233nd.concatenate(img_list).shape #(13233L, 3L, 64L, 64L)train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list),batch_size=64)train_data.reset()for batch in train_data: print batch break#输出DataBatch: data shapes: [(64L, 3L, 64L, 64L)] label shapes: []#即每个batch是64张图 nd.concatenate([history,temp],axis=1)或者nd.concat(history,temp,dim=1)对应F.concat(history, temp, dim=1) 计算L2Loss123456789import mxnet as mxfrom mxnet import gluonimport numpy as nploss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,2,4))b=mx.nd.random.uniform(0, 10,shape=(3,2,4))print loss1(a,b)print np.mean(np.square((a[:,0,:]-b[:,0,:]).asnumpy()))/2print np.mean(np.square((a[:,1,:]-b[:,1,:]).asnumpy()))/2 sym.list_outputs()列出一个模型输出端口的名字 sym.list_arguments()列出一个模型的输入端口的名字以及权重和偏置的名字 sym.tojson()可以打印出网络结构 mod.get_outputs()列出前馈的输出 显示网络结构 viz.plot_network直接显示网络结构mx.viz.plot_network(symbol=sym) 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraphPlot"&#125;] 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraph"&#125;] mask-RNN重要的SequenceMask函数第二个参数表示这个mini-batch内几个样本是真实的，这里代表两个真实12345678910111213141516171819202122232425x = mx.nd.array([[[ 1., 2., 3.], [ 4., 5., 6.]], [[ 7., 8., 9.], [ 10., 11., 12.]], [[ 13., 14., 15.], [ 16., 17., 18.]]])#x.shape=(3L,2L,3L)res=mx.nd.SequenceMask(x,mx.nd.array([2,1]), use_sequence_length=True)print res#表明第一个batch保留两个time-stseps，第二个batch保留1个time-stsep# 得到# [[ 1. 2. 3.]# [ 4. 5. 6.]]# [[ 7. 8. 9.]# [ 0. 0. 0.]]# [[ 0. 0. 0.]# [ 0. 0. 0.]]]#这样的话 res[:,0,:]取出的就是第一个batch加了mask的结果# [[ 1. 2. 3.]# [ 7. 8. 9.]# [ 0. 0. 0.]]# res[:,1,:]取出的就是第2个batch加了mask的结果# [[ 4. 5. 6.]# [ 0. 0. 0.]# [ 0. 0. 0.]] 首先解决带mask的loss1234567891011121314151617import mxnet as mxa=mx.random.normal(0,1,shape=(50,128,43))b=mx.random.normal(0,1,shape=(50,128,43))mask=[49]*128 #如果这里是[50]*128那么这两个loss的结果一样loss=mx.gluon.loss.L2Loss(batch_axis=1)print loss(a,b)def L2LossMask(a,b,mask): #类似于gluon.loss.L2Loss(batch_axis=1)，但是可以用mask方式计算 maskloss=[] maska=nd.SequenceMask(a, mask, use_sequence_length=True) maskb=nd.SequenceMask(b, mask, use_sequence_length=True) for i in range(a.shape[1]): maskloss.append(nd.sum((maska[:,i,:]-maskb[:,i,:])**2)/(2*mask[i]*a.shape[2])) return nd.concat(*maskloss,dim=0)print L2LossMask(a,b,mask) MXNet高阶应用利用HDF5文件做迭代器用于训练123456789101112131415161718192021222324252627282930313233343536import mxnet as mxfrom mxnet import nd,gluon,autogradfrom mxnet.gluon import nnimport h5pynet = nn.Sequential()with net.name_scope(): net.add(nn.Dense(32,in_units=2,activation="tanh")) net.add(nn.Dense(1))net.initialize()# load data from filewith h5py.File('test_data_SE.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] batch_size = 512 epochs=10 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'adam', &#123;'learning_rate': 0.3&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0]) loss = square_loss(output, batch.label[0]) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() print("Epoch %d, average loss: %f" % (epoch, total_loss/num_examples)) print(net(nd.array([[-1,-0.9]]))[0].asnumpy()) 单输入单输出Seq2Seq模型Python代码（HybridBlock版本）123456789101112131415161718192021222324252627282930313233import mxnet as mxfrom mxnet.gluon import nnprint("mxnet version: "+mx.__version__)mx.random.seed(1234) #Getting the same result everytimedef get_net(): # construct a MLP net = nn.HybridSequential() with net.name_scope(): net.add(nn.Dense(5, activation="relu")) net.add(nn.Dense(2)) # initialize the parameters net.collect_params().initialize() return net# forwardx = mx.nd.array([[0.1,0.2,0.3]])net = get_net()net.hybridize()print('=== net(x) ===&#123;&#125;'.format(net(x)))net.export('model')############## Re-importing the net ##############from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,3))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([[0.1,0.2,0.3]])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() C++导入模型再预测 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include &lt;stdio.h&gt;// Path for c_predict_api#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./simple prediction model/model-symbol.json"; std::string param_file = "./simple prediction model/model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 1; // 1 for feedforward const char* input_key[1] = &#123; "data" &#125;; const char** input_keys = input_key; // input-dims int data_len = 3; const mx_uint input_shape_indptr[2] = &#123; 0, 2 &#125;; const mx_uint input_shape_data[2] = &#123; 1,static_cast&lt;mx_uint&gt;(data_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0==MXPredCreate((const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, &amp;pred_hnd)); assert(pred_hnd); std::vector&lt;mx_float&gt; vector_data = std::vector&lt;mx_float&gt;(data_len); mx_float* p = vector_data.data(); p[0] = .1; p[1] = .2; p[2] = .3; MXPredSetInput(pred_hnd, "data", vector_data.data(), data_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output_index = 0; mx_uint *shape = 0; //shape相当于1*3的向量 mx_uint shape_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output_index, &amp;shape, &amp;shape_len); size_t size = 1; for (mx_uint i = 0; i &lt; shape_len; ++i) size *= shape[i]; std::vector&lt;float&gt; data(size); assert(0==MXPredGetOutput(pred_hnd, output_index, &amp;(data[0]), size)); // Release Predictor MXPredFree(pred_hnd); // Print Output Data PrintOutputResult(data); return 0;&#125; 简单的多输入多输出网络Python代码（普通版本）1234567891011121314151617181920212223from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.Block): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def forward(self,x,y): result1 = nd.relu(self.dense0(x))+nd.relu(self.dense1(y)) result2 = nd.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1] Python代码（HybridBlock版本）1234567891011121314151617181920212223242526272829303132333435from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.HybridBlock): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def hybrid_forward(self, F,x,y): result1 = F.relu(self.dense0(x))+F.relu(self.dense1(y)) result2 = F.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()net.hybridize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1]net.export('model')print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,3)),('data1',(1,5))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])mod.forward(Batch(data=[x,y]))print mod.get_outputs() C++导入模型再预测 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./model-symbol.json"; std::string param_file = "./model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 2; mx_uint num_output_nodes = 2; const char* input_key[2] = &#123; "data0" , "data1" &#125;; const char** input_keys = input_key; //output_key name maybe should modify const char* output_key[2] = &#123; "hybridnet0__plus0" , "hybridnet0_relu2" &#125;; const char** output_keys = output_key; // input-dims int data0_len = 3; int data1_len = 5; const mx_uint input_shape_indptr[3] = &#123; 0,2,4 &#125;; const mx_uint input_shape_data[4] = &#123;1,static_cast&lt;mx_uint&gt;(data0_len),1,static_cast&lt;mx_uint&gt;(data1_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0 == MXPredCreatePartialOut( (const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, num_output_nodes, output_keys, &amp;pred_hnd)); assert(pred_hnd); //ERROR HERE std::vector&lt;mx_float&gt; vector_data0 = std::vector&lt;mx_float&gt;(data0_len); mx_float* p0 = vector_data0.data(); p0[0] = 1;p0[1] = 2;p0[2] = 5; MXPredSetInput(pred_hnd, "data0", vector_data0.data(), data0_len); std::vector&lt;mx_float&gt; vector_data1 = std::vector&lt;mx_float&gt;(data1_len); mx_float* p1 = vector_data1.data(); p1[0] = 5; p1[1] = 3; p1[2] = 1; p1[3] = 4; p1[4] = 5; MXPredSetInput(pred_hnd, "data1", vector_data1.data(), data1_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output0_index = 0; mx_uint *shape0 = 0; //shape相当于1*3的向量 mx_uint shape0_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output0_index, &amp;shape0, &amp;shape0_len); size_t size0 = 1; for (mx_uint i = 0; i &lt; shape0_len; ++i) size0 *= shape0[i]; mx_uint output1_index = 1; mx_uint *shape1 = 0; //shape相当于1*5的向量 mx_uint shape1_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output1_index, &amp;shape1, &amp;shape1_len); size_t size1 = 1; for (mx_uint i = 0; i &lt; shape1_len; ++i) size1 *= shape1[i]; std::vector&lt;float&gt; data0(size0); assert(0 == MXPredGetOutput(pred_hnd, output0_index, &amp;(data0[0]), size0)); std::vector&lt;float&gt; data1(size1); assert(0 == MXPredGetOutput(pred_hnd, output1_index, &amp;(data1[0]), size1)); // Print Output Data printf("output0:\n"); PrintOutputResult(data0); printf("output1:\n"); PrintOutputResult(data1); // Release Predictor MXPredFree(pred_hnd); return 0;&#125; 训练模板用目标模型举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx = gpu()net = nn.HybridSequential()with net.name_scope(): net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(32))net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/TargetModel/validation_normalization_Target.h5', 'r')X_val_h5 = nd.array(val_file["Input"][:]).as_in_context(ctx)y_val_h5 = nd.array(val_file["Output"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/TargetModel/training_normalization_Target.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx)) loss = square_loss(output, batch.label[0].as_in_context(ctx)) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch%100==0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) val_loss = nd.mean(square_loss(net(X_val_h5), y_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('TargetModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") 导入测试1234567891011import mxnet as mxfrom mxnet.gluon import nnfrom collections import namedtuplesym = mx.symbol.load('TargetModel-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,1+523))])mod.load_params('TargetModel-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([range(1+523)])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() 用连接模型举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx=gpu()class JoinModel(nn.HybridBlock): def __init__(self, **kwargs): super(JoinModel, self).__init__(**kwargs) self.encodeNet=nn.HybridSequential() self.decodeNet=nn.HybridSequential() self.fc=nn.HybridSequential() with self.name_scope(): self.encodeNet.add(nn.Dense(128,activation="relu")) self.encodeNet.add(nn.Dense(128)) self.decodeNet.add(nn.Dense(128,activation="relu")) self.decodeNet.add(nn.Dense(32)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(32)) def hybrid_forward(self,F,text,history): temp = self.encodeNet(text) result1 = self.decodeNet(temp) result2 = self.fc(F.concat(history, temp, dim=1)) return [result1,result2]net = JoinModel()net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/JoinModel/validation_normalization_Join.h5', 'r')text_val_h5 = nd.array(val_file["Input1"][:]).as_in_context(ctx)history_val_h5 = nd.array(val_file["Input2"][:]).as_in_context(ctx)UnitVec_val_h5 = nd.array(val_file["Output1"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/JoinModel/training_normalization_Join.h5', 'r') as h5file: text_h5 = h5file["Input1"] history_h5 = h5file["Input2"] UnitVec_h5 = h5file["Output1"] num_examples=text_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter([text_h5,history_h5], UnitVec_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx),batch.data[1].as_in_context(ctx)) loss1 = square_loss(output[0], batch.label[0].as_in_context(ctx)) loss2 = square_loss(output[1], batch.label[0].as_in_context(ctx)) loss = loss1+loss2 loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch % 100 == 0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) res = net(text_val_h5,history_val_h5) val_loss = nd.mean(square_loss(res[0],UnitVec_val_h5)+square_loss(res[1],UnitVec_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('JoinModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") 导入测试12345678910111213141516import mxnet as mxfrom mxnet import ndimport numpy as np############## Re-importing the net ##############print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('JoinModel-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,524)),('data1',(1,128))])mod.load_params('JoinModel-0000.params')Batch=namedtuple('Batch',['data'])x = nd.random.normal(shape=(1,524))y = nd.random.normal(shape=(1,128))mod.forward(Batch(data=[x,y]),is_train=False)print mod.get_outputs()print sym.list_outputs() 配置C++平台 在C++/常规中添加“附加包含目录”，即工作目录，方便定位c_predict_api.h的位置。如果能成功#include的话，不设置也行 在链接器/输入中增加“附加依赖项”，即libmxnet.lib 修改“活动解决方案平台”为x64 拷贝libmxnet.dll和libmxnet.lib和c_predict_api.h到工作目录 cpp文件加入#include &lt;c_predict_api.h&gt; C++使用指南 可运行单输入单输出 默认采用预测方式 可运行多输入多输出 默认采用预测方式 可运行多输入多输出，但是在输出端口可以只输出一个端口的数据 修改预测支持一个mini-batch只需要修改input_shape_data中的batch_size，并且将一个mini-batch的输入数据压平送进网络。在设置输入输出端口的vector的大小时候都要把它设置为一个batch数据长度的batch_size倍 MXNet源码阅读io.py位于E:\Anaconda\envs\gluon\Lib\site-packages\mxnet阅读如何自定义迭代器]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Python</tag>
        <tag>MXNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mathematica]]></title>
    <url>%2F2018%2F07%2F27%2FMathematica%2F</url>
    <content type="text"><![CDATA[设置问题没有图形化界面的机器导出图像计算机是Linux服务器, 无图形化界面链接How to save Image or Graphics in Terminal? sudo apt-get install xvfb xvfb-run wolfram此时运行这个代码就正常了 12p=Graphics@Circle[];Export["test.jpg",p]; 状态栏显示时间格式-&gt;选项设置（快捷键Ctrl+Shift+O），显示选项值选择全局偏好，搜索 EvaluationCompletionAction，将其设置为“ShowTiming”,笔记本下方的状态栏就会显示每次运行代码的消耗时间了。 当用到GPU并且执行wolframscript的语法是：CUDA_VISIBLE_DEVICES=1 xvfb-run wolframscript -file test.wl 基础知识原子表达式不能替换头部因为1是原子表达式，所以f不能替换掉它的头部1234Apply[f, &#123;&#123;g[1], g[a]&#125;, &#123;g[2], g[b]&#125;, &#123;g[3], g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;f[1], f[a]&#125;, &#123;f[2], f[b]&#125;, &#123;f[3], f[c]&#125;&#125; *)Apply[f, &#123;&#123;1, g[a]&#125;, &#123;2, g[b]&#125;, &#123;3, g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;1, f[a]&#125;, &#123;2, f[b]&#125;, &#123;3, f[c]&#125;&#125; *) 函数式指令Gather将相同元素收集在一起12345Gather[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First[#1] == First[#2] &amp;](*or*)GatherBy[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First](*&#123;&#123;&#123;a, 1&#125;, &#123;a, 2&#125;&#125;, &#123;&#123;b, 1&#125;, &#123;b, 3&#125;&#125;, &#123;&#123;d, 1&#125;&#125;&#125;*) 表格排版 新版可以不用设置Partition,Grid组合起来用那么麻烦，因为Partition要考虑是怎么划分的Multicolumn[Range[50], 6] 旧版Grid@Partition[Range[50], 6, 6, 1, &quot;&quot;] 尽量用Grid排版，而不是Row+Column1Column[Row[#, " "] &amp; /@ &#123;&#123;asa, b, c&#125;, &#123;x, y, z&#125;, &#123;adaasd, 1, 2&#125;&#125;] 显得非常的不整齐但是Grid就没问题 可以对齐1Grid[&#123;&#123;asa, b, c&#125;, &#123;x, y, z&#125;, &#123;adaasd, 1, 2&#125;&#125;] 数学运算求出最大/小元素的位置求出最小元素的位置用Ordering[lis, 1];求出最大元素的位置用Ordering[lis, -1] 矩阵重复再拼接 类似numpy的tail函数1ArrayFlatten[&#123;ReplicateLayer[4]@mat&#125;] // TraditionalForm 数学证明 文件管理列出文件夹下的文件列出当前目录和子目录下所有后缀为nb的文件1FileNames["*.nb","*",Infinity] 得到BaseName12FileBaseName["C:\\Users\\xzhou\\Desktop\\test.gif"](*test*) 保存mma表达式12345678FilePrint @ Export["test.wl", Solve[x^2 + a x + 1 == 0, x]](*Or*)file = "test.wl"If[FileExistsQ[#], DeleteFile[#]]&amp; @ file;FilePrint @ Save[file, Solve[x^2 + a x + 1 == 0, x]];(*Or*)(*Compress is very nice for expression can't directly saved to file*)Export[file, Compress@Encrypt["my pass", "short text"], "Text"] 可视化CoordinateBoundingBoxArray输入边界坐标，自动均匀填充边界内的点坐标12CoordinateBoundingBoxArray[&#123;&#123;3, -1&#125;, &#123;8, 2&#125;&#125;];Graphics[Point[Flatten[%, 1]], Frame -&gt; True] 在MatrixPlot和Graphics中插入文字考虑Epilog选项和Inset图元 自动给曲线图打标签1ListLinePlot[RandomReal[1, 26] -&gt; CharacterRange["a", "z"]] 给特定点上特定颜色 Style封装这里输出{0,0.5,1}是因为它Rescale了{1,2,3}不想规整需要设置ColorFunctionScaling-&gt;False123ListPlot[Values@&lt;|a -&gt; Style[1, Red], b -&gt; Style[2, Green], c -&gt; Style[1, Blue]|&gt;, ColorFunction -&gt; Function[&#123;v&#125;, Print[v]; ColorData["Rainbow", v]]] 可以看到颜色函数并没有看到“颜色”，只看到了数值，为了特定点上特定色必须用Style封装最简单形式1ListPlot[&#123;Style[1, Red], Style[2, Green], Style[3, Blue]&#125;] 不过对于Raster可以另辟蹊径，因为它可以这么做12col = &lt;|'a'-&gt;Red, 'b'-&gt; Green, 'c'-&gt;Blue|&gt;;Raster[&#123;data&#125;, ColorFunction -&gt; (ColorData["Rainbow", col[#]] &amp;)] 当然它支持Association，不过只能画出对应label而不是颜色1ListPlot[&lt;|Red -&gt; 1, Green -&gt; 2, Blue -&gt; 3|&gt;] 音频函数语音合成Speak可以让Mma说话，SpokenString可以显示说话的内容 让Audio自动播放声音：最后的参数”Play”可以换成Pause Stop之类的12au = ExampleData[&#123;"Sound", "Violin"&#125;];Audio`Internals`Execute[ Audio`Internals`GetAudioManager[ Audio`AudioInformation[au, "AudioID"]], "Play"] 得到Audio文件此时的播放位置1id =Audio`AudioInformation[song, "AudioID"];mngr = Audio`Internals`GetAudioManager[id];Dynamic@Audio`AudioDump`getGUIInfo[mngr, "AudioPosition"] 计算音频的能量123456a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "RMSAmplitude"](*实际上度量的是均方误差a // AudioData // #^2 &amp; // Mean // Sqrt*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Power"](*实际上度量的是 a // AudioData // #^2 &amp; // Mean*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Loudness"](*实际上度量的是 a // AudioData // #^2 &amp; // Mean // #^0.67 &amp;*) 常用替换Audio Sound1234(*Audio-&gt;Sound*)Audio@s(*Sound-&gt;Audio*)Sound[SampledSoundList[First@AudioData[#], QuantityMagnitude@AudioSampleRate@#]]@a List Association1234(*List-&gt;Association*)Association[&#123;1 -&gt; 2, 2 -&gt; 3&#125;](*Association-&gt;List*)Normal@&lt;|1 -&gt; 2, 2 -&gt; 3|&gt; 替换123456(*函数式 &#123;1-&gt;2,2-&gt;3&#125; -&gt; &#123;&#123;1,2&#125;,&#123;2,3&#125;&#125;*)List@@@&#123;1-&gt;2,2-&gt;3&#125;(*规则式 谢谢xzcyr和Alexander0620提供的解法*)&#123;1 -&gt; 2, 2 -&gt; 3&#125; /. Sequence[x_ -&gt; y_] -&gt; &#123;x, y&#125;(*或者*)&#123;1 -&gt; 2, 2 -&gt; 3&#125; /. Rule -&gt; List Dataset深入、退出运算符值得注意的是TakeLargestBy是深入运算符，TakeLargest是退出运算符。 在后面的运算符应用到更深一层之前，“深入”运算符被应用到原始数据集相应的部分. 深入运算符的特点是在作用于某一层时，它们不会改变数据更深层次的结构. 这确保后面的运算符操作时，子表达式的结构和原始数据集的相应层次是一样的. 最简单的深入运算符是 All，它选取某个给定层的所有部分，因此不会改变该层数据的结构 在所有随后的运算符完成对深层数据的操作后，“退出”运算符被应用.因此dataset[f,g]是Query[f, g] // Normal,也就是Map[g] /* f .深入运算符对应于原始数据的层，而退出运算符对应于结果的层. 和深入运算符不同，退出运算符不必保持所操作数据的结构. 如果一个运算符没有被明确指定为深入运算符，假定其为退出运算符 data[SortBy[#x - #y &amp;], Total, #^2 &amp;]是深入、退出1、退出2运算符，因此先应用深入运算符，再应用#^2 &amp;，再应用Total 数据分析或处理利用SQL语法查询数据sales = SemanticImport[&quot;ExampleData/RetailSales.tsv&quot;]sales[All, &quot;Sales&quot;]得到Sales列的所有数据因为All是深入运算符，可以安全的更换为其他深入运算符，如sales[Mean, &quot;Sales&quot;] // N这时候如果想再针对月份和星期几排序可以这样：12sales[GroupBy[DateValue[#Date, "Month"] &amp;], GroupBy[DateValue[#Date, "DayName"] &amp;], Mean, "Sales"] 聚类 ClusteringComponents的第二个参数意思是聚类个数为3类，第三个参数将第一层数据视为一个样本 归一化数据对数据（矩阵）做归一化，数据每行是一个样本，每一列是一个特征均值文件存储的也是矩阵。第一行是最小值，第二行是最大值若只对矩阵第一维归一化1data1[[All, 1]] = (data1[[All, 1]] - meanInput[[1, 1]])/(meanInput[[2, 1]] - meanInput[[1, 1]]); 若对矩阵的每一维做归一化1mat = (# - meanOutput[[1]])/meanOutput[[2]] &amp; /@ mat; 实用小功能美化输出GeneralUtilities`PrettyForm可以美化输出 导出矢量图SVG和wmf文件可以输出矢量图，wmf适合visio 将PDF中的段落变成一行，方便谷歌翻译使用先复制段落再粘贴进mma执行以下代码1StringDelete[text, "\n"] // CopyToClipboard 当然CopyToClipboard可以直接拷贝数据至剪贴板，也对复制图片是极好的 导出数学公式至Stack Exchange例如http://math.stackexchange.com公式选择复制为Latex格式 然后在前后加上$就行了1$c=\sqrt&#123;a^2-2 a b \cos (\theta )+b^2&#125;$ 导出含有Alpha通道的图片12img//Binarize//ColorReplace[#,Black-&gt;Red]&amp;Export["img.gif",%,"TranspararentColor"-&gt;White] 导入导出导入导入lst文件（每行均为数字构成）Import[filename,&quot;List&quot;]导入lst文件（每行均为字符串构成）Import[filename,&quot;Lines&quot;]导入纯文本构成的矩阵 Import[filename,&quot;Table&quot;]导入浮点数二进制文件 BinaryReadList[filename,&quot;Real32&quot;] 如果一些tsv文件导入乱码比如使用Import[filename,&quot;Table&quot;可以尝试123Import[&quot;/Users/xzhou/python/nvshens/Girls.lst&quot;, &quot;TSV&quot;](*Or*)StringSplit[StringSplit[#, &quot;\n&quot;], &quot;\t&quot;] &amp; @ Import[filename,&quot;Text&quot;,Character-&gt;&quot;UTF8&quot;] 文件流控制以二进制文件形式导入Import不会引入新的流，简单但是灵活性低12Import["test.exe", "Byte"] // LengthStreams[] // Length (*2，证明只有输出流stdout和错误流stderr*) OpenRead 如果用完关闭流也不会引入新的流，稍复杂但是灵活性高1234567file = OpenRead["test.exe", BinaryFormat -&gt; True];Length@Reap[ While[(tempRecord = BinaryRead[file]) =!= EndOfFile, Sow@tempRecord]][[2, 1]]Close[file];Streams[] // Length (*2，证明只有输出流stdout和错误流stderr*) 不管是BinaryReadList还是BinaryRead都会改变流指针的位置： Mathemtica向文件追加二进制数据123456file = "test.dat";str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[12], "Real32"];BinaryWrite[str, Range[15,30], "Real32"];Close[str]; BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30} 继续追加12345str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[5], "Real32"];BinaryWrite[str, Range[10, 15], "Real32"];Close[str];BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 10, 11, 12, 13, \14, 15} 不导出也查看导出的效果比如ExportString[{1, {1, 2, 3}}, &quot;Table&quot;]输出的效果就是Export[&quot;test.txt&quot;,{1, {1, 2, 3}}, &quot;Table&quot;]打开后的效果 单元 笔记本在单元中启用动态1TextCell[Dynamic[ Refresh[DateString[], UpdateInterval -&gt; 1]], "Subsection"] 时序数据TimeSeries的头部依然是TemporalData1234v = &#123;2, 1, 6, 5, 7, 4&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; ts = TimeSeries[v, &#123;t&#125;]Head[ts](* TemporalData *) 两条路径使用 TemporalData而不是TimeSeries1234s1 = &#123;2, 1, 6, 5, 7, 4&#125;; s2 = &#123;4, 7, 5, 6, 1, 2&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; td = TemporalData[&#123;s1, s2&#125;, &#123;t&#125;] Differences和Accumulate可以用于 TemporalData，但是要注意采样是否均匀的问题 打开数据库文件（SQLite）1234567Needs["DatabaseLink`"];JDBCDrivers["SQLite"];conn = OpenSQLConnection[JDBC["SQLite"], "log.db"];data = SQLExecute[conn, "SELECT * FROM log"];SQLColumnInformation[conn] // TableFormSQLExecute[conn,"select detail from log where name=\"群组消息\" and detail like \"群：123456789\""]CloseSQLConnection[conn];]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>Mathematica</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow]]></title>
    <url>%2F2018%2F07%2F26%2FTensorflow%2F</url>
    <content type="text"><![CDATA[Keras与Tensorflow联动123456789101112131415161718192021222324252627282930313233343536import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist_data = input_data.read_data_sets('MNIST_data/', one_hot=True)# Building modelimg = tf.placeholder(tf.float32, shape=(None, 784))labels = tf.placeholder(tf.float32, shape=(None, 10))x = tf.keras.layers.Dense(128, activation='relu')(img)x = tf.keras.layers.Dense(128, activation='relu')(x)prediction = tf.keras.layers.Dense(10)(x)loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))train_optim = tf.train.AdamOptimizer().minimize(loss)#Print model name and shapefor i in tf.trainable_variables(): print '&#123;&#125;\t&#123;&#125;\t&#123;&#125;'.format(i.name,i.shape,i.dtype)#dense/kernel:0 (784, 128) &lt;dtype: 'float32_ref'&gt;#dense/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_1/kernel:0 (128, 128) &lt;dtype: 'float32_ref'&gt;#dense_1/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_2/kernel:0 (128, 10) &lt;dtype: 'float32_ref'&gt;#dense_2/bias:0 (10,) &lt;dtype: 'float32_ref'&gt;# Train modelwith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for _ in range(1000): batch_x, batch_y = mnist_data.train.next_batch(50) sess.run(train_optim, feed_dict=&#123;img: batch_x, labels: batch_y&#125;) acc_pred = tf.keras.metrics.categorical_accuracy(labels, prediction) pred = sess.run(acc_pred, feed_dict=&#123;labels: mnist_data.test.labels, img: mnist_data.test.images&#125;) print('accuracy: %.3f' % (sum(pred)/len(mnist_data.test.labels))) Tensorflow如何处理训练模式、测试模式DropOut层和BN层都有训练模式、测试模式。DropOut层：设立一个placeholder，设置训练时一个数，测试时设置为0phase = tf.placeholder(tf.bool, name=&#39;phase&#39;)BN层： Boardcasting机制可以看到b的维度竟然和a的最后一维一致因为tf.nn.conv2d只计算卷积的部分，不自动添加bias偏置。所以要这样tf.nn.relu(tf.nn.conv2d(x,w)+bias)，其中bias的加法需要使用boardcasting 123456import tensorflow as tfa=tf.constant(1,shape=[2,3,5])b=tf.constant(range(5))with tf.Session() as sess: tf.global_variables_initializer().run() print sess.run(a+b) [[[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]] [[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]]] 模型相关载入模型1234trainable = tf.trainable_variables()optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt') 载入多模型 交替循环不同部分123456789101112131415161718192021222324trainable = tf.trainable_variables()trainable_DNN = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"DNN_part")trainable_WaveNet = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"wavenet_part")optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)optim_DNN = optimizer.minimize(loss, global_step=global_step, var_list=trainable_DNN)optim_WaveNet = optimizer.minimize(loss, global_step=global_step, var_list=trainable_WaveNet)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt')DNN_saver = tf.train.Saver(trainable_DNN)DNN_saver .restore(sess, './logdir/DNN_part/Unit2Vec.ckpt')WaveNet_saver = tf.train.Saver(trainable_WaveNet)WaveNet_saver.restore(sess, './logdir/WaveNet_part/Unit2Vec.ckpt')#part 1-&gt;3-&gt;2-&gt;3-&gt;2-&gt;3...if step &lt; 10: #turn round every 10 steps #part 1 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim])elif int(step/10) % 2 == 0: #part 2 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_WaveNet])elif int(step/10) % 2 == 1: #part 3 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_DNN])else: raise ValueError(x) 队列机制入队的方式有两种，enqueue和enqueue_many。一般采取第一种出队的方式有两种，dequeue和dequeue_many。一般采取第二种，这相当于dequeue出来的数据是一个batch RandomShuffleQueue创建一个随机队列，表示出队的是随机的，但是当使用RandomShuffleQueue时如果shape不明确指定具体大小，dequeue_many是禁用的。 enqueue这里首先创建了一个10个箱子（每个箱子可以放两个物品，第一种物品是5*2的矩阵，第二种是5*3的矩阵）的队列，要求min_after_dequeue为7个箱子，也就是最多只可以deque出三个箱子。循环中入队了十次，使得队列为满箱状态，所以dequeue_many(3)刚好不阻塞。 12345678910111213141516171819import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=7, dtypes=[tf.int32, tf.int32], shapes=[(5,2),(5,3)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[5,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[5,3])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data1 = np.arange(i,i+10).reshape(-1,2) data2 = np.arange(i,i+15).reshape(-1,3) sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) [array([[[ 3, 4], [ 5, 6],[ 7, 8], [ 9, 10], [11, 12]], [[ 9, 10],[11, 12],[13, 14], [15, 16], [17, 18]], [[ 5, 6],[ 7, 8], [ 9, 10], [11, 12], [13, 14]]], dtype=int32), array([[[ 3, 4, 5],[ 6, 7, 8],[ 9, 10, 11],[12, 13, 14],[15, 16, 17]], [[ 9, 10, 11],[12, 13, 14],[15, 16, 17],[18, 19, 20],[21, 22, 23]], [[ 5, 6, 7],[ 8, 9, 10],[11, 12, 13],[14, 15, 16],[17, 18, 19]]], dtype=int32)] 可以看到返回两种箱子，一般我们会将这个返回值赋值给tuples,比如把代码最后一句改为(col2,col3) = sess.run(dequeue)。这样col2和col3就可以作为数据供给网络使用 enqueue_many这里首先创建了一个10个箱子（每个箱子放两种物品，第一个物品是一个长度为2的数组，第二个物品是长度为3的数组）的随机队列。使用enqueue_many相当于一次性填充多个箱子。现在一次性填充10个箱子让队列满箱，因为min_after_dequeue是7所以最多只能弹出3个箱子,否则阻塞。 123456789101112131415161718import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=7, dtypes=[tf.int32, tf.int32], shapes=[(2,),(3,)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[10,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[10,3])enqueue_op = input_queue.enqueue_many([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue data1 = np.arange(20).reshape(10,2) data2 = np.arange(30).reshape(10,3) sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) PaddingFIFOQueue支持变化的shape，同时支持dequeue_many!12345678910111213141516171819import tensorflow as tfimport numpy as npinput_queue = tf.PaddingFIFOQueue(capacity=10, dtypes=[tf.int32, tf.int32], shapes=[(None,2),(None,3)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[None,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[None,3])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data1 = np.arange(2*(i+1)).reshape(-1,2)+i data2 = np.arange(3*(i+1)).reshape(-1,3)+i sess.run(enqueue_op,feed_dict=&#123;placeholder1:data1, placeholder2:data2&#125;) print sess.run(dequeue) [array([[[0, 1],[0, 0],[0, 0]], [[1, 2],[3, 4],[0, 0]], [[2, 3],[4, 5],[6, 7]]], dtype=int32), array([[[ 0, 1, 2],[ 0, 0, 0],[ 0, 0, 0]], [[ 1, 2, 3],[ 4, 5, 6],[ 0, 0, 0]], [[ 2, 3, 4],[ 5, 6, 7],[ 8, 9, 10]]], dtype=int32)] 发现了什么吧，就是它补零了。小小说些题外话，你见过np.array([[1],[1,2],[1,2,3]])的返回值吗？没吧，是Object而不是int64。因为numpy不支持，但是python本身支持[[1],[1,2],[1,2,3]]。这就不如Mathematica了,表扬一下顺便推荐这个语言！ 如果改成dequeue = input_queue.dequeue_many(1)，一次只出一个箱子那么就不会出现补零情况了。所以补零发生在sess.run(dequeue)的时候 甚至它还支持shape完全不定的情况12345678910111213141516import tensorflow as tfimport numpy as npinput_queue = tf.PaddingFIFOQueue(capacity=10,dtypes=[tf.int32], shapes=[(None,None)])placeholder = tf.placeholder(dtype=tf.int32, shape=[None,None])enqueue_op = input_queue.enqueue([placeholder])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(10): data = np.arange((i+1)**2).reshape(i+1,i+1)+i sess.run(enqueue_op,feed_dict=&#123;placeholder:data&#125;) print sess.run(dequeue) [[[ 0 0 0] [ 0 0 0] [ 0 0 0]] [[ 1 2 0] [ 3 4 0] [ 0 0 0]] [[ 2 3 4] [ 5 6 7] [ 8 9 10]]] 函数会话注册sess=tf.InteractivateSession()表示将是这个创建的session作为随后默认的session，之后的运行也运算也在这里面进行 列出当前每个节点使用的device使用的是tf.Session(config=tf.ConfigProto(log_device_placement=True)) 各种loss函数tf.losses.mean_squared_error理解123456789101112131415161718192021import tensorflow as tfimport numpy as npshape_obj = (5,6,3)Y1 = tf.random_normal(shape=shape_obj)Y2 = tf.random_normal(shape=shape_obj)loss1 = tf.reduce_sum(tf.pow(Y1 - Y2, 2)) / (reduce(lambda x, y: x*y, shape_obj))loss2 = tf.reduce_mean(tf.squared_difference(Y1, Y2))loss3 = tf.losses.mean_squared_error(predictions=Y1, labels=Y2)loss4 = tf.nn.l2_loss(Y1 - Y2)with tf.Session() as sess: #不需要初始化 lis = sess.run([Y1, Y2, loss1, loss2, loss3, loss4]) Y1, Y2 = lis[:2] #Y1, Y2 print lis[2:] #loss1, loss2, loss3, loss4 lis=[] for i in range(shape_obj[-1]): lis.append(np.mean(np.square((Y1[:,:,i]-Y2[:,:,i])))) print np.mean(lis) [2.0185342, 2.0185342, 2.0185342, 90.83404]2.018534 可以看到tf把最后一维（shape_obj 是二维也是一样）当做batch_axis，而且loss没有除以2在Gluon里就相当于：loss1=gluon.loss.L2Loss(batch_axis=-1)*2还发现一个问题就是sess.run(想要的必须写在一起)，如果sess.run(loss1);sess.run(loss1)结果也会不一样，因为每运行一次run计算图就运行一次，因为每次运行的随机数不一样，结果自然也不一样 12345678910111213141516import mxnet as mxfrom mxnet import gluonimport numpy as np#Indicate 2-th dims as batch_axisloss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,5,4))b=mx.nd.random.uniform(0, 10,shape=(3,5,4))print loss1(a,b)#[ 4.95132017 11.42089748 7.28211212 6.8867259 6.93179274]#&lt;NDArray 5 @cpu(0)&gt;lis=[]for i in range(5): lis.append(1./2*np.mean(np.square((a[:,i,:]-b[:,i,:]).asnumpy())))print lis#[4.9513201713562012, 11.420897483825684, 7.282111644744873, 6.886725902557373, 6.9317927360534668] tf.losses.sparse_softmax_cross_entropy理解sparse_softmax_cross_entropy要求labels是一个整数列表形式，范围是[0, num_classes], logits是一个浮点数据，存储的是网络输出的值 MXNet和tf结果一样，说明在二维数据的时候，都是将第一维作为batch_axis,类别总数可以从Y1.shape[1]知道123456789101112131415161718import tensorflow as tfimport numpy as npY1 = tf.constant(np.arange(50).reshape((5,10)),dtype=tf.float32)Y2 = tf.constant([5,3,2,9,1])Y3 = tf.one_hot(Y2, depth = Y1.shape[1])loss1 = tf.losses.sparse_softmax_cross_entropy(logits=Y1, labels=Y2)loss2 = tf.losses.softmax_cross_entropy(logits=Y1, onehot_labels=Y3)loss3 = tf.nn.softmax_cross_entropy_with_logits(logits=Y1, labels=Y3)loss4 = tf.reduce_mean(loss3)with tf.Session() as sess: [loss1,loss2,loss3,loss4] = sess.run([loss1,loss2,loss3,loss4]) print loss1,loss2 #5.4586296, 5.4586296 print loss3.shape #(5,) print np.mean(loss3) #5.4586296 print loss4 #5.4586296''' 用MXNet来验证1234567import mxnet as mximport numpy as nploss=mx.gluon.loss.SoftmaxCrossEntropyLoss()a=mx.nd.array(np.arange(50).reshape((5,10)))b=mx.nd.array([5,3,2,9,1])print loss(a,b)print mx.nd.mean(loss(a,b))#5.45862961 数据操作tf.one_hot()tf.one_hot([[0,1],[2,3]],depth=5)得到的数据维度是(2,2,5)tf.one_hot([[[0,1],[2,3]],[[0,1],[2,3]]],depth=5)得到的数据维度是(2,2,2,5) tf.unique和tf.unique_with_counts函数类似于mma的{1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4} // Counts功能12345678910111213import tensorflow as tfimport numpy as npY1 = tf.constant([5,5,1,2,2,4,4,4,3,3])Y2 = tf.unique(Y1)Y3 = tf.unique_with_counts(Y1) #Can Count valuewith tf.Session() as sess: [Y2,Y3] = sess.run([Y2,Y3]) print Y2 # Unique(y=array([5, 1, 2, 4, 3], dtype=int32),idx=array([0, 0, 1, 2, 2, 3, 3, 3, 4, 4], dtype=int32)) print Y3 # UniqueWithCounts(y=array([5, 1, 2, 4, 3], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 3, 3, 4, 4], dtype=int32), count=array([2, 1, 2, 3, 2], dtype=int32)) 实现左移一个数，最右补零将[[0],[1],[2],[3]]-&gt;[[1],[2],[3],[0]]12345678import tensorflow as tfencoded = tf.reshape(tf.constant(range(4)),[1,-1,1])shifted = tf.slice(encoded, [0, 1, 0],[-1, tf.shape(encoded)[1] - 1, -1])shifted = tf.pad(shifted, [[0, 0], [0, 1], [0, 0]])with tf.Session() as sess: print sess.run([encoded,shifted]) tf.conv1D输入的shape是（batch_size, width1, in_channel）卷积核的shape是 （filter_width, in_channel, out_channel）输出是（batch_size, width2, out_channel）123456789101112import tensorflow as tfimport numpy as npx = tf.Variable(np.arange(320).reshape(8,10,4).astype(np.float32))k = tf.Variable(tf.contrib.layers.xavier_initializer_conv2d()(shape=[5,4,16]))conv = tf.nn.conv1d(x, k, stride=1, padding='VALID', data_format='NWC')with tf.Session() as sess: sess.run(tf.global_variables_initializer()) [a, b] = sess.run([x, conv]) print a.shape, b.shape #(8, 10, 4) -&gt; (8, 6, 16) 图像处理完整范例1234567891011121314import tensorflow as tfimport numpy as npfrom PIL import Imageimg = Image.open("1620.jpg")img.show()w, h = img.sizeimg = np.expand_dims(img, 0)bi_image_bilinear = tf.image.resize_bilinear(img, size=(int(h*3), int(w*3)))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: bi_result = sess.run(bi_image_bilinear)Image.fromarray(np.uint8(bi_result)).show() tf.image.resize*tf.image.resize_nearest_neighbor [0 1 2] -&gt; [0 0 1 1 2 2]tf.image.resize_bilinear [0 1 2] -&gt; [0 0.5 1 1.5 2 2 ]tf.image.resize_bicubic [0 0.40625 1 1.59375 2 2.09375]123456789import tensorflow as tfimport numpy as npimg = np.arange(3).reshape((1,1,3,1))bi_image_bilinear = tf.image.resize_bilinear(img, size=(1,6))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: print sess.run(bi_image_bilinear) 高阶函数tf.map_fn 类似于map函数，一个迭代器，将函数作用于指定变量上这是例子1：因为elems是(a,b)，lambda的变量必须与其保持一致，所以也是tuple的。因为a,b分别是int32和float32，返回值也是int32和float32的tuple，与elms一致，所以dtype可以省略。1234567891011import tensorflow as tfimport numpy as npdef mean(lis,num): return (tf.reduce_mean(lis[:num]), num)a = tf.constant(np.arange(30).reshape((3,10)), dtype='float32')b = tf.constant([3,6,2],dtype='int32')c = tf.map_fn(fn=lambda (i,j):mean(i,j), elems=(a,b))with tf.Session() as sess: print sess.run(c) 例子2：此时返回值与elms结构不一样，需要明确指明返回值类型1234567891011import tensorflow as tfimport numpy as npdef mean(lis,num): return tf.reduce_mean(lis[:num])a = tf.constant(np.arange(30).reshape((3,10)), dtype='float32')b = tf.constant([3,6,2],dtype='int32')c = tf.map_fn(fn=lambda (i,j):mean(i,j), elems=(a,b), dtype='float32')with tf.Session() as sess: print sess.run(c)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2018%2F07%2F26%2FLinux%2F</url>
    <content type="text"><![CDATA[命令行指令Linux要查看所有和pdf相关的命令 可以输入pdf 再按Tab键 目录 ls -l看当前目录下文件的基本属性 ls -a看隐藏文件 tree可以看到目录树结构 删除文件夹 rm -rf xxx sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/将远程服务器88的文件夹/home/xzhou/project挂载到本机的88_mount/目录下，取消挂载fusermount -u 88_mount/.注意管理员下需要sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/ -o allow_other ln -s /tmp/test1.txt test2.txt 将在当前目录下创建符号文件“test2.txt”，ln -s /tmp/test1.txt 将在当前目录下创建符号文件“test1.txt”。删除链接符号文件语法是rm file或者rm dir Mac对应Windows的按键Command (or Cmd) ⌘Shift ⇧Option (or Alt) ⌥Control (or Ctrl) ⌃Caps Lock ⇪ 文字处理 Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出 PDF相关PDF-&gt;TXTpdftotext可以得到pdf对应的纯文本版本 字体嵌入强制字体嵌入：12pdf2ps template.pdfps2pdf -dPDFSETTINGS=/prepress template.ps file.pdf 验证：pdffonts template.pdf可以看到所有字体已被嵌入 显示PDF信息 (MacOS)12brew install xpdfpdfinfo test.pdf PDF修改作者等metadata (MacOS)12brew install exiftoolexiftool -Title=&quot;Change This Title&quot; -Subject=&quot;Fun and PDF&quot; change_my_meta.pdf 图像处理Mac需要 brew install imagemagick才能使用convert gif转一些列图片（帧为单位） convert test.gif test%05d.png一系列png转视频 ffmpeg -i test%05d.png test.mp4 如果需要将视频速度变慢要加选项 -filter:v &quot;setpts=2.0*PTS&quot;要让符合MP4V2格式需要加选项 -brand mp42比如ffmpeg -i test%05d.png -filter:v &quot;setpts=2.0*PTS&quot; -brand mp42 test.mp4 系统指令 getconf LONG_BIT得到Linux系统是x86还是x32 cat /proc/driver/nvidia/version查看CUDA驱动版本 who -b 查看最后一次系统启动的时间 who -r 查看当前系统运行时间 查看所用的桌面环境 env|grep DESKTOP= lsb_release -a查看系统版本(没有就用yum install lsb或者cat /etc/os-release) 关机 shutdown -r now 增加用户 先登录root用户 adduser xzhou passwd xzhou 似乎不需要 因为第一步输入了密码增加网络资源共享文件夹 sudo nano /etc/samba/smb.conf sudo smbpasswd -a xzhou sudo service smbd restart 显卡 GPU计算 watch -n 1 nvidia-smi 每秒刷新一次 nvidia-smi 进程 ps ax | grep python 可以看到其他人在运行的Python代码 已知PID查看指令所在目录：lsof -p PID|grep cwd kill -s 9 PID 强制杀死进程标识号PID的进程 已知PID如何查看完整指令:ps PID 已知端口查进程是 lsof –i:端口号 工具 实时查看网速 sudo apt-get install nethogs &amp; sudo nethogs 查看公网IP curl api.ipify.org 查看私有IP ifconfig 安装VNC-serverps -ef|grep -i vnc 查看正在运行的vncserver的进程vncserver -kill :1 #关闭这个连接vncserver :1 重启vncserver 美化和汉化man汉化 sudo apt-get install sudo !!-zh 查看man 手册安装到哪里，dpkg -L manpages-zh | less查看到安装在/usr/share/man/zh_CN 设一个中文man别名, 修改 ~/.bashrc 添加一个alias :alias cman=&#39;man -M /usr/share/man/zh_CN&#39;，或者用命令sed -i &#39;$a alias cman=&quot;man -M /usr/share/man/zh_CN&quot;&#39; .bashrc(在最后一行后增加一行，并写入文件) source ~/.bashrc 重启终端 cman ls就是汉化的man，man ls就是英文的man##美化 sudo apt-get install most 修改 ~/.bashrc 添加一个环境变量 :export PAGER=&quot;/usr/bin/most -s&quot;,或者用命令sed -i &#39;$a export PAGER=&quot;/usr/bin/most -s&quot;&#39; .bashrc(在最后一行后增加一行，并写入文件) source ~/.bashrc 重启终端 man ls就是英文的美化版的man 小技巧让上一个命令以管理员身份执行apt-get install ranger然后报权限不足再敲入sudo !!运行上一条命令 快捷键命令行日常系快捷键 Ctrl + U - 剪切光标前的内容Ctrl + K - 剪切光标至行末的内容Ctrl + Y - 粘贴Ctrl + E - 移动光标到行末Ctrl + A - 移动光标到行首Ctrl + F - 跳向下一个空格Ctrl + B - 跳回上一个空格Alt + Backspace - 删除前一个单词Ctrl + W - 剪切光标后一个单词Shift + Insert - 向终端内粘贴文本 暂停并在后台运行命令Ctrl + Z - 暂停应用程序（比如正在用nano编辑test.txt）fg - 重新将程序唤到前台jobs - 查看任务数目只要按Ctrl + Z，前台的命令就会暂停，画面就切回到命令行了。然后你就能运行你想要运行的命令，等命令运行完后在终端窗口输入fg就可以回到先前暂停的任务 下载普通下载使用axelapt-get install axel使用简单 axel URL我常用的指令:多线程(10个)下载并改变进度条样式：axel -n 32 -a URL 下载视频使用you-get和youtube-dl以及硕鼠从Youtube视频中下载音频（wav格式）支持b站youtube-dl –extract-audio –audio-format wav URL 比如我想下载这个情非得已的音频 使用python3安装you-get you-get http://www.miaopai.com/show/R~22buLsn55r7IVQKvMjZ4Le2mJ7PS7BqxjbAg__.htm ffmpeg -i 阿卡贝拉版情非得已.mp4 -f mp3 -vn 阿卡贝拉版情非得已.mp3参数解释：-i 表示input，即输入文件-f 表示format，即输出格式-vn表示vedio not，即输出不包含视频 play 阿卡贝拉版情非得已.mp3 (需要安装sox库) 后台下载视频如果现在很多个b站视频需要下载，是不是就是CTRL + Z and fg 结合 youtube-dl，实践发现不行，挂起时下载会暂停。之前我玩过树莓派，很多Linux知识都是从那里学到的 所以我发现了screen命令. MacOS是自带的,Linux使用sudo apt-get install screen安装 终端输入（Xshell软件里操作一样的）:1screen youtube-dl --extract-audio --audio-format mp3 https://www.bilibili.com/video/av6846882 它会下载第一个视频，这时候按住Ctrl+A+D会回到终端，但是视频依然在下载，这时候再次终端输出新的视频PID，就会下载第二个，以此类推… 查看所以任务是screen -ls,所有视频一旦完成下载，screen -ls就会输出No Sockets found in bilibala...。说明一个任务完成它会自动退出那个虚拟终端的 如果我们关闭终端不影响screen，不信你重新打开终端试试screen -ls 恢复一个虚拟终端命令是screen -r ID号 Docker容器 查看当前正在运行的容器 docker ps 显示已经退出的容器 docker ps -a 显示所有镜像 docker images 启动/停止某个容器 docker start/stop 容器ID 删除某个容器 docker rm 容器ID 删除镜像 docker rmi 镜像ID 实践 在容器运行命令 docker run ubuntu cat /etc/os-release，没有这个镜像则创建镜像（用完可删除容器） 开启容器交互模式：docker run -it ubuntu /bin/bash exit退出 查看容器ID docker ps -a 打开交互式终端 docker start -i 容器ID 以后每次使用就使用上面这个命令就行 nano快捷键]]></content>
      <categories>
        <category>常见指令以及用法备忘录</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Mac</tag>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[素材网站]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%B4%A0%E6%9D%90%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[可视化算法 可视化算法网站 旧金山大学的算法课程的可视化 VisuAlgo 极其绚丽，艺术效果似的可视化，用了D3 相应中文版 算法的互动可视化 github 网页版 PCA 介绍算法的Distill 可视化形式的论文 可视化K-Means 还有其他很多算法 交互的 JavaScript可视化好想学HTML5 Canvas呀 好漂亮 比如全是计算机生成的呀 D3 paper.js 各种可视化方案讲解 阿里巴巴的墨者学院 可视化神经网络 计算机视觉历史-The Modern History of Object Recognition 可视化DNN CNN 简易声音素材网站 Find the perfect sound. - soundsnap freesound WebGL 20个不可思议的 WebGL 示例和演示]]></content>
      <categories>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F07%2F26%2FPython%2F</url>
    <content type="text"><![CDATA[使用中文# -*- coding: utf-8 -*- 告诉Python解释器，用UTF-8编码读取源代码print u&#39;中文&#39; u表示Unicode字符串 Python说明Python代码的缩进规则说：最好使用4个空格ipython --pylab 导入了numpy(np) 和 matplotlib 基础知识预备基础知识 若自定义函数没有return，函数执行完毕后返回None 保持字典顺序不变使用OrderedDict 123from collections import OrderedDictprint dict([('a', 1), ('b', 2), ('c', 3)]) #Randomprint OrderedDict([('a', 1), ('b', 2), ('c', 3)]) #Ordered 命令行参数： 12345678import sys if __name__=="__main__": print len(sys.argv) for i in sys.argv: print i,#save as test.py#python test.py #result: 1 2 3 用r’…’来抑制转义比如path = r&#39;C:\xzhou\Desktop&#39; 关于布尔运算Python把0、空字符串’’和None看成 False其他数值和非空字符串都看成 True不过不要完全依赖这一点 List 12345678910L=['Michael', 'Bob', 'Tracy'] # 创建List#可用索引 L [0], L [2], L [-1], L [-3], L [0:3]L [-1::-1] #得到 L 的逆序['Tracy', 'Bob', 'Michael'] L [::-1] #得到 L 的逆序['Tracy', 'Bob', 'Michael'] L [-1:0:-1] #得到['Tracy', 'Bob']L .append('Paul') #改变了LL .insert(0, 'Paul') # 改变了L L 现在为['Paul', 'Michael', 'Bob', 'Tracy', 'Paul']L .pop() #返回'Paul' L 现在为['Paul', 'Michael', 'Bob', 'Tracy'] L .pop(0) #返回'Bob' L 现在为 ['Michael', 'Bob', 'Tracy']L [2] = 'Paul' # L 现在为['Michael', 'Bob', 'Paul'] 迭代列表:123a=range(10)for i in iter(a): print i 列表的拼接（str,tuple也可以这样,dict和set不行）:123456a = []b = [1,]c = [2,3]print a+b+c #[1,2,3]print c * 2 #[2,3,2,3]print []+[[1,2],[3,4]]+[[5,6],[7,8]] #[[1,2],[3,4],[5,6],[7,8]] TupleTuple没有append()方法，也没有insert()和pop()方法。#获取Tuple元素的方式和List一样，可以使用 t[0]，t[-1]等索引方式访问元素，但是不能赋值成别的元素 Tuple和List一样，可以包含 0 个、1个和任意多个元素t = ()对应s=[]t=(1,)对应s=[1], 为了防止歧义而不使用(1) 不过当Tuple包括非Tuple类型时可改变如t = (‘a’, ‘b’, [‘A’, ‘B’])可改变[‘A’, ‘B’]内的元素但t = (‘a’, ‘b’, (‘A’, ‘B’))不可以 dictlen(d)得到字典长度d.get(‘Bart’)得到’Bart’对应的键，不存在返回None1234567891011121314151617d = &#123;'a':[1,2],'b':['hello','xiao',3]&#125;print d.items()# 遍历键for key in d: print key,# 遍历键值for key, value in d.items(): #创建迭代器，效率更高 print key,value# 更快的遍历键值，也省内存for key, value in d.iteritems(): #创建迭代器，效率更高 print key,value# 遍历值for v in d.values(): print v,# 更快速的遍历值，也省内存for v in d.itervalues(): print v, 另外值得注意的是key只能选择不能被改变的数据类型如整数、字符串、Tuple，不能用List set类型因为强调的事并集，所以排序无规律也不支持索引支持 len(s), ‘A’ in s 等 set的内部结构和dict很像，唯一区别是不存储value，因此，判断一个元素是否在set中速度很快。set存储的元素和dict的key类似，必须是不变对象，因此，任何可变对象是不能放入set中的。最后，set存储的元素也是没有顺序的。适用场合：让用户输入星期一至星期日的某天，判断用户的输入是否是一个有效的星期？ 更新set: 增加元素是s.add(‘A’), 删除是s.remove(‘A’), 删除的元素不在set中，remove会报错 定义可变参数函数： 123456def fn(*args): print argsfn() #() fn('a') #('a',)fn('a', 'b') #('a', 'b')fn(['a', 'b']) #(['a', 'b'],) enumerate 很有用的函数，用于索引、迭代 zip()函数可以把两个 list 变成一个 list，类似于转置 12zip([10, 20, 30], ['A', 'B', 'C'])# [(10, 'A'), (20, 'B'), (30, 'C')] 列表生成式： 1234[x * x for x in range(1, 3)] #[1, 4, 9][x * x for x in range(1, 6) if x % 2 == 0] #[4, 16, 36][m + n for m in 'ABC' for n in '123'] #['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3']&#123;phone:i for i, phone in enumerate(set(y))&#125; 搭配字典哦😯 变量可以指向函数： 123456len=abs#len([1,2,3]) 报错print len(-5) #5 说明函数名就是指向函数的变量def g(a,b,f): #高阶函数（可以接受函数的函数） return f(a)+f(b)print g(-3,6,abs) #9 map函数（同Mathematica的Map）：map(lambda i:i**2, [1, 2, 3]) #得到[1, 4, 9] reduce函数（类似Mathematica的Fold）： 12reduce(lambda i,j:i+j, [1,2,3],10) #16 Fold[#1 + #2 &amp;, 10, &#123;1, 2, 3&#125;]reduce(lambda i,j:i+j, [1,2,3]) #6 Fold[#1 + #2 &amp;, &#123;1, 2, 3&#125;] filter函数（类似Mathematica的Select ： 123filter(lambda i:i%2==0, range(10)) #[0, 2, 4, 6, 8] filter(lambda str:str and str.strip()&gt;0, [&apos;test&apos;, None, &apos;&apos;, &apos;str&apos;, &apos; &apos;, ...: &apos;END&apos;])#输出[&apos;test&apos;, &apos;str&apos;, &apos;END&apos;] sorted函数可以用来排序: 123456sorted([1,5,2,5,9]) #输出[1, 2, 5, 5, 9] sorted([1,5,2,5,9],lambda i,j:cmp(j,i)) #输出[9, 5, 5, 2, 1] sorted([1,5,2,5,9],lambda i,j:cmp(i,j)) #输出[1, 2, 5, 5, 9]# Applicationa = ['5_3','2_6','4_9','2_1']sorted(a, key = lambda i: (i.split('_')[0], i.split('_')[1])) 返回函数的函数 1234567def calc_prod(lst): def lazy_prod(): return reduce((lambda x,y: x*y),lst) return lazy_prodf = calc_prod([1, 2, 3, 4])print f() 闭包： 12345678910def count(): fs = [] for i in range(1, 4): def f(): return i fs.append(f) print fs return fsf1, f2, f3 = count() #f1() f2() f3() 都是3 纯函数内加入条件判断lambda x: -x if x &lt; 0 else x 面向对象编程 初始化过程中使用键值对： 12345678910class Person(object): def __init__(self, name, gender, birth, **kw): self.name = name self.gender = gender self.birth = birth for k, v in kw.iteritems(): setattr(self, k, v)xiaoming = Person('Xiao Ming', 'Male', '1990-1-1', job='Student')print xiaoming.name #Xiao Mingprint xiaoming.job #Student decorator装饰器 123456789101112131415161718192021def f1(x): return x*2 def decorator(f): def fn(x): print 'Using decorator...\ncall ' + f.__name__+ '()' return f(x) return fn f1 = decorator(f1) print f1(5) @decorator def f2(x): return x*x print f2(5)#打印出了：#Using decorator... #call f1() #10 #Using decorator...#call f2()#25 编写无参数的decorator装饰器用于记录函数运行效率： 12345678910111213141516import timedef performance(f): def fn(*args, **kw): t1 = time.time() r = f(*args, **kw) t2 = time.time() print 'call %s() in %fs' % (f.__name__, (t2 - t1)) return r return fn@performancedef factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10)#call factorial() in 0.000005s #3628800 偏函数： 12345import functoolssorted_ignore_case = functools.partial(sorted, cmp=lambda s1, s2: cmp(s1.upper(), s2.upper()))print sorted_ignore_case(['bob', 'about', 'Zoo', 'Credit'])#第一个cmp是sorted函数参数中的一个键#输出['about', 'bob', 'Credit', 'Zoo'] 得到元素位置的index函数：index() 函数用于从列表中找出某个值第一个匹配项的索引位置。所以lis.index(min(lis))可以得到最小值的索引，numpy.argmin其实就是干这个的 累加函数python3123456from itertools import accumulatelist(accumulate(range(10)))#[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]import operatorlist(accumulate(range(1,5), operator.mul))#[1, 2, 6, 24] 易错点 type(round(12.3))是float类型 x[a:a+N]实际上x的长度就是N x[:a]+x[a:]==x 0 % N == 0.0 (N != 0) 普通数组是地址传递1234567import numpy as npa = np.arange(10)b = a[3:6]b[2] = 1000# a竟然被b改变了，注意print "a is "+ str(a) #a is [ 0 1 2 3 4 1000 6 7 8 9] print "b is "+ str(b) #b is [ 3 4 1000] python系统管理相关查看python安装目录123import syspath = sys.executableprint(path) pip升级包pip install --pre mxnet-cu80 --upgrade 第三方库scipy包括fft,fftshift,窗函数等信号处理算法 Numpy复数计算X=np.array([1-1j, 1+0.000000000000001j, 4+9j],dtype=complex)X.real得到实部 X.imag得带虚部X.imag[np.abs(X.imag)&lt;0.1]筛选出第二个元素np.unwrap(np.angle(X))可以解卷绕X的相位 索引一般索引a=np.zeros((3,4))a[:,1:3] 得到的是32的矩阵a[:,[1]] 得到的是31的矩阵a[:, 1 ] 得到的是(3,)的数组 根据条件索引符合条件则x否则yAPI:numpy.where(condition[, x, y])1np.where([[True, False], [True, True]], [[1, 2], [3, 4]], [[9, 8], [7, 6]]) array([[1, 8], [3, 4]]) 只有条件的话返回condition.nonzero() 12x = np.arange(9.).reshape(3, 3)np.where( x &gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) 1x[np.where( x &gt; 3.0 )] # Note: result is 1D. array([ 4., 5., 6., 7., 8.]) 1np.where(x &lt; 5, x, -1) # Note: broadcasting. array([[ 0., 1., 2.], [ 3., 4., -1.], [-1., -1., -1.]]) 删除某一维度数据np.delete(arr, 1, axis=0)12arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])np.delete(arr, 1, 0) array([[ 1, 2, 3, 4], [ 9, 10, 11, 12]]) np.delete(arr, np.s_[::2], 1) 用np.s_构造索引 array([[ 2, 4], [ 6, 8], [10, 12]]) np.delete(arr, [1,3,5], None) array([ 1, 3, 5, 7, 8, 9, 10, 11, 12]) all函数1234a=np.arange(-3,3)np.all(abs(a)&lt;5) #Truea=np.arange(-3,6)np.all(abs(a)&lt;5) #False 更改数据类型astype函数如a.astype(np.int32) 普通数组与numpy数组互转12np.arange(3).tolist() #to listnp.asarray([0,1,2]) #to numpy axis的理解123456789a=np.arange(20).reshape(2,10) a.sum(axis=0) #array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])np.diff(a,axis=0) #得到array([[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]]) a.sum(axis=1) #array([ 45, 145])#axis=0把列当做成对处理的对象#axis=1把行当做成对处理的对象 广播机制1234np.array([1,2])*np.array([3,4]) #np.array([3,8]) 行向量的内积 np.array([1,2])*np.array([[3,4],[5,6]]) #np.array([[3,8],[5,12]]) 行向量乘以矩阵 np.array([1,2]).reshape(-1,1)*np.array([[3,4],[5,6]]) #np.array([[3,4],[10,12]]) 列向量乘以矩阵 np.array([[1,2],[3,4]])*np.array([[5,6],[7,8]]) #矩阵的点乘 Element-wisenp.less([1, 2], [2, 2])返回array([True, False], dtype=bool) 行向量列向量的转化12345np.array([1, 2, 3, 4]).reshape((-1, 1)) # &lt;--- THIS IS THE TRICKnp.array([[5, 4]]).Tnp.array([10,20,30]).shape #(3,) 向量np.array([[10,20,30]]).shape #(1,3) 行向量 函数式编程Outer 123m=np.arange(5);n=np.arange(5);a=np.subtract.outer(m,n) #结果和mma一样 Inner 123a = np.arange(12).reshape((4,3))b = [0,1,2,3]np.inner(a, b) #array([ 5, 14, 23, 32]) 结果同MMA 拼接标准数学形式的拼接按列拼接包括向量拼向量 向量拼矩阵 矩阵拼矩阵123456a = np.array([1, 2, 3])b = np.array([2, 3, 4])c = np.vstack((a,b))print c #array([[1, 2, 3], [2, 3, 4]])print np.vstack((a,c)) #array([[1 2 3], [1 2 3], [2 3 4]])print np.vstack((c,c)) #array([[1 2 3], [2 3 4], [1 2 3], [2 3 4]]) 按行拼接包括向量拼向量 向量拼矩阵 矩阵拼矩阵123456a = np.array([[1], [2], [3]])b = np.array([[2], [3], [4]])c = np.hstack((a,b))print c #array([[1, 2], [2, 3], [3, 4]])print np.hstack((a,c)) #array([[1, 1, 2], [2, 2, 3], [3, 3, 4]])print np.hstack((c,c)) #array([[1, 2, 1, 2], [2, 3, 2, 3], [3, 4, 3, 4]]) 仿matlab式拼接123456a = np.array([[1, 2], [3, 4]])b = np.array([[5, 6]])np.concatenate((a, b), axis=0)#array([[1, 2], [3, 4], [5, 6]])np.concatenate((a, b.T), axis=1)#array([[1, 2, 5], [3, 4, 6]]) 多个numpy数组的拼接12np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]#array([[1, 2, 3, 0, 0, 4, 5, 6]]) 数据的填充12a = [1, 2, 3, 4, 5]np.lib.pad(a, (2, 3), 'edge') array([1, 1, 1, 2, 3, 4, 5, 5, 5, 5]) 12a = [[1, 2], [3, 4]]np.lib.pad(a, ((3, 2), (2, 3)), 'minimum') array([[1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [3, 3, 3, 4, 3, 3, 3], [1, 1, 1, 2, 1, 1, 1], 找到数据的unique元素找到数组每个元素出现几次mma代码12&#123;1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4&#125; // Counts&lt;|1 -&gt; 4, 5 -&gt; 2, 3 -&gt; 3, 2 -&gt; 4, 4 -&gt; 1| 保持顺序python使用迭代器函数123from itertools import groupbya = [1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4][len(list(group)) for key, group in groupby(a)] 不保持顺序采用np.unique函数123456a = [1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4]np.unique(a, return_counts=True)#(array([1, 2, 3, 4, 5]), array([4, 4, 3, 1, 2]))from collections import CounterCounter(a)#Counter(&#123;1: 4, 2: 4, 3: 3, 5: 2, 4: 1&#125;) matplotlib库等值线图 ContourPlot12345678910111213141516%matplotlib inlineimport matplotlib.pylab as plt def f(x,y): z = (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) return z n = 256 x = np.linspace(-1,1,n)y = np.linspace(-1,1,n)X,Y = np.meshgrid(x,y) fig = plt.figure()surf1 = plt.contourf(X, Y, f(X,Y))fig.colorbar(surf1) 三维图 Plot3D123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure()ax = Axes3D(fig)# X, Y valueX = np.arange(-4, 4, 0.25)Y = np.arange(-4, 4, 0.25)X, Y = np.meshgrid(X, Y) # x-y 平面的网格Z = np.sin(np.sqrt(X ** 2 + Y ** 2))ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('rainbow')) 柱状图1234567891011import matplotlib.pyplot as pltimport numpy as npmu, sigma = 100, 15x = mu + sigma * np.random.randn(10000)hist, bins = np.histogram(x, bins=30)width = 0.9 * (bins[1] - bins[0])center = (bins[:-1] + bins[1:]) / 2plt.bar(center, hist, align='center', width=width)plt.show() 其他可视化库 Seaborn：Seaborn跟matplotlib最大的区别就是它的默认绘图风格和色彩搭配都具有现代美感。由于Seaborn是构建在matplotlib的基础上的，你需要了解matplotlib从而来调整Seaborn的默认参数。 不要用Bokeh和ggplot2，前一个语法兼容不好，晦涩难懂，后一个作者弃坑了且bug多 pygal超美丽，语法超简单，可以直接输出SVG的Tooltip形式的矢量图，但是只能输出SVG格式文件不能直接看图的效果 plotly很美，也是神器之一！致力于交互图表的制作，但是它提供在别的库中很难找到的几种图表类型，比如等值线图，树形图和三维图表。如何离线使用参见Here! 美美哒~但是由于我很熟悉Mathematica，作图基本上就是靠她了。如果是动态图，我使用JavaScript和D3。 可视化大规模数据集的库 Datashader安装conda install -c bokeh datashader 12345678import datashader as dsimport datashader.transfer_functions as tfimport pandas as pddf = pd.read_csv(&apos;user_data.csv&apos;)cvs = ds.Canvas(plot_width=400, plot_height=400)agg = cvs.points(df, &apos;x_col&apos;, &apos;y_col&apos;, ds.mean(&apos;z_col&apos;))img = tf.shade(agg, cmap=[&apos;lightblue&apos;, &apos;darkblue&apos;], how=&apos;log&apos;) 在Jupyter中画图3D散点图12345678910111213%matplotlib notebookfrom matplotlib import pyplotfrom mpl_toolkits.mplot3d import Axes3Dimport randomfig = pyplot.figure()ax = Axes3D(fig)sequence_containing_x_vals = X[:, 0].asnumpy()sequence_containing_y_vals = X[:, 1].asnumpy()sequence_containing_z_vals = y.asnumpy()ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)pyplot.show() 显示图像123%matplotlib inlineimport matplotlib.pyplot as pltplt.imshow(image_data) 操作系统库 os 调用系统cmd的ls程序打印当前目录，并且返回是否成功（0即为成功）os.system(&#39;ls&#39;) os.mkdir(path)函数创建目录（创建一级目录) os.makedirs(path)函数创建多级目录 os.listdir(path)可以得到一个包含当前目录下文件和子目录的List列表（但是是乱序的，需要sorted） os.walk() 方法用于通过在目录树种游走输出在目录中的文件名，向上或者向下 os.path.split 用于分割路径为目录路径和不带后缀的文件名 os.path.split 得到不带后缀的文件名 显示进度条12345678from time import sleepfrom tqdm import tqdmfor i in tqdm(range(100)): sleep(0.01) #也可以用于迭代器 但是要传total参数告诉它迭代器的大小for index, batch in tqdm(enumerate(dataiter),total=num_examples/batch_size,unit="mini-batchs"): pass print(&quot;Epoch %d&quot; % epoch)可以改为tqdm.write(&quot;Epoch %d&quot; % epoch) 找到某一后缀的文件 glob库12import globprint glob.glob("./source/*.cpp") 递归查找可以用glob2库,注意使用了 **12import glob2print glob2.glob("./source/**/*.cpp") h5py使用指南读取h5文件12345678import h5pyf = h5py.File('test_data_SE.h5', 'r')f.keys()#[u'Input', u'Output']f['Input']#&lt;HDF5 dataset "Input": shape (1681, 2), type "&lt;f8"&gt;f['Input'][:] #得到所有数据f.close() 多进程和多线程库1234567891011121314151617181920212223import multiprocessingimport osdef square(x): return x*x def Run(cmd): assert(os.system(cmd)==0)def ParallelFunction(func,argList,threads=5): if threads&gt;multiprocessing.cpu_count(): threads=multiprocessing.cpu_count() pool = multiprocessing.Pool(processes=threads) res=pool.map(func, argList) pool.close() return res def ParallelRun(cmds,threads=5): ParallelFunction(Run,cmds,threads=threads)if __name__ == '__main__': print ParallelFunction(square,range(10)) ParallelRun(['time','dir']) 简单示例 （结合深度学习）创建一个输入，一个输出的的网络所需的hdf5文件 新版12345678910111213141516171819202122232425import numpy as npimport h5pyimport mxnet as mxN = 1000X = np.random.normal(0, 1, (N, 12))y = np.random.randint(0, 2, N)# write data to filewith h5py.File('myfile.hdf5', "w") as ofile: ofile.create_dataset("X", data=X) ofile.create_dataset("y", data=y)# load data from fileifile = h5py.File('myfile.hdf5', 'r')X_h5 = ifile["X"]y_h5 = ifile["y"]batch_size = 200dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size)for iBatch, batch in enumerate(dataiter): print(iBatch, batch.data[0].asnumpy().shape)ifile.close() 旧版12345678910111213141516171819202122232425262728import osimport h5pyimport numpy as npimport structimport randomfloat_size=4input_node=2output_node=1input_file='test_data_SE.dat'out_file='test_data_SE.h5'input_and_output_node=input_node+output_nodewith open(input_file,'rb') as f: f.seek(0,os.SEEK_END) file_len=f.tell()/(float_size*input_and_output_node)with h5py.File(out_file, "w") as f: Input = f.create_dataset('Input', (1681,input_node ),dtype='float', chunks=True) Output = f.create_dataset('Output', (1681,output_node),dtype='float', chunks=True) fin=open(input_file,'rb') index=range(file_len) random.shuffle(index) for i in index: fin.seek(float_size*input_and_output_node*i,os.SEEK_SET) Input[i,:] = np.array(struct.unpack('&lt;'+str(input_node )+'f',fin.read(float_size*input_node))) Output[i,:] = np.array(struct.unpack('&lt;'+str(output_node)+'f',fin.read(float_size*output_node))) fin.close() Python小工具检查项目代码memcpy是否都包含了sizeof使用了glob2库 这个相比glob不仅可以找到目录下的特定后缀文件还可以递归查询它的子目录下的文件1234567891011import glob2files=glob2.glob("./source/**/*.cpp")for file in files: num=0 for line in open(file,'rt'): num=num+1 line=line.strip() if line.startswith('memcpy'): if('sizeof' not in line): print line+'\t\t'+file+'\t'+str(num) 可以显示行 文件名 行号，效果还是不错的，因为可以自定义呀~ 导入导出数据清除文件数据12with open('test.txt','w') as f_out: pass 文本数据np.loadtxt忽略首行，数据是浮点数np.loadtxt(&#39;test.txt&#39;,dtype=float,skiprows=1)读取特定的列使用参数usecols,多列是usecols=(1,3)，单列是usecols=(3,) np.genfromtxt只读取第一三列浮点数据且忽略首行np.genfromtxt(&#39;test.txt&#39;,dtype=float,usecols=(1,3),skip_header=1) 实例12345678910111213import numpy as npimport struct,osmat = np.arange(15).reshape((3,5)).astype(np.float32)with open('test.txt','w') as f_out: for lis in mat: #Write every row f_out.writelines(map(lambda i:str(i)+'\t',lis)+['\n'])with open('test.txt','r') as f_in: for line in f_in.readlines(): print line 二进制数据####快速读取二进制数据123456789101112#速度慢data=np.array(struct.unpack('&lt;'+str(lis_len)+'f',fin.read()))#速度快data = np.fromfile(datafile,dtype=np.float32)#为了方便使用这第二种快速读取的方式，定义如下函数def BinaryRead(datafile,column): data = np.fromfile(datafile,dtype=np.float32) LengthOfFile=len(data) assert(LengthOfFile) assert((LengthOfFile%column)==0) data.shape = [LengthOfFile/column,column] return data 实例1234567891011121314151617181920import numpy as npimport struct,osfloat_size=4mat = np.arange(15).reshape((3,5)).astype(np.float32)with open('test.dat','wb') as f_out: for lis in mat: #Write every row f_out.write(struct.pack('&lt;5f',*lis))with open('test.dat','rb') as f_in: #Read every row f_in.seek(0,os.SEEK_END) row_Num = int(f_in.tell()/(float_size*5)) print "row number is "+str(row_Num) f_in.seek(0,os.SEEK_SET) for i in range(row_Num): print np.array(struct.unpack('&lt;5f',f_in.read(float_size*5))) # Got mat again. 导出字典（使用JSON）打印到屏幕indent可以控制缩进单位，美化JSON用的print json.dumps(mydict, indent=2)输出到文件12with open('Unit2Vec_tSNE.json', 'w') as outfile: json.dump(mydict, outfile, indent=2) 导出字典（使用pickle）可以保存字典、列表、numpy数据等pickle.dump(数据, 文件，[使用协议])表示将要持久化的数据，保存到文件中，使用协议有3种，索引0为ASCII，1是旧式2进制，2是新式二进制协议，不同之处在于后者更高效一些。默认的话dump方法使用使用协议0。1234567891011121314151617181920212223import pickleimport numpy as npdata1 = &#123;'a': [1, 2.0, 3, 4+6j], 'b': ('string', u'Unicode string'), 'c': None&#125;data2 = [1, 2, [3,4,5]]data3 = np.arange(5)with open('data.pkl', 'wb') as output_file: # Using -1 to make it more stable and less file size pickle.dump(data1, output_file, -1) pickle.dump(data2, output_file, -1) pickle.dump(data3, output_file, -1)with open('data.pkl', 'r') as input_fine: data4 = pickle.load(input_fine) data5 = pickle.load(input_fine) data6 = pickle.load(input_fine) print data4 print data5 print np.sum(data6) #0+1+2+3+4==10 Anaconda使用备忘录安装环境conda create -n 环境名conda create -n 环境名 python=3.6 删除环境conda remove -n 环境名 –all 查看所处环境conda info -e 升级Condaconda update conda 解决错误出现Intel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.so错误执行conda install nomkl就可以了。在计算DTW算法的库时遇到 解决h5py的⚠️pip install numpy==1.13.0 找不到conda对于Linux: 如果最终conda not found 只需要终端输入export PATH=&quot;/home/xzhou/anaconda2/bin:$PATH&quot;就行，为了永久生效加入这行代码进~/.bashrc, 然后source ~/.bashrc对于window: scripts文件夹路径作为环境变量 ipython的环境不正常当激活一个环境后 ipython的sys.executable不对劲只需要conda install ipython进行了Reactivate the environment or run hash -r (in bash) or rehash (in zsh). 就行了 Conda不能联网注意当conda不能用时可以考虑使用手机USB共享网络，但是一定要关闭微软输入法，不然会导致蓝屏。最好用4G网络，更新顺利。使用科大镜像 12345678910# 优先使用清华 conda 镜像。conda config --prepend channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/# 或者选用科大 conda 镜像。conda config --prepend channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes# 移除镜像conda config --remove channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ 待Check如果conda create -n test_env python=2.7 创建出的环境并不在envs里，那么执行conda create –prefix /tmp/test-env python=2.7]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>Python</tag>
        <tag>MXNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大连之行]]></title>
    <url>%2F2018%2F07%2F25%2F%E5%A4%A7%E8%BF%9E%E4%B9%8B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer-ElBMpZqf"), narrow: false, autoplay: false, showlrc: false, music: { title: "单车练习曲", author: "王雁盟", url: "单车练习曲.mp3", pic: "/2018/07/25/大连之行/单车练习曲.jpg", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 2018年7月20日 周五上午十点飞机，11.40到达大连 凯宁来机场接我，中午吃了蒸汽海鲜，海胆海螺海参。 吃完饭打的回去，就连蝉也和合肥到不同，不是吱吱吱叫很久，而是断断续续的，也许是气温不像我们这里这么炎热吧 下午从海军大连舰艇学院出来后沿着海边一直走 先路过老虎滩(老虎抽象的雕塑位于广场正中） 接着路过了滨海路还有北大桥，把他家小狗牛牛也带出来遛了。晚上找了家东北菜吃，有特色菜焖子(就是炸过的地瓜粉做的) 还有锅包肉(吃起来像厦门的拔丝，酸甜口的)，都吃不完，分量很足也不贵。吃完饭去了东港，有音乐喷泉! 还有欧洲风情街比如凯旋门威尼斯啥的，人头攒动 2018年7月21日 周六早晨去了吃鲜肉小笼包 甜口的好吃些江浙口味，鲜虾饺子。之后去北广场坐车去旅顺,主要去了两个景点一个是旅顺军港，不大，但是有很多海鸥。 另一个是日俄旅顺监狱，一个爱国主义基地，可看到当时监狱条件是多差（监狱嘛照片就不拍了）。 回市里已经是下午三点，我吃了顿铁板后看了电影《邪不压正》，也许是喝了咖啡的原因真是特别想上厕所呀，而且姜文的这部电影很难懂。晚上去了星海广场和附近的沙滩 晚上从游乐园出来后去了烧烤店，第一次大胆从容吃蚕蛹，很好吃，只有微微苦味，中间一个小心心不能吃。 2018年7月22日 周日去了老虎滩海洋公园还有鸟语林，感受就是海洋公园里头太阳那么大，极地动物还要表演也是一种折磨。鸟语林不错，各种鸟可以凑近你，喂了它们巧克力面包。 老虎滩公园里的沙滩比星海广场的软，白天能看见细长的小鱼在浅滩处（所以钓鱼抓鱼的都能见到） 之后我又去老虎滩广场了，喂食海鸥，基本上刚开始都不过来都离我很远在天上飞，不过只要象征性的撒几次，海鸥都过来了，他们空中接食很厉害。然后去见了凯宁朋友一起吃了饭喝了点酒，晚上去了凯宁家吃的饭，饭菜主打海鲜，但是吃不掉有些多，第一次吃知了猴，味道不错哦，高蛋白，别人都是把知了当主食吃。 傍晚走在老虎滩的海边大道上一种夏日的宁静。 晚上在大院散步是凯宁不知怎么说到了法国对应于中国难忘春宵的曲子是Les demons De Minuit，二三十年的老歌，每当什么活动大家就唱这个，所以他也顺便学学。节奏感很好听 接着就外放着这首歌晚上去了星海广场，顺便也踩沙滩了，不过很硌脚。 晚上的星海湾大桥开灯了，很长，打通了开发区与星海广场的距离。 2018年7月23日 周一今天早上随便吃了一点后就先去了造船厂看到了辽宁号航空母舰，只能远望 去了金石滩公园，做轻轨3号线花了一个小时(8元)才到，够远的。中午吃了肯德基，直接坐车(20元)坐到了地质公园入口处。然后就又走回了三号线终点，一路上风景很好，都是礁石海滩，穿行在林间感觉特别不错。 就是太热了我们把衣服套头上，好一副沙特王子的样子。下午买了水特产，还看到了鳐鱼 晚上吃了鲅鱼鲜饺等，这是北方特产（听说山东人也爱吃） 2018年7月24日 周二坐飞机回合肥]]></content>
      <categories>
        <category>旅行</category>
      </categories>
      <tags>
        <tag>大连</tag>
        <tag>旅行</tag>
      </tags>
  </entry>
</search>
