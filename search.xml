<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[测试Markdown]]></title>
    <url>%2F2018%2F07%2F30%2F%E6%B5%8B%E8%AF%95Markdown%2F</url>
    <content type="text"><![CDATA[马克飞象是一款专为印象笔记（Evernote）打造的Markdown编辑器，通过精心的设计与技术实现，配合印象笔记强大的存储和同步功能，带来前所未有的书写体验。特点概述： 功能丰富 ：支持高亮代码块、LaTeX 公式、流程图，本地图片以及附件上传，甚至截图粘贴，工作学习好帮手； 得心应手 ：简洁高效的编辑器，提供桌面客户端以及离线Chrome App，支持移动端 Web； 深度整合 ：支持选择笔记本和添加标签，支持从印象笔记跳转编辑，轻松管理。 Markdown简介 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— 维基百科 正如您在阅读的这份文档，它使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接或一个脚注[^demo]。下面列举了几个高级功能，更多语法请按Ctrl + /查看帮助。 代码块12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' LaTeX 公式可以创建行内公式，例如 $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$。或者块级公式： $$ x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$ 表格 Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 流程图12345678st=&gt;start: Starte=&gt;endop=&gt;operation: My Operationcond=&gt;condition: Yes or No?st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 以及时序图: 123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 提示：想了解更多，请查看流程图语法以及时序图语法。 复选框使用 - [ ] 和 - [x] 语法可以创建复选框，实现 todo-list 等功能。例如： 已完成事项 待办事项1 待办事项2 注意：目前支持尚不完全，在印象笔记中勾选复选框是无效、不能同步的，所以必须在马克飞象中修改 Markdown 原文才可生效。下个版本将会全面支持。 印象笔记相关笔记本和标签马克飞象增加了@(笔记本)[标签A|标签B]语法, 以选择笔记本和添加标签。 绑定账号后， 输入(自动会出现笔记本列表，请从中选择。 笔记标题马克飞象会自动使用文档内出现的第一个标题作为笔记标题。例如本文，就是第一行的 欢迎使用马克飞象。 快捷编辑保存在印象笔记中的笔记，右上角会有一个红色的编辑按钮，点击后会回到马克飞象中打开并编辑该笔记。 注意：目前用户在印象笔记中单方面做的任何修改，马克飞象是无法自动感知和更新的。所以请务必回到马克飞象编辑。 数据同步马克飞象通过将Markdown原文以隐藏内容保存在笔记中的精妙设计，实现了对Markdown的存储和再次编辑。既解决了其他产品只是单向导出HTML的单薄，又规避了服务端存储Markdown带来的隐私安全问题。这样，服务端仅作为对印象笔记 API调用和数据转换之用。 隐私声明：用户所有的笔记数据，均保存在印象笔记中。马克飞象不存储用户的任何笔记数据。 离线存储马克飞象使用浏览器离线存储将内容实时保存在本地，不必担心网络断掉或浏览器崩溃。为了节省空间和避免冲突，已同步至印象笔记并且不再修改的笔记将删除部分本地缓存，不过依然可以随时通过文档管理打开。 注意：虽然浏览器存储大部分时候都比较可靠，但印象笔记作为专业云存储，更值得信赖。以防万一，请务必经常及时同步到印象笔记。 编辑器相关设置右侧系统菜单（快捷键Ctrl + M）的设置中，提供了界面字体、字号、自定义CSS、vim/emacs 键盘模式等高级选项。 快捷键帮助 Ctrl + /同步文档 Ctrl + S创建文档 Ctrl + Alt + N最大化编辑器 Ctrl + Enter预览文档 Ctrl + Alt + Enter文档管理 Ctrl + O系统菜单 Ctrl + M 加粗 Ctrl + B插入图片 Ctrl + G插入链接 Ctrl + L提升标题 Ctrl + H 关于收费马克飞象为新用户提供 10 天的试用期，试用期过后需要续费才能继续使用。未购买或者未及时续费，将不能同步新的笔记。之前保存过的笔记依然可以编辑。 反馈与建议 微博：@马克飞象，@GGock 邮箱：&#x68;&#x75;&#115;&#116;&#x67;&#x6f;&#x63;&#107;&#64;&#x67;&#109;&#97;&#x69;&#x6c;&#x2e;&#99;&#x6f;&#x6d; 感谢阅读这份帮助文档。请点击右上角，绑定印象笔记账号，开启全新的记录与分享体验吧。 [^demo]: 这是一个示例脚注。请查阅 MultiMarkdown 文档 关于脚注的说明。 限制： 印象笔记的笔记内容使用 ENML 格式，基于 HTML，但是不支持某些标签和属性，例如id，这就导致脚注和TOC无法正常点击。]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客更新日志]]></title>
    <url>%2F2018%2F07%2F30%2F%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[2018年7月24日周二我开始着手研究博客。起因是因为印象笔记的最高级会员一个笔记的容量也只有200MB，对于游记里喜欢放照片的我来说太小了。因此决定从使用了五年的印象笔记迁移至我现在这个博客。 曾经我写印象笔记是直接使用，后来使用StackExchange论坛发现了Markdown这种写作方式，于是购买了印象笔记插件“马克飞象”，总体来说不错。 因此新博客站定很重要的一个功能就是支持Markdown。 最先注意到的框架是Hugo,因为自己喜欢的一个可视化设计师Nadieh Bremer的博客使用的就是这个，我非常喜欢网站的主题Victor Hugo。我同时了解到这是一个静态网站生成器，优点是生成速度是同类框架中最快的，安装也简单。但是一开始我就知道我希望自己的网站具备什么，比如旅行博客可以拥有背景音乐，但是搜索了下，资料很少。jekyll和Hexo和Hugo都是静态网站生成器，Hexo生成速度介于三者之间，而且中文文档也很不错，因为使用的是NodeJs所以拓展性是优于Hugo的。 所以选择Hexo这个作为网站框架，主题先暂时配置成主流黑白风格的Next，不过我觉得这种风格太程序员了，之后会换掉。（更换主题在Hexo中很简单） 与自己的Github关联并托管自己的网站内容在上面，很多博客已有叙述这里不多说。设置Next主题，设置根目录下_config.yml的theme: next,设置主题目录下的_config.yml的Schemes字段更换风格 按照资源文件夹的说法，打开根目录下_config.yml内的post_asset_folder字段,这样不管是图片还是自己本地的音乐都可以直接被Markdown引用。每当dexo new &quot;testPost&quot;,source/_posts_目录下都会出现testPost文件夹以及testPost.md。所以素材放置在testPost中 图片：1&#123;% asset_img IMG_20180720_105107.jpg %&#125; 本地音乐：1&#123;% aplayer &quot;单车练习曲&quot; &quot;王雁盟&quot; &quot;单车练习曲.mp3&quot; &quot;单车练习曲.jpg&quot; %&#125; 网易云音乐：123456&lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&amp;id=28582962&amp;auto=1&amp;height=66"&gt;&lt;/iframe&gt; 对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源。这个稍微有些复杂但是管理资源非常方便的功能可以通过将 config.yml 文件中的 post_asset_folder 选项设为 true 来打开。 设置标签，分类以及文章目录（不要安装hexo-toc插件不然目录不能跳转）设置如我这篇博客toc: true代表打开目录&lt;!-- toc --&gt;设置目录出现的位置comments: true代表打开评论，评论区域，使用韩国“来必力”评论系统，填写主题目录下的_config.yml的livere_uid字段 12345678910---title: 博客更新日志date: 2018-07-30 14:54:12tags: [博客,Hexo]comments: truetoc: truecategories: 博客---&lt;!-- toc --&gt; 2018/7/30 增加搜索功能。修改站点配置文件_config.yml search:path: search.xmlfield: postformat: htmllimit: 10000 修改主题配置文件/themes/next下的_config.yml的enable，设置为true 未来可能会设置标签云以及思维导图]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ and VS]]></title>
    <url>%2F2018%2F07%2F29%2FC%2B%2B%20and%20VS%2F</url>
    <content type="text"><![CDATA[VS知识快捷键Ctrl-K + Ctrl-C： 注释一段选择代码Ctrl-K+ Ctrl-U： 取消一段选择代码的注释格式化整篇代码： Ctrl+K， D 为解决方案创建目录后那么根目录包含 .sln .db git文件夹 solution文件夹: 与工程同名, 放源代码. 以及x64文件夹，用于放编译出来的项目. 在solution文件夹中, 比如项目名是test, 那么源代码就在./test/test/里面, 第一个test指的是解决方案目录, 第二个就是项目名. 包含 所有的源代码, .cpp和.h等等 .vcxproj .vcxproj.filters .vcxproj.user 这也是默认的输入输出的根目录，也就是说，如果程序中打开或新建一个文件，只给文件名的话，就从这个目录打开. 疑问为什么项目总是让我们编译查看工具-&gt;选项-&gt;项目和解决方案-&gt;MSBuild项目生成输出详细级别再把 视图-&gt;输出 中的内容复制到txt中 寻找类似语句“项目不是最新的，因为缺少…”修复后对解决方案或项目选择全部生成。之后运行就正常了 Note: 不是“MSBuild项目生成日志文件详细级别”，那个内容不够丰富，会遗漏一些 修复后不是立即运行，而是对解决方案或项目选择全部生成 如何在VS里添加头文件包含路径项目-&gt;属性-&gt;C++-&gt;附加包路径 C++知识知识注意事项C++内部变量连续存储，意味着先定义了a数组a[100]后定义了b，那么如果a[105]原先是未定义的 但是当把b置0后，a[105]的值也会跟着改变，因为a[105]地址可能就是b的地址 指针初始化a指向整型数组int* a = new int[5]; 初始化a指向5这个整型int* a = new int(5); 拷贝拷贝数组至另一个数组(数组元素为N个)拷贝数组a至数组b：memcpy(b, a, sizeof(float)*N);拷贝数组a至向量b：memcpy(&amp;b[0], a, sizeof(float)*N);拷贝向量a至向量b：memcpy(&amp;b[0], &amp;a[0], sizeof(float)*N); ####拷贝二维数组的一部分（N列）至向量b（N个元素）拷贝二维数组的第一行至向量b：memcpy(&amp;b[0], a, sizeof(float)*N);拷贝二维数组的第二行至向量b：memcpy(&amp;b[0], a+1 sizeof(float)*N);拷贝二维数组的第二行第三个元素开始的N个元素至向量b：memcpy(&amp;b[0], *(a+1)+2,sizeof(float)*N);或者memcpy(&amp;b[0], &amp;a[1][2],sizeof(float)*N);因为&amp;a[i]=a+i，&amp;a[i][j]=*(a+i)+j,在指向行的指针前加 * ,转换为指向列的指针；在指向列的指针前加 &amp; ,转换为指向行的指针； 测量时间123456#include "time.h"clock_t start, end;start = clock();//code hereend = clock();printf("Elapsed time:%f secs.\n", (double)(end - start) / CLOCKS_PER_SEC); 函数 sprintf 12int sprintf( char *buffer, const char *format, [ argument] … )//把格式化的数据写入某个字符串缓冲区buffer中sprintf(szLstFile,"%s\\lists\\phoneme.lst",g_LibCfg.szPrjDir);//把 g_LibCfg.szPrjDir 按照 "%s\\lists\\phoneme.lst"格式转化，并存在 szLstFile 中 sscanf 1int sscanf(const char *buffer,const char *format,[argument ]...); //sscanf会从buffer里读进数据，依照format的格式将数据写入到argument里。 fgets 1char *fgets(char *buf, int bufsize, FILE *stream);//从文件结构体指针stream中读取数据，每次读取一行。读取的数据保存在buf指向的字符数组中，每次最多读取bufsize-1个字符（第bufsize个字符赋'\0'） fgets返回值 成功，则返回第一个参数buf 在读字符时遇到end-of-file，则eof指示器被设置，如果还没读入任何字符就遇到这种情况，则buf保持原来的内容，返回NULL 如果发生读入错误，error指示器被设置，返回NULL，buf的值可能被改变 fscanf 12int fscanf(FILE*stream, constchar*format, [argument...]); //其功能为根据数据格式(format)从输入流(stream)中写入数据(argument)；与fgets的差别在于：fscanf遇到空格和换行时结束，注意空格时也结束，fgets遇到空格不结束。fscanf(fpPhone," %s %s",szTmpStr,szTmpStr);//只会将第二个字符串赋值给szTmpStr fread 1size_t fread ( void * ptr, size_t size, size_t count, FILE * stream );//从文件流指针stream处读count个数据，每个数据大小size个字节，放到ptr中存储。 fwrite 1size_t fwrite ( const void * ptr, size_t size, size_t count, FILE * stream )//fwrite()用来将数据写入文件流中,将ptr指向的数据地址的内容输出至stream文件指针指向的文件 memset 12void *memset(void *s, int ch, size_t n);//函数解释：将s中当前位置后面的n个字节（typedef unsigned int size_t ）用 ch 替换并返回 s//memset：作用是在一段内存块中填充某个给定的值，它是对较大的结构体或数组进行清零操作的一种最快方法 strstr 1extern char *strstr(char *str1, const char *str2);//返回值；若str2是str1的子串，则返回str2在str1的首次出现的地址；如果str2不是str1的子串，则返回NULL。 strncpy 1char *strncpy(char *dest, const char *src, int n)//把src所指向的字符串中以src地址开始的前n个字节复制到dest所指的数组中，并返回dest。 strcpy 1char *strcpy(char *dest, const char *src);//strcpy()会将参数src 字符串拷贝至参数dest 所指的地址。 strcmp 1234extern int strcmp(const char *s1,const char *s2);//当s1&lt;s2时，返回为负数//当s1=s2时，返回值= 0//当s1&gt;s2时，返回正数 memcpy 1void * memcpy ( void * destination, const void * source, size_t num );//从source处读num个字节放到destination指向的内存中去。 assertassert宏能测试传入表达式的真假值，当表达式为真(true)，则不会有任何反应；当表达式为假(false)，则函数将输出错误信息，并中断程序的执行。 疑问如何在sprintf函数中使用string？sprintf是C++继承自C语言的函数，无法直接支持string类型，所以要先把string类型转为基础类型，也就是char*。这里需要使用string类的成员函数c_str();该成员函数功能为，将string的内容转为C语言的字符数组表达形式。所以用sprintf将string对象str，输出的char[]数组array中的代码可以写作： sprintf(array, &quot;%s&quot;, str.c_str());除此外，还可以用strcpy函数，使代码更简单：strcpy(array, str.c_str()); 实际例子建立二维数组1234567891011//开辟内存float **ppTrgAnswer_Data = new float*[nTrgPhoneNum];for (int i = 0; i &lt; nTrgPhoneNum; i++)&#123; ppTrgAnswer_Data[i] = new float[MAX_QUES_NUM]; memset(ppTrgAnswer_Data[i], 0, sizeof(float)*MAX_QUES_NUM);&#125;//释放内存for (i = 0; i &lt; nTrgPhoneNum; i++) delete[] ppTrgAnswer_Data[i];delete[] ppTrgAnswer_Data;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Visual Studio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MXNet]]></title>
    <url>%2F2018%2F07%2F27%2FMXNet%2F</url>
    <content type="text"><![CDATA[MXNet环境指南 打开mxnet source activate gluon # 注意Windows下不需要 source退出环境 source deactivate GPU版本进入环境后如果用指定的卡可以 CUDA_VISIBLE_DEVICES=2 python，这样数据只能分配在一个GPU上 CUDA_VISIBLE_DEVICES=2 jupyter notebook ，进入jupyter后再导入mxnet，如果使用GPU训练，也只训练在一块卡上 升级 pip install --pre mxnet-cu80 --upgrade或者pip install --pre mxnet --upgrade 可以不让MXNet占用过多显存，设置保留的百分数 export MXNET_GPU_MEM_POOL_RESERVE=5 安装依赖库：jupyter，matplotlib，pandas，requests，mxnet MXNet如何处理训练模式和测试模式Gluon：若在通过网络的代码met(…)被with autograd.record()包裹，那么这时候Gluon知道是训练模式。如果没有则是测试模式。可以参见在论坛的帖子得到一些证明MNNet：默认是训练模式，测试模式需要指明mod.forward(Batch([x]),is_train=False)C++：默认是测试模式 MXNet训练，C++使用基本流程 在python中训练MXNet模型 在python中导入模型，并进行预测 在C++中导入模型（在小例子上进行验证两个接口结果一致） 在C++项目中使用模型 工程小例子层的使用RNN循环神经网络的使用12345678910layer = mx.gluon.rnn.RNN(100, 3)#只知道每个time-steps的输出维度是100，有三个隐层，具体几个time-steps未知layer.initialize()input = mx.nd.random_uniform(shape=(6, 8, 10))# 默认TNC模式，方便取到跨batch的数据# 代表time-steps是6，每个time-steps对应的输入维度是10，batch_size为8# 6*10-&gt;6*100# by default zeros are used as begin stateoutput = layer(input)print output.shape Embedding层 提取权重1net.weight.data().asnumpy() 关于提高GPU利用率可以尝试将数据全部放进内存，如果是不规则数据集，numpy处理不了可以用python自带的数组处理 MXNet常用函数nd.concatenate（被弃用,改为nd.concat）123456789101112print img_list[0].shape #(1L, 3L, 64L, 64L) 每个都是这样的形状print len(img_list) #13233nd.concatenate(img_list).shape #(13233L, 3L, 64L, 64L)train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list),batch_size=64)train_data.reset()for batch in train_data: print batch break#输出DataBatch: data shapes: [(64L, 3L, 64L, 64L)] label shapes: []#即每个batch是64张图 nd.concatenate([history,temp],axis=1)或者nd.concat(history,temp,dim=1)对应F.concat(history, temp, dim=1) 计算L2Loss123456789import mxnet as mxfrom mxnet import gluonimport numpy as nploss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,2,4))b=mx.nd.random.uniform(0, 10,shape=(3,2,4))print loss1(a,b)print np.mean(np.square((a[:,0,:]-b[:,0,:]).asnumpy()))/2print np.mean(np.square((a[:,1,:]-b[:,1,:]).asnumpy()))/2 sym.list_outputs()列出一个模型输出端口的名字 sym.list_arguments()列出一个模型的输入端口的名字以及权重和偏置的名字 sym.tojson()可以打印出网络结构 mod.get_outputs()列出前馈的输出 显示网络结构 viz.plot_network直接显示网络结构mx.viz.plot_network(symbol=sym) 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraphPlot"&#125;] 1graph = Import["ExampleData/mxnet_example2.json", &#123;"MXNet", "NodeGraph"&#125;] mask-RNN重要的SequenceMask函数第二个参数表示这个mini-batch内几个样本是真实的，这里代表两个真实12345678910111213141516171819202122232425x = mx.nd.array([[[ 1., 2., 3.], [ 4., 5., 6.]], [[ 7., 8., 9.], [ 10., 11., 12.]], [[ 13., 14., 15.], [ 16., 17., 18.]]])#x.shape=(3L,2L,3L)res=mx.nd.SequenceMask(x,mx.nd.array([2,1]), use_sequence_length=True)print res#表明第一个batch保留两个time-stseps，第二个batch保留1个time-stsep# 得到# [[ 1. 2. 3.]# [ 4. 5. 6.]]# [[ 7. 8. 9.]# [ 0. 0. 0.]]# [[ 0. 0. 0.]# [ 0. 0. 0.]]]#这样的话 res[:,0,:]取出的就是第一个batch加了mask的结果# [[ 1. 2. 3.]# [ 7. 8. 9.]# [ 0. 0. 0.]]# res[:,1,:]取出的就是第2个batch加了mask的结果# [[ 4. 5. 6.]# [ 0. 0. 0.]# [ 0. 0. 0.]] 首先解决带mask的loss1234567891011121314151617import mxnet as mxa=mx.random.normal(0,1,shape=(50,128,43))b=mx.random.normal(0,1,shape=(50,128,43))mask=[49]*128 #如果这里是[50]*128那么这两个loss的结果一样loss=mx.gluon.loss.L2Loss(batch_axis=1)print loss(a,b)def L2LossMask(a,b,mask): #类似于gluon.loss.L2Loss(batch_axis=1)，但是可以用mask方式计算 maskloss=[] maska=nd.SequenceMask(a, mask, use_sequence_length=True) maskb=nd.SequenceMask(b, mask, use_sequence_length=True) for i in range(a.shape[1]): maskloss.append(nd.sum((maska[:,i,:]-maskb[:,i,:])**2)/(2*mask[i]*a.shape[2])) return nd.concat(*maskloss,dim=0)print L2LossMask(a,b,mask) MXNet高阶应用利用HDF5文件做迭代器用于训练123456789101112131415161718192021222324252627282930313233343536import mxnet as mxfrom mxnet import nd,gluon,autogradfrom mxnet.gluon import nnimport h5pynet = nn.Sequential()with net.name_scope(): net.add(nn.Dense(32,in_units=2,activation="tanh")) net.add(nn.Dense(1))net.initialize()# load data from filewith h5py.File('test_data_SE.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] batch_size = 512 epochs=10 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'adam', &#123;'learning_rate': 0.3&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0]) loss = square_loss(output, batch.label[0]) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() print("Epoch %d, average loss: %f" % (epoch, total_loss/num_examples)) print(net(nd.array([[-1,-0.9]]))[0].asnumpy()) 单输入单输出Seq2Seq模型Python代码（HybridBlock版本）123456789101112131415161718192021222324252627282930313233import mxnet as mxfrom mxnet.gluon import nnprint("mxnet version: "+mx.__version__)mx.random.seed(1234) #Getting the same result everytimedef get_net(): # construct a MLP net = nn.HybridSequential() with net.name_scope(): net.add(nn.Dense(5, activation="relu")) net.add(nn.Dense(2)) # initialize the parameters net.collect_params().initialize() return net# forwardx = mx.nd.array([[0.1,0.2,0.3]])net = get_net()net.hybridize()print('=== net(x) ===&#123;&#125;'.format(net(x)))net.export('model')############## Re-importing the net ##############from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,3))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([[0.1,0.2,0.3]])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() C++导入模型再预测 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include &lt;stdio.h&gt;// Path for c_predict_api#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./simple prediction model/model-symbol.json"; std::string param_file = "./simple prediction model/model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 1; // 1 for feedforward const char* input_key[1] = &#123; "data" &#125;; const char** input_keys = input_key; // input-dims int data_len = 3; const mx_uint input_shape_indptr[2] = &#123; 0, 2 &#125;; const mx_uint input_shape_data[2] = &#123; 1,static_cast&lt;mx_uint&gt;(data_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0==MXPredCreate((const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, &amp;pred_hnd)); assert(pred_hnd); std::vector&lt;mx_float&gt; vector_data = std::vector&lt;mx_float&gt;(data_len); mx_float* p = vector_data.data(); p[0] = .1; p[1] = .2; p[2] = .3; MXPredSetInput(pred_hnd, "data", vector_data.data(), data_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output_index = 0; mx_uint *shape = 0; //shape相当于1*3的向量 mx_uint shape_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output_index, &amp;shape, &amp;shape_len); size_t size = 1; for (mx_uint i = 0; i &lt; shape_len; ++i) size *= shape[i]; std::vector&lt;float&gt; data(size); assert(0==MXPredGetOutput(pred_hnd, output_index, &amp;(data[0]), size)); // Release Predictor MXPredFree(pred_hnd); // Print Output Data PrintOutputResult(data); return 0;&#125; 简单的多输入多输出网络Python代码（普通版本）1234567891011121314151617181920212223from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.Block): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def forward(self,x,y): result1 = nd.relu(self.dense0(x))+nd.relu(self.dense1(y)) result2 = nd.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1] Python代码（HybridBlock版本）1234567891011121314151617181920212223242526272829303132333435from mxnet import ndfrom mxnet.gluon import nnclass HybridNet(nn.HybridBlock): def __init__(self, **kwargs): super(HybridNet, self).__init__(**kwargs) with self.name_scope(): self.dense0 = nn.Dense(3) self.dense1 = nn.Dense(3) self.dense2 = nn.Dense(6) def hybrid_forward(self, F,x,y): result1 = F.relu(self.dense0(x))+F.relu(self.dense1(y)) result2 = F.relu(self.dense2(result1)) return [result1,result2]net = HybridNet()net.initialize()net.hybridize()x = nd.random.normal(shape=(4,3))y = nd.random.normal(shape=(4,5))res=net(x,y)print "output1:",res[0]print "output2:",res[1]net.export('model')print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('model-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,3)),('data1',(1,5))])mod.load_params('model-0000.params')Batch=namedtuple('Batch',['data'])mod.forward(Batch(data=[x,y]))print mod.get_outputs() C++导入模型再预测 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151#include &lt;mxnet/c_predict_api.h&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;assert.h&gt;// Read file to bufferclass BufferFile &#123;public: std::string file_path_; int length_; char* buffer_; explicit BufferFile(std::string file_path) :file_path_(file_path) &#123; std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary); if (!ifs) &#123; std::cerr &lt;&lt; "Can't open the file. Please check " &lt;&lt; file_path &lt;&lt; ". \n"; length_ = 0; buffer_ = NULL; return; &#125; ifs.seekg(0, std::ios::end); length_ = ifs.tellg(); ifs.seekg(0, std::ios::beg); std::cout &lt;&lt; file_path.c_str() &lt;&lt; " ... " &lt;&lt; length_ &lt;&lt; " bytes\n"; buffer_ = new char[sizeof(char) * length_]; ifs.read(buffer_, length_); ifs.close(); &#125; int GetLength() &#123; return length_; &#125; char* GetBuffer() &#123; return buffer_; &#125; ~BufferFile() &#123; if (buffer_) &#123; delete[] buffer_; buffer_ = NULL; &#125; &#125;&#125;;void PrintOutputResult(const std::vector&lt;float&gt;&amp; data) &#123; for (int i = 0; i &lt; static_cast&lt;int&gt;(data.size()); i++) &#123; printf("%.8f\n", data[i]); &#125; printf("\n");&#125;int main(int argc, char* argv[]) &#123; // Models path for your model, you have to modify it std::string json_file = "./model-symbol.json"; std::string param_file = "./model-0000.params"; BufferFile json_data(json_file); BufferFile param_data(param_file); // Parameters int dev_type = 1; // 1: cpu, 2: gpu int dev_id = 1; // arbitrary. mx_uint num_input_nodes = 2; mx_uint num_output_nodes = 2; const char* input_key[2] = &#123; "data0" , "data1" &#125;; const char** input_keys = input_key; //output_key name maybe should modify const char* output_key[2] = &#123; "hybridnet0__plus0" , "hybridnet0_relu2" &#125;; const char** output_keys = output_key; // input-dims int data0_len = 3; int data1_len = 5; const mx_uint input_shape_indptr[3] = &#123; 0,2,4 &#125;; const mx_uint input_shape_data[4] = &#123;1,static_cast&lt;mx_uint&gt;(data0_len),1,static_cast&lt;mx_uint&gt;(data1_len) &#125;; PredictorHandle pred_hnd = 0; if (json_data.GetLength() == 0 || param_data.GetLength() == 0) return -1; // Create Predictor assert(0 == MXPredCreatePartialOut( (const char*)json_data.GetBuffer(), (const char*)param_data.GetBuffer(), static_cast&lt;size_t&gt;(param_data.GetLength()), dev_type, dev_id, num_input_nodes, input_keys, input_shape_indptr, input_shape_data, num_output_nodes, output_keys, &amp;pred_hnd)); assert(pred_hnd); //ERROR HERE std::vector&lt;mx_float&gt; vector_data0 = std::vector&lt;mx_float&gt;(data0_len); mx_float* p0 = vector_data0.data(); p0[0] = 1;p0[1] = 2;p0[2] = 5; MXPredSetInput(pred_hnd, "data0", vector_data0.data(), data0_len); std::vector&lt;mx_float&gt; vector_data1 = std::vector&lt;mx_float&gt;(data1_len); mx_float* p1 = vector_data1.data(); p1[0] = 5; p1[1] = 3; p1[2] = 1; p1[3] = 4; p1[4] = 5; MXPredSetInput(pred_hnd, "data1", vector_data1.data(), data1_len); // Do Predict Forward MXPredForward(pred_hnd); mx_uint output0_index = 0; mx_uint *shape0 = 0; //shape相当于1*3的向量 mx_uint shape0_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output0_index, &amp;shape0, &amp;shape0_len); size_t size0 = 1; for (mx_uint i = 0; i &lt; shape0_len; ++i) size0 *= shape0[i]; mx_uint output1_index = 1; mx_uint *shape1 = 0; //shape相当于1*5的向量 mx_uint shape1_len; // Get Output Result MXPredGetOutputShape(pred_hnd, output1_index, &amp;shape1, &amp;shape1_len); size_t size1 = 1; for (mx_uint i = 0; i &lt; shape1_len; ++i) size1 *= shape1[i]; std::vector&lt;float&gt; data0(size0); assert(0 == MXPredGetOutput(pred_hnd, output0_index, &amp;(data0[0]), size0)); std::vector&lt;float&gt; data1(size1); assert(0 == MXPredGetOutput(pred_hnd, output1_index, &amp;(data1[0]), size1)); // Print Output Data printf("output0:\n"); PrintOutputResult(data0); printf("output1:\n"); PrintOutputResult(data1); // Release Predictor MXPredFree(pred_hnd); return 0;&#125; 训练模板用目标模型举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx = gpu()net = nn.HybridSequential()with net.name_scope(): net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(128, activation="relu")) net.add(nn.Dropout(0.1)) net.add(nn.Dense(32))net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/TargetModel/validation_normalization_Target.h5', 'r')X_val_h5 = nd.array(val_file["Input"][:]).as_in_context(ctx)y_val_h5 = nd.array(val_file["Output"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/TargetModel/training_normalization_Target.h5', 'r') as h5file: X_h5 = h5file["Input"] y_h5 = h5file["Output"] num_examples=X_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx)) loss = square_loss(output, batch.label[0].as_in_context(ctx)) loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch%100==0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) val_loss = nd.mean(square_loss(net(X_val_h5), y_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('TargetModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") 导入测试1234567891011import mxnet as mxfrom mxnet.gluon import nnfrom collections import namedtuplesym = mx.symbol.load('TargetModel-symbol.json') mod=mx.mod.Module(symbol=sym)mod.bind(data_shapes=[('data',(1,1+523))])mod.load_params('TargetModel-0000.params')Batch=namedtuple('Batch',['data'])data=mx.nd.array([range(1+523)])mod.forward(Batch([data]),is_train=False)print mod.get_outputs() 用连接模型举例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import mxnet as mxfrom mxnet.gluon import nnfrom mxnet import nd,gluon,autograd,gpuimport h5pyimport osctx=gpu()class JoinModel(nn.HybridBlock): def __init__(self, **kwargs): super(JoinModel, self).__init__(**kwargs) self.encodeNet=nn.HybridSequential() self.decodeNet=nn.HybridSequential() self.fc=nn.HybridSequential() with self.name_scope(): self.encodeNet.add(nn.Dense(128,activation="relu")) self.encodeNet.add(nn.Dense(128)) self.decodeNet.add(nn.Dense(128,activation="relu")) self.decodeNet.add(nn.Dense(32)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(256,activation="relu")) self.fc.add(nn.Dropout(0.1)) self.fc.add(nn.Dense(32)) def hybrid_forward(self,F,text,history): temp = self.encodeNet(text) result1 = self.decodeNet(temp) result2 = self.fc(F.concat(history, temp, dim=1)) return [result1,result2]net = JoinModel()net.initialize(ctx=ctx)net.hybridize()val_file = h5py.File('../data/JoinModel/validation_normalization_Join.h5', 'r')text_val_h5 = nd.array(val_file["Input1"][:]).as_in_context(ctx)history_val_h5 = nd.array(val_file["Input2"][:]).as_in_context(ctx)UnitVec_val_h5 = nd.array(val_file["Output1"][:]).as_in_context(ctx)val_file.close()# load data from filewith h5py.File('../data/JoinModel/training_normalization_Join.h5', 'r') as h5file: text_h5 = h5file["Input1"] history_h5 = h5file["Input2"] UnitVec_h5 = h5file["Output1"] num_examples=text_h5.shape[0] min_val_loss=float("inf") epochs=100 batch_size = 128 dataiter = mx.io.NDArrayIter([text_h5,history_h5], UnitVec_h5, batch_size=batch_size) square_loss = gluon.loss.L2Loss() trainer = gluon.Trainer(net.collect_params(), 'sgd', &#123;'learning_rate': 0.1&#125;) for epoch in range(epochs): total_loss = 0 dataiter.reset() for iBatch, batch in enumerate(dataiter): with autograd.record(): output = net(batch.data[0].as_in_context(ctx),batch.data[1].as_in_context(ctx)) loss1 = square_loss(output[0], batch.label[0].as_in_context(ctx)) loss2 = square_loss(output[1], batch.label[0].as_in_context(ctx)) loss = loss1+loss2 loss.backward() trainer.step(batch_size) total_loss += nd.sum(loss).asscalar() if iBatch % 100 == 0: print("Epoch %d, Batch: %d/%d, average loss: %f"%(epoch,iBatch,num_examples/batch_size,nd.mean(loss).asscalar())) print("Epoch %d finished, average loss of training set: %f" % (epoch, total_loss/num_examples)) res = net(text_val_h5,history_val_h5) val_loss = nd.mean(square_loss(res[0],UnitVec_val_h5)+square_loss(res[1],UnitVec_val_h5)).asscalar() print("\n-----loss of validation set: %f-----\n" % val_loss) if(val_loss &lt; min_val_loss): min_val_loss=val_loss net.export('JoinModel') print("---validation set got a smaller loss---\n---------------Save net----------------\n") 导入测试12345678910111213141516import mxnet as mxfrom mxnet import ndimport numpy as np############## Re-importing the net ##############print("############## Re-importing the net ##############")from collections import namedtuplesym = mx.symbol.load('JoinModel-symbol.json') mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])mod.bind(data_shapes=[('data0',(1,524)),('data1',(1,128))])mod.load_params('JoinModel-0000.params')Batch=namedtuple('Batch',['data'])x = nd.random.normal(shape=(1,524))y = nd.random.normal(shape=(1,128))mod.forward(Batch(data=[x,y]),is_train=False)print mod.get_outputs()print sym.list_outputs() 配置C++平台 在C++/常规中添加“附加包含目录”，即工作目录，方便定位c_predict_api.h的位置。如果能成功#include的话，不设置也行 在链接器/输入中增加“附加依赖项”，即libmxnet.lib 修改“活动解决方案平台”为x64 拷贝libmxnet.dll和libmxnet.lib和c_predict_api.h到工作目录 cpp文件加入#include &lt;c_predict_api.h&gt; C++使用指南 可运行单输入单输出 默认采用预测方式 可运行多输入多输出 默认采用预测方式 可运行多输入多输出，但是在输出端口可以只输出一个端口的数据 修改预测支持一个mini-batch只需要修改input_shape_data中的batch_size，并且将一个mini-batch的输入数据压平送进网络。在设置输入输出端口的vector的大小时候都要把它设置为一个batch数据长度的batch_size倍 MXNet源码阅读io.py位于E:\Anaconda\envs\gluon\Lib\site-packages\mxnet阅读如何自定义迭代器]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Python</tag>
        <tag>MXNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mathematica]]></title>
    <url>%2F2018%2F07%2F27%2FMathematica%2F</url>
    <content type="text"><![CDATA[设置问题没有图形化界面的机器导出图像计算机是Linux服务器, 无图形化界面链接How to save Image or Graphics in Terminal? sudo apt-get install xvfb xvfb-run wolfram此时运行这个代码就正常了 12p=Graphics@Circle[];Export["test.jpg",p]; 状态栏显示时间格式-&gt;选项设置（快捷键Ctrl+Shift+O），显示选项值选择全局偏好，搜索 EvaluationCompletionAction，将其设置为“ShowTiming”,笔记本下方的状态栏就会显示每次运行代码的消耗时间了。 当用到GPU并且执行wolframscript的语法是：CUDA_VISIBLE_DEVICES=1 xvfb-run wolframscript -file test.wl 基础知识原子表达式不能替换头部因为1是原子表达式，所以f不能替换掉它的头部1234Apply[f, &#123;&#123;g[1], g[a]&#125;, &#123;g[2], g[b]&#125;, &#123;g[3], g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;f[1], f[a]&#125;, &#123;f[2], f[b]&#125;, &#123;f[3], f[c]&#125;&#125; *)Apply[f, &#123;&#123;1, g[a]&#125;, &#123;2, g[b]&#125;, &#123;3, g[c]&#125;&#125;, &#123;2&#125;](* &#123;&#123;1, f[a]&#125;, &#123;2, f[b]&#125;, &#123;3, f[c]&#125;&#125; *) 函数式指令Gather将相同元素收集在一起12345Gather[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First[#1] == First[#2] &amp;](*or*)GatherBy[&#123;&#123;a, 1&#125;, &#123;b, 1&#125;, &#123;a, 2&#125;, &#123;d, 1&#125;, &#123;b, 3&#125;&#125;, First](*&#123;&#123;&#123;a, 1&#125;, &#123;a, 2&#125;&#125;, &#123;&#123;b, 1&#125;, &#123;b, 3&#125;&#125;, &#123;&#123;d, 1&#125;&#125;&#125;*) 表格排版 新版可以不用设置Partition,Grid组合起来用那么麻烦，因为Partition要考虑是怎么划分的Multicolumn[Range[50], 6] 旧版Grid@Partition[Range[50], 6, 6, 1, &quot;&quot;] 数学运算求出最大/小元素的位置求出最小元素的位置用Ordering[lis, 1];求出最大元素的位置用Ordering[lis, -1] 矩阵重复再拼接 类似numpy的tail函数1ArrayFlatten[&#123;ReplicateLayer[4]@mat&#125;] // TraditionalForm 数学证明 文件管理列出文件夹下的文件列出当前目录和子目录下所有后缀为nb的文件1FileNames["*.nb","*",Infinity] 得到BaseName12FileBaseName["C:\\Users\\xzhou\\Desktop\\test.gif"](*test*) 保存mma表达式123456FilePrint @ Export["test.wl", Solve[x^2 + a x + 1 == 0, x]](*Or*)file = "test.wl"If[FileExistsQ[#], DeleteFile[#]]&amp; @ file;FilePrint @ Save[file, Solve[x^2 + a x + 1 == 0, x]]; 可视化CoordinateBoundingBoxArray输入边界坐标，自动均匀填充边界内的点坐标12CoordinateBoundingBoxArray[&#123;&#123;3, -1&#125;, &#123;8, 2&#125;&#125;];Graphics[Point[Flatten[%, 1]], Frame -&gt; True] 在MatrixPlot和Graphics中插入文字考虑Epilog选项和Inset图元 自动给曲线图打标签1ListLinePlot[RandomReal[1, 26] -&gt; CharacterRange["a", "z"]] 音频函数语音合成Speak可以让Mma说话，SpokenString可以显示说话的内容 让Audio自动播放声音：最后的参数”Play”可以换成Pause Stop之类的12au = ExampleData[&#123;"Sound", "Violin"&#125;];Audio`Internals`Execute[ Audio`Internals`GetAudioManager[ Audio`AudioInformation[au, "AudioID"]], "Play"] 得到Audio文件此时的播放位置1id =Audio`AudioInformation[song, "AudioID"];mngr = Audio`Internals`GetAudioManager[id];Dynamic@Audio`AudioDump`getGUIInfo[mngr, "AudioPosition"] 计算音频的能量123456a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "RMSAmplitude"](*实际上度量的是均方误差a // AudioData // #^2 &amp; // Mean // Sqrt*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Power"](*实际上度量的是 a // AudioData // #^2 &amp; // Mean*)a = ExampleData[&#123;"Sound", "Violin"&#125;]; AudioMeasurements[a, "Loudness"](*实际上度量的是 a // AudioData // #^2 &amp; // Mean // #^0.67 &amp;*) Dataset深入、退出运算符值得注意的是TakeLargestBy是深入运算符，TakeLargest是退出运算符。 在后面的运算符应用到更深一层之前，“深入”运算符被应用到原始数据集相应的部分. 深入运算符的特点是在作用于某一层时，它们不会改变数据更深层次的结构. 这确保后面的运算符操作时，子表达式的结构和原始数据集的相应层次是一样的. 最简单的深入运算符是 All，它选取某个给定层的所有部分，因此不会改变该层数据的结构 在所有随后的运算符完成对深层数据的操作后，“退出”运算符被应用.因此dataset[f,g]是Query[f, g] // Normal,也就是Map[g] /* f .深入运算符对应于原始数据的层，而退出运算符对应于结果的层. 和深入运算符不同，退出运算符不必保持所操作数据的结构. 如果一个运算符没有被明确指定为深入运算符，假定其为退出运算符 data[SortBy[#x - #y &amp;], Total, #^2 &amp;]是深入、退出1、退出2运算符，因此先应用深入运算符，再应用#^2 &amp;，再应用Total 数据分析或处理利用SQL语法查询数据sales = SemanticImport[&quot;ExampleData/RetailSales.tsv&quot;]sales[All, &quot;Sales&quot;]得到Sales列的所有数据因为All是深入运算符，可以安全的更换为其他深入运算符，如sales[Mean, &quot;Sales&quot;] // N这时候如果想再针对月份和星期几排序可以这样：12sales[GroupBy[DateValue[#Date, "Month"] &amp;], GroupBy[DateValue[#Date, "DayName"] &amp;], Mean, "Sales"] 聚类 ClusteringComponents的第二个参数意思是聚类个数为3类，第三个参数将第一层数据视为一个样本 归一化数据对数据（矩阵）做归一化，数据每行是一个样本，每一列是一个特征均值文件存储的也是矩阵。第一行是最小值，第二行是最大值若只对矩阵第一维归一化1data1[[All, 1]] = (data1[[All, 1]] - meanInput[[1, 1]])/(meanInput[[2, 1]] - meanInput[[1, 1]]); 若对矩阵的每一维做归一化1mat = (# - meanOutput[[1]])/meanOutput[[2]] &amp; /@ mat; 实用小功能美化输出GeneralUtilities`PrettyForm可以美化输出 导出矢量图SVG和wmf文件可以输出矢量图，wmf适合visio 将PDF中的段落变成一行，方便谷歌翻译使用先复制段落再粘贴进mma执行以下代码1StringDelete[text, "\n"] // CopyToClipboard 当然CopyToClipboard可以直接拷贝数据至剪贴板，也对复制图片是极好的 导出数学公式至Stack Exchange例如http://math.stackexchange.com公式选择复制为Latex格式 然后在前后加上$就行了1$c=\sqrt&#123;a^2-2 a b \cos (\theta )+b^2&#125;$ 导出含有Alpha通道的图片12img//Binarize//ColorReplace[#,Black-&gt;Red]&amp;Export["img.gif",%,"TranspararentColor"-&gt;White] 导入导出导入导入lst文件（每行均为数字构成）Import[filename,&quot;List&quot;]导入lst文件（每行均为字符串构成）Import[filename,&quot;Lines&quot;]导入纯文本构成的矩阵 Import[filename,&quot;Table&quot;]导入浮点数二进制文件 BinaryReadList[filename,&quot;Real32&quot;] 文件流控制以二进制文件形式导入Import不会引入新的流，简单但是灵活性低12Import["test.exe", "Byte"] // LengthStreams[] // Length (*2，证明只有输出流stdout和错误流stderr*) OpenRead 如果用完关闭流也不会引入新的流，稍复杂但是灵活性高1234567file = OpenRead["test.exe", BinaryFormat -&gt; True];Length@Reap[ While[(tempRecord = BinaryRead[file]) =!= EndOfFile, Sow@tempRecord]][[2, 1]]Close[file];Streams[] // Length (*2，证明只有输出流stdout和错误流stderr*) 不管是BinaryReadList还是BinaryRead都会改变流指针的位置： Mathemtica向文件追加二进制数据123456file = "test.dat";str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[12], "Real32"];BinaryWrite[str, Range[15,30], "Real32"];Close[str]; BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30} 继续追加12345str = OpenAppend[file, BinaryFormat -&gt; True];BinaryWrite[str, Range[5], "Real32"];BinaryWrite[str, Range[10, 15], "Real32"];Close[str];BinaryReadList[file, "Real32"] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, \22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 10, 11, 12, 13, \14, 15} 不导出也查看导出的效果比如ExportString[{1, {1, 2, 3}}, &quot;Table&quot;]输出的效果就是Export[&quot;test.txt&quot;,{1, {1, 2, 3}}, &quot;Table&quot;]打开后的效果 单元 笔记本在单元中启用动态1TextCell[Dynamic[ Refresh[DateString[], UpdateInterval -&gt; 1]], "Subsection"] 时序数据TimeSeries的头部依然是TemporalData1234v = &#123;2, 1, 6, 5, 7, 4&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; ts = TimeSeries[v, &#123;t&#125;]Head[ts](* TemporalData *) 两条路径使用 TemporalData而不是TimeSeries1234s1 = &#123;2, 1, 6, 5, 7, 4&#125;; s2 = &#123;4, 7, 5, 6, 1, 2&#125;; t = &#123;1, 2, 5, 10, 12, 15&#125;; td = TemporalData[&#123;s1, s2&#125;, &#123;t&#125;] Differences和Accumulate可以用于 TemporalData，但是要注意采样是否均匀的问题]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Mathematica</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow]]></title>
    <url>%2F2018%2F07%2F26%2FTensorflow%2F</url>
    <content type="text"><![CDATA[Keras与Tensorflow联动123456789101112131415161718192021222324252627282930313233343536import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist_data = input_data.read_data_sets('MNIST_data/', one_hot=True)# Building modelimg = tf.placeholder(tf.float32, shape=(None, 784))labels = tf.placeholder(tf.float32, shape=(None, 10))x = tf.keras.layers.Dense(128, activation='relu')(img)x = tf.keras.layers.Dense(128, activation='relu')(x)prediction = tf.keras.layers.Dense(10)(x)loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))train_optim = tf.train.AdamOptimizer().minimize(loss)#Print model name and shapefor i in tf.trainable_variables(): print '&#123;&#125;\t&#123;&#125;\t&#123;&#125;'.format(i.name,i.shape,i.dtype)#dense/kernel:0 (784, 128) &lt;dtype: 'float32_ref'&gt;#dense/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_1/kernel:0 (128, 128) &lt;dtype: 'float32_ref'&gt;#dense_1/bias:0 (128,) &lt;dtype: 'float32_ref'&gt;#dense_2/kernel:0 (128, 10) &lt;dtype: 'float32_ref'&gt;#dense_2/bias:0 (10,) &lt;dtype: 'float32_ref'&gt;# Train modelwith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for _ in range(1000): batch_x, batch_y = mnist_data.train.next_batch(50) sess.run(train_optim, feed_dict=&#123;img: batch_x, labels: batch_y&#125;) acc_pred = tf.keras.metrics.categorical_accuracy(labels, prediction) pred = sess.run(acc_pred, feed_dict=&#123;labels: mnist_data.test.labels, img: mnist_data.test.images&#125;) print('accuracy: %.3f' % (sum(pred)/len(mnist_data.test.labels))) Tensorflow如何处理训练模式、测试模式DropOut层和BN层都有训练模式、测试模式。DropOut层：设立一个placeholder，设置训练时一个数，测试时设置为0phase = tf.placeholder(tf.bool, name=&#39;phase&#39;)BN层： Boardcasting机制可以看到b的维度竟然和a的最后一维一致因为tf.nn.conv2d只计算卷积的部分，不自动添加bias偏置。所以要这样tf.nn.relu(tf.nn.conv2d(x,w)+bias)，其中bias的加法需要使用boardcasting 123456import tensorflow as tfa=tf.constant(1,shape=[2,3,5])b=tf.constant(range(5))with tf.Session() as sess: tf.global_variables_initializer().run() print sess.run(a+b) [[[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]] [[1 2 3 4 5] [1 2 3 4 5] [1 2 3 4 5]]] 模型相关载入模型1234trainable = tf.trainable_variables()optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt') 载入多模型 交替循环不同部分123456789101112131415161718192021222324trainable = tf.trainable_variables()trainable_DNN = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"DNN_part")trainable_WaveNet = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,"wavenet_part")optim = optimizer.minimize(loss, global_step=global_step, var_list=trainable)optim_DNN = optimizer.minimize(loss, global_step=global_step, var_list=trainable_DNN)optim_WaveNet = optimizer.minimize(loss, global_step=global_step, var_list=trainable_WaveNet)saver = tf.train.Saver(trainable)saver.restore(sess, './logdir/model.ckpt')DNN_saver = tf.train.Saver(trainable_DNN)DNN_saver .restore(sess, './logdir/DNN_part/Unit2Vec.ckpt')WaveNet_saver = tf.train.Saver(trainable_WaveNet)WaveNet_saver.restore(sess, './logdir/WaveNet_part/Unit2Vec.ckpt')#part 1-&gt;3-&gt;2-&gt;3-&gt;2-&gt;3...if step &lt; 10: #turn round every 10 steps #part 1 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim])elif int(step/10) % 2 == 0: #part 2 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_WaveNet])elif int(step/10) % 2 == 1: #part 3 summary, loss_value, acc_value, _ = sess.run([summaries, loss, acc, optim_DNN])else: raise ValueError(x) 队列机制min_after_dequeue的含义用enqueue_many增加队列元素这里首先创建了一个50个元素的队列，要求min_after_dequeue为5。然后入队了五次，每次5个元素，每个元素形状为2，也就是现在队列里有25行2列的数据，25个元素。所以最多只能出队25-5=20个元素，否则将会阻塞 1234567891011121314151617import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=50, min_after_dequeue=5, dtypes=[tf.int32, tf.int32], shapes=[(2,),(2,)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[5,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[5,2])enqueue_op = input_queue.enqueue_many([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(20)with tf.Session() as sess: #filled the queue for _ in range(5): sess.run(enqueue_op,feed_dict=&#123;placeholder1:np.arange(10).reshape(-1,2), placeholder2:np.arange(10).reshape(-1,2)&#125;) print (sess.run(dequeue)) 用enqueue增加队列元素这里首先创建了一个50个元素的队列，要求min_after_dequeue为2。然后入队了五次，每次一个元素，每个元素的形状为5*2的矩阵。所以最多只能出队5-2=3个元素，否则将会阻塞 1234567891011121314151617import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=50, min_after_dequeue=2, dtypes=[tf.int32, tf.int32], shapes=[(5,2),(5,2)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[5,2])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[5,2])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(50): sess.run(enqueue_op,feed_dict=&#123;placeholder1:np.arange(10).reshape(-1,2)+i, placeholder2:np.arange(10).reshape(-1,2)+i&#125;) print (sess.run(dequeue)) 正确使用RandomShuffleQueue队列1234567891011121314151617import tensorflow as tfimport numpy as npinput_queue = tf.RandomShuffleQueue(capacity=50, min_after_dequeue=2, dtypes=[tf.int32, tf.int32], shapes=[(5,1),(6,3)])placeholder1 = tf.placeholder(dtype=tf.int32, shape=[5,1])placeholder2 = tf.placeholder(dtype=tf.int32, shape=[6,3])enqueue_op = input_queue.enqueue([placeholder1, placeholder2])dequeue = input_queue.dequeue_many(3)with tf.Session() as sess: #filled the queue for i in range(50): sess.run(enqueue_op,feed_dict=&#123;placeholder1:np.arange(5).reshape(5,1)+i, placeholder2:np.arange(18).reshape(6,3)+i&#125;) print (sess.run(dequeue)) 函数：会话注册：sess=tf.InteractivateSession()表示将是这个创建的session作为随后默认的session，之后的运行也运算也在这里面进行 列出当前每个节点使用的device使用的是tf.Session(config=tf.ConfigProto(log_device_placement=True)) 各种loss函数tf.losses.mean_squared_error理解123456789101112131415161718192021import tensorflow as tfimport numpy as npshape_obj = (5,6,3)Y1 = tf.random_normal(shape=shape_obj)Y2 = tf.random_normal(shape=shape_obj)loss1 = tf.reduce_sum(tf.pow(Y1 - Y2, 2)) / (reduce(lambda x, y: x*y, shape_obj))loss2 = tf.reduce_mean(tf.squared_difference(Y1, Y2))loss3 = tf.losses.mean_squared_error(predictions=Y1, labels=Y2)loss4 = tf.nn.l2_loss(Y1 - Y2)with tf.Session() as sess: #不需要初始化 lis = sess.run([Y1, Y2, loss1, loss2, loss3, loss4]) print lis[2:] Y1, Y2 = lis[:2] lis=[] for i in range(shape_obj[-1]): lis.append(np.mean(np.square((Y1[:,:,i]-Y2[:,:,i])))) print np.mean(lis) [2.0185342, 2.0185342, 2.0185342, 90.83404]2.018534 可以看到tf把最后一维（shape_obj 是二维也是一样）当做batch_axis，而且loss没有除以2在Gluon里就相当于：loss1=gluon.loss.L2Loss(batch_axis=-1)*2还发现一个问题就是sess.run[想要的必须写在一起]，如果sess.run[loss1],sess.run[loss1]这样写就算是loss1==loss2结果也会不一样，应该是每运行一次计算图运行一次，因为每次运行的随机数不一样，结果自然也不一样 123456789101112import mxnet as mxfrom mxnet import gluonimport numpy as nploss1=gluon.loss.L2Loss(batch_axis=1)a=mx.nd.random.uniform(0, 10,shape=(3,5,4))b=mx.nd.random.uniform(0, 10,shape=(3,5,4))print loss1(a,b)lis=[]for i in range(5): lis.append(1./2*np.mean(np.square((a[:,i,:]-b[:,i,:]).asnumpy())))print lis tf.losses.sparse_softmax_cross_entropy理解sparse_softmax_cross_entropy要求labels是一个整数列表形式，范围是[0, num_classes], logits是一个浮点数据，存储的是网络输出的值 MXNet和tf结果一样，说明在二维数据的时候，都是将第一维作为batch_axis,类别总数可以从Y1.shape[1]知道123456789101112131415161718import tensorflow as tfimport numpy as npY1 = tf.constant(np.arange(50).reshape((5,10)),dtype=tf.float32)Y2 = tf.constant([5,3,2,9,1])Y3 = tf.one_hot(Y2, depth = Y1.shape[1])loss1 = tf.losses.sparse_softmax_cross_entropy(logits=Y1, labels=Y2)loss2 = tf.losses.softmax_cross_entropy(logits=Y1, onehot_labels=Y3)loss3 = tf.nn.softmax_cross_entropy_with_logits(logits=Y1, labels=Y3)loss4 = tf.reduce_mean(loss3)with tf.Session() as sess: [loss1,loss2,loss3,loss4] = sess.run([loss1,loss2,loss3,loss4]) print loss1,loss2 #5.4586296, 5.4586296 print loss3.shape #(5,) print np.mean(loss3) #5.4586296 print loss4 #5.4586296''' 用MXNet来验证1234567import mxnet as mximport numpy as nploss=mx.gluon.loss.SoftmaxCrossEntropyLoss()a=mx.nd.array(np.arange(50).reshape((5,10)))b=mx.nd.array([5,3,2,9,1])print loss(a,b)print mx.nd.mean(loss(a,b))#5.45862961 神经网络函数tf.one_hot()tf.one_hot([[0,1],[2,3]],depth=5)得到的数据维度是(2,2,5)tf.one_hot([[[0,1],[2,3]],[[0,1],[2,3]]],depth=5)得到的数据维度是(2,2,2,5) tf.unique和tf.unique_with_counts函数12345678910111213import tensorflow as tfimport numpy as npY1 = tf.constant([1,1,2,4,4,3,3,7])Y2 = tf.unique(Y1)Y3 = tf.unique_with_counts(Y1)with tf.Session() as sess: [Y2,Y3] = sess.run([Y2,Y3]) print Y2 #Y2:Unique(y=array([1, 2, 4, 3, 7], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 3, 4], dtype=int32)) print Y3 #Y3:UniqueWithCounts(y=array([1, 2, 4, 3, 7], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 3, 4], dtype=int32), count=array([2, 1, 2, 2, 1], dtype=int32)) 实现左移一个数，最右补零将[[0],[1],[2],[3]]-&gt;[[1],[2],[3],[0]]12345678import tensorflow as tfencoded = tf.reshape(tf.constant(range(4)),[1,-1,1])shifted = tf.slice(encoded, [0, 1, 0],[-1, tf.shape(encoded)[1] - 1, -1])shifted = tf.pad(shifted, [[0, 0], [0, 1], [0, 0]])with tf.Session() as sess: print sess.run([encoded,shifted]) tf.conv1D输入的shape是（batch_size, width1, in_channel）卷积核的shape是 （filter_width, in_channel, out_channel）输出是（batch_size, width2, out_channel）width2取决于stride是什么123456789101112import tensorflow as tfimport numpy as npx = tf.Variable(np.arange(200).reshape(5,10,4).astype(np.float32))k = tf.Variable(tf.contrib.layers.xavier_initializer_conv2d()(shape=[1,4,16]))conv = tf.nn.conv1d(x, k, stride=1, padding='SAME', data_format='NHWC')with tf.Session() as sess: sess.run(tf.global_variables_initializer()) [a, b] = sess.run([x, conv]) print a.shape, b.shape #reshape(1,10,4)-&gt;reshape(1,10,16) 图像处理完整范例1234567891011121314import tensorflow as tfimport numpy as npfrom PIL import Imageimg = Image.open("1620.jpg")img.show()w, h = img.sizeimg = np.expand_dims(img, 0)bi_image_bilinear = tf.image.resize_bilinear(img, size=(int(h*3), int(w*3)))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: bi_result = sess.run(bi_image_bilinear)Image.fromarray(np.uint8(bi_result)).show() tf.image.resize*tf.image.resize_nearest_neighbor [0 1 2] -&gt; [0 0 1 1 2 2]tf.image.resize_bilinear [0 1 2] -&gt; [0 0.5 1 1.5 2 2 ]tf.image.resize_bicubic [0 0.40625 1 1.59375 2 2.09375]123456789import tensorflow as tfimport numpy as npimg = np.arange(3).reshape((1,1,3,1))bi_image_bilinear = tf.image.resize_bilinear(img, size=(1,6))bi_image_bilinear = tf.squeeze(bi_image_bilinear)with tf.Session() as sess: print sess.run(bi_image_bilinear)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2018%2F07%2F26%2FLinux%2F</url>
    <content type="text"><![CDATA[命令行指令Linux要查看所有和pdf相关的命令 可以输入pdf 再按Tab键 目录 ls -l看当前目录下文件的基本属性 ls -a看隐藏文件 tree可以看到目录树结构 删除文件夹 rm -rf xxx sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/将远程服务器88的文件夹/home/xzhou/project挂载到本机的88_mount/目录下，取消挂载fusermount -u 88_mount/.注意管理员下需要sshfs xzhou@172.16.46.88:/home/xzhou/project 88_mount/ -o allow_other ln -s /tmp/test1.txt test2.txt 将在当前目录下创建符号文件“test2.txt”，ln -s /tmp/test1.txt 将在当前目录下创建符号文件“test1.txt”。删除链接符号文件语法是rm file或者rm dir 文字处理 Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出 PDF相关PDF-&gt;TXTpdftotext可以得到pdf对应的纯文本版本 字体嵌入强制字体嵌入：12pdf2ps template.pdfps2pdf -dPDFSETTINGS=/prepress template.ps file.pdf 验证：pdffonts template.pdf可以看到所有字体已被嵌入 图像处理Mac需要 brew install imagemagick才能使用convert gif转一些列图片（帧为单位） convert test.gif test%05d.png一系列png转视频 ffmpeg -i test%05d.png test.mp4 如果需要将视频速度变慢要加选项 -filter:v &quot;setpts=2.0*PTS&quot;要让符合MP4V2格式需要加选项 -brand mp42比如ffmpeg -i test%05d.png -filter:v &quot;setpts=2.0*PTS&quot; -brand mp42 test.mp4 系统指令 getconf LONG_BIT得到Linux系统是x86还是x32 cat /proc/driver/nvidia/version查看CUDA驱动版本 who -b 查看最后一次系统启动的时间 who -r 查看当前系统运行时间 查看所用的桌面环境 env|grep DESKTOP= lsb_release -a查看系统版本(没有就用yum install lsb或者cat /etc/os-release) 关机 shutdown -r now 增加用户 先登录root用户 adduser xzhou passwd xzhou 似乎不需要 因为第一步输入了密码增加网络资源共享文件夹 sudo nano /etc/samba/smb.conf sudo smbpasswd -a xzhou sudo service smbd restart 显卡 GPU计算 watch -n 1 nvidia-smi 每秒刷新一次 nvidia-smi 进程 ps ax | grep python 可以看到其他人在运行的Python代码 已知PID查看指令所在目录：lsof -p PID|grep cwd kill -s 9 PID 强制杀死进程标识号PID的进程 已知PID如何查看完整指令:ps PID 已知端口查进程是 lsof –i:端口号 工具 实时查看网速 sudo apt-get install nethogs &amp; sudo nethogs 查看公网IP curl api.ipify.org 查看私有IP ifconfig 安装VNC-serverps -ef|grep -i vnc 查看正在运行的vncserver的进程vncserver -kill :1 #关闭这个连接vncserver :1 重启vncserver 美化和汉化man汉化 sudo apt-get install sudo !!-zh 查看man 手册安装到哪里，dpkg -L manpages-zh | less查看到安装在/usr/share/man/zh_CN 设一个中文man别名, 修改 ~/.bashrc 添加一个alias :alias cman=&#39;man -M /usr/share/man/zh_CN&#39;，或者用命令sed -i &#39;$a alias cman=&quot;man -M /usr/share/man/zh_CN&quot;&#39; .bashrc(在最后一行后增加一行，并写入文件) source ~/.bashrc 重启终端 cman ls就是汉化的man，man ls就是英文的man##美化 sudo apt-get install most 修改 ~/.bashrc 添加一个环境变量 :export PAGER=&quot;/usr/bin/most -s&quot;,或者用命令sed -i &#39;$a export PAGER=&quot;/usr/bin/most -s&quot;&#39; .bashrc(在最后一行后增加一行，并写入文件) source ~/.bashrc 重启终端 man ls就是英文的美化版的man 小技巧让上一个命令以管理员身份执行apt-get install ranger然后报权限不足再敲入sudo !!运行上一条命令 快捷键命令行日常系快捷键 CTRL + U - 剪切光标前的内容CTRL + K - 剪切光标至行末的内容CTRL + Y - 粘贴CTRL + E - 移动光标到行末CTRL + A - 移动光标到行首ALT + F - 跳向下一个空格ALT + B - 跳回上一个空格ALT + Backspace - 删除前一个单词CTRL + W - 剪切光标后一个单词Shift + Insert - 向终端内粘贴文本 暂停并在后台运行命令CTRL + Z - 暂停应用程序（比如正在用nano编辑test.txt）fg - 重新将程序唤到前台jobs - 查看任务数目只要按CTRL + Z，前台的命令就会暂停，画面就切回到命令行了。然后你就能运行你想要运行的命令，等命令运行完后在终端窗口输入fg就可以回到先前暂停的任务 下载视频使用you-get和youtube-dl以及硕鼠从Youtube视频中下载音频（wav格式）支持b站youtube-dl –extract-audio –audio-format wav URL 比如我想下载这个情非得已的音频 使用python3安装you-get you-get http://www.miaopai.com/show/R~22buLsn55r7IVQKvMjZ4Le2mJ7PS7BqxjbAg__.htm ffmpeg -i 阿卡贝拉版情非得已.mp4 -f mp3 -vn 阿卡贝拉版情非得已.mp3参数解释：-i 表示input，即输入文件-f 表示format，即输出格式-vn表示vedio not，即输出不包含视频 play 阿卡贝拉版情非得已.mp3 (需要安装sox库) 后台下载视频如果现在很多个b站视频需要下载，是不是就是CTRL + Z and fg 结合 youtube-dl，实践发现不行，挂起时下载会暂停。之前我玩过树莓派，很多Linux知识都是从那里学到的 所以我发现了screen命令. MacOS是自带的 终端输入:1screen youtube-dl --extract-audio --audio-format mp3 https://www.bilibili.com/video/av6846882 它会下载第一个视频，这时候按住Ctrl+A+D会回到终端，但是视频依然在下载，这时候再次终端输出新的视频PID，就会下载第二个，以此类推… 查看所以任务是screen -ls, 所有视频一旦完成下载，screen -ls就会输出No Sockets found in bilibala...。说明一个任务完成它会自动退出那个虚拟终端的 如果我们关闭终端不影响screen，不信你重新打开终端试试screen -ls Docker容器 查看当前正在运行的容器 docker ps 显示已经退出的容器 docker ps -a 显示所有镜像 docker images 启动/停止某个容器 docker start/stop 容器ID 删除某个容器 docker rm 容器ID 删除镜像 docker rmi 镜像ID 实践 在容器运行命令 docker run ubuntu cat /etc/os-release，没有这个镜像则创建镜像（用完可删除容器） 开启容器交互模式：docker run -it ubuntu /bin/bash exit退出 查看容器ID docker ps -a 打开交互式终端 docker start -i 容器ID 以后每次使用就使用上面这个命令就行 nano快捷键]]></content>
      <categories>
        <category>常见指令以及用法备忘录</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[素材网站]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%B4%A0%E6%9D%90%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[可视化算法 可视化算法网站 旧金山大学的算法课程的可视化 VisuAlgo 极其绚丽，艺术效果似的可视化，用了D3 相应中文版 算法的互动可视化 github 网页版 PCA 介绍算法的Distill 可视化形式的论文 可视化K-Means 还有其他很多算法 交互的 JavaScript可视化好想学HTML5 Canvas呀 好漂亮 比如全是计算机生成的呀 D3 paper.js 各种可视化方案讲解 阿里巴巴的墨者学院 可视化神经网络 计算机视觉历史-The Modern History of Object Recognition 可视化DNN CNN 简易声音素材网站 Find the perfect sound. - soundsnap freesound WebGL 20个不可思议的 WebGL 示例和演示]]></content>
      <categories>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F07%2F26%2FPython%2F</url>
    <content type="text"><![CDATA[使用中文# -*- coding: utf-8 -*- 告诉Python解释器，用UTF-8编码读取源代码print u&#39;中文&#39; u表示Unicode字符串 Python说明Python代码的缩进规则说：最好使用4个空格ipython --pylab 导入了numpy(np) 和 matplotlib 基础知识预备基础知识 若自定义函数没有return，函数执行完毕后返回None 保持字典顺序不变使用OrderedDict 123from collections import OrderedDictprint dict([('a', 1), ('b', 2), ('c', 3)]) #Randomprint OrderedDict([('a', 1), ('b', 2), ('c', 3)]) #Ordered 命令行参数： 12345678import sys if __name__=="__main__": print len(sys.argv) for i in sys.argv: print i,#save as test.py#python test.py #result: 1 2 3 用r’…’来抑制转义如path = r’C:\xzhou\Desktop’ 关于布尔运算Python把0、空字符串’’和None看成 False其他数值和非空字符串都看成 True不过不要完全依赖这一点 List 123456789L=['Michael', 'Bob', 'Tracy'] # 创建List#可用索引 L [0], L [2], L [-1], L [-3], L [0:3]L [-1::-1] #得到 L 的逆序['Tracy', 'Bob', 'Michael'] L [-1:0:-1] #得到['Tracy', 'Bob']L .append('Paul') #改变了LL .insert(0, 'Paul') # 改变了L L 现在为['Paul', 'Michael', 'Bob', 'Tracy', 'Paul']L .pop() #返回'Paul' L 现在为['Paul', 'Michael', 'Bob', 'Tracy'] L .pop(0) #返回'Bob' L 现在为 ['Michael', 'Bob', 'Tracy']L [2] = 'Paul' # L 现在为['Michael', 'Bob', 'Paul'] 迭代列表:123a=range(10)for i in iter(a): print i 列表的拼接（str,tuple也可以这样,dict和set不行）:123456a = []b = [1,]c = [2,3]print a+b+c #[1,2,3]print c * 2 #[2,3,2,3]print []+[[1,2],[3,4]]+[[5,6],[7,8]] #[[1,2],[3,4],[5,6],[7,8]] TupleTuple没有append()方法，也没有insert()和pop()方法。#获取Tuple元素的方式和List一样，可以使用 t[0]，t[-1]等索引方式访问元素，但是不能赋值成别的元素 Tuple和List一样，可以包含 0 个、1个和任意多个元素t = ()对应s=[]t=(1,)对应s=[1], 为了防止歧义而不使用(1) 不过当Tuple包括非Tuple类型时可改变如t = (‘a’, ‘b’, [‘A’, ‘B’])可改变[‘A’, ‘B’]内的元素但t = (‘a’, ‘b’, (‘A’, ‘B’))不可以 dictlen(d)得到字典长度d.get(‘Bart’)得到’Bart’对应的键，不存在返回None1234567891011121314151617d = &#123;'a':[1,2],'b':['hello','xiao',3]&#125;print d.items()# 遍历键for key in d: print key,# 遍历键值for key, value in d.items(): #创建迭代器，效率更高 print key,value# 更快的遍历键值，也省内存for key, value in d.iteritems(): #创建迭代器，效率更高 print key,value# 遍历值for v in d.values(): print v,# 更快速的遍历值，也省内存for v in d.itervalues(): print v, 另外值得注意的是key只能选择不能被改变的数据类型如整数、字符串、Tuple，不能用List set类型因为强调的事并集，所以排序无规律也不支持索引支持 len(s), ‘A’ in s 等 set的内部结构和dict很像，唯一区别是不存储value，因此，判断一个元素是否在set中速度很快。set存储的元素和dict的key类似，必须是不变对象，因此，任何可变对象是不能放入set中的。最后，set存储的元素也是没有顺序的。适用场合：让用户输入星期一至星期日的某天，判断用户的输入是否是一个有效的星期？ 更新set: 增加元素是s.add(‘A’), 删除是s.remove(‘A’), 删除的元素不在set中，remove会报错 定义可变参数函数： 123456def fn(*args): print argsfn() #() fn('a') #('a',)fn('a', 'b') #('a', 'b')fn(['a', 'b']) #(['a', 'b'],) enumerate 很有用的函数，用于索引、迭代 zip()函数可以把两个 list 变成一个 list，类似于转置 12zip([10, 20, 30], ['A', 'B', 'C'])# [(10, 'A'), (20, 'B'), (30, 'C')] 列表生成式： 1234[x * x for x in range(1, 3)] #[1, 4, 9][x * x for x in range(1, 6) if x % 2 == 0] #[4, 16, 36][m + n for m in 'ABC' for n in '123'] #['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3']&#123;phone:i for i, phone in enumerate(set(y))&#125; 搭配字典哦😯 变量可以指向函数： 123456len=abs#len([1,2,3]) 报错print len(-5) #5 说明函数名就是指向函数的变量def g(a,b,f): #高阶函数（可以接受函数的函数） return f(a)+f(b)print g(-3,6,abs) #9 map函数（同Mathematica的Map）：map(lambda i:i**2, [1, 2, 3]) #得到[1, 4, 9] reduce函数（类似Mathematica的Fold）： 12reduce(lambda i,j:i+j, [1,2,3],10) #16 Fold[#1 + #2 &amp;, 10, &#123;1, 2, 3&#125;]reduce(lambda i,j:i+j, [1,2,3]) #6 Fold[#1 + #2 &amp;, &#123;1, 2, 3&#125;] filter函数（类似Mathematica的Select ： 123filter(lambda i:i%2==0, range(10)) #[0, 2, 4, 6, 8] filter(lambda str:str and str.strip()&gt;0, [&apos;test&apos;, None, &apos;&apos;, &apos;str&apos;, &apos; &apos;, ...: &apos;END&apos;])#输出[&apos;test&apos;, &apos;str&apos;, &apos;END&apos;] sorted函数可以用来排序: 123sorted([1,5,2,5,9]) #输出[1, 2, 5, 5, 9] sorted([1,5,2,5,9],lambda i,j:cmp(j,i)) #输出[9, 5, 5, 2, 1] sorted([1,5,2,5,9],lambda i,j:cmp(i,j)) #输出[1, 2, 5, 5, 9] 应用12a = ['5_3','2_6','4_9','2_1']sorted(a, key = lambda i: (i.split('_')[0], i.split('_')[1])) 返回函数的函数 123456def calc_prod(lst): def lazy_prod(): return reduce((lambda x,y: x*y),lst) return lazy_prod f = calc_prod([1, 2, 3, 4])print f() 闭包： 123456789def count(): fs = [] for i in range(1, 4): def f(): return i fs.append(f) print fs return fs f1, f2, f3 = count() #f1() f2() f3() 都是3 纯函数内加入条件判断lambda x: -x if x &lt; 0 else x 面向对象编程 初始化过程中使用键值对： 12345678910class Person(object): def __init__(self, name, gender, birth, **kw): self.name = name self.gender = gender self.birth = birth for k, v in kw.iteritems(): setattr(self, k, v)xiaoming = Person('Xiao Ming', 'Male', '1990-1-1', job='Student')print xiaoming.name #Xiao Mingprint xiaoming.job #Student decorator装饰器 123456789101112131415161718192021def f1(x): return x*2 def decorator(f): def fn(x): print 'Using decorator...\ncall ' + f.__name__+ '()' return f(x) return fn f1 = decorator(f1) print f1(5) @decorator def f2(x): return x*x print f2(5)#打印出了：#Using decorator... #call f1() #10 #Using decorator...#call f2()#25 编写无参数的decorator装饰器用于记录函数运行效率： 12345678910111213141516import timedef performance(f): def fn(*args, **kw): t1 = time.time() r = f(*args, **kw) t2 = time.time() print 'call %s() in %fs' % (f.__name__, (t2 - t1)) return r return fn@performancedef factorial(n): return reduce(lambda x,y: x*y, range(1, n+1))print factorial(10)#call factorial() in 0.000005s #3628800 偏函数： 12345import functoolssorted_ignore_case = functools.partial(sorted, cmp=lambda s1, s2: cmp(s1.upper(), s2.upper()))print sorted_ignore_case(['bob', 'about', 'Zoo', 'Credit'])#第一个cmp是sorted函数参数中的一个键#输出['about', 'bob', 'Credit', 'Zoo'] 得到元素位置的index函数：index() 函数用于从列表中找出某个值第一个匹配项的索引位置。所以lis.index(min(lis))可以得到最小值的索引，numpy.argmin其实就是干这个的 函数式求出同一类的个数：mma代码1&#123;1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4&#125; // Counts // Values python使用迭代器函数123from itertools import groupbya = [1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2, 2, 2, 4][len(list(group)) for key, group in groupby(a)] 累加函数python3123456from itertools import accumulatelist(accumulate(range(10)))#[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]import operatorlist(accumulate(range(1,5), operator.mul))#[1, 2, 6, 24] 易错点 type(round(12.3))是float类型 x[a:a+N]实际上x的长度就是N x[:a]+x[a:]==x 0 % N == 0.0 (N != 0) 普通数组是地址传递1234567import numpy as npa = np.arange(10)b = a[3:6]b[2] = 1000# a竟然被b改变了，注意print "a is "+ str(a) #a is [ 0 1 2 3 4 1000 6 7 8 9] print "b is "+ str(b) #b is [ 3 4 1000] python系统管理相关查看python安装目录123import syspath = sys.executableprint(path) pip升级包pip install --pre mxnet-cu80 --upgrade 第三方库scipy包括fft,fftshift,窗函数等信号处理算法 Numpy复数计算X=np.array([1-1j, 1+0.000000000000001j, 4+9j],dtype=complex)X.real得到实部 X.imag得带虚部X.imag[np.abs(X.imag)&lt;0.1]筛选出第二个元素np.unwrap(np.angle(X))可以解卷绕X的相位 索引一般索引a=np.zeros((3,4))a[:,1:3] 得到的是32的矩阵a[:,[1]] 得到的是31的矩阵a[:, 1 ] 得到的是(3,)的数组 根据条件索引符合条件则x否则yAPI:numpy.where(condition[, x, y])1np.where([[True, False], [True, True]], [[1, 2], [3, 4]], [[9, 8], [7, 6]]) array([[1, 8], [3, 4]]) 只有条件的话返回condition.nonzero() 12x = np.arange(9.).reshape(3, 3)np.where( x &gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) 1x[np.where( x &gt; 3.0 )] # Note: result is 1D. array([ 4., 5., 6., 7., 8.]) 1np.where(x &lt; 5, x, -1) # Note: broadcasting. array([[ 0., 1., 2.], [ 3., 4., -1.], [-1., -1., -1.]]) 删除某一维度数据np.delete(arr, 1, axis=0)12arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])np.delete(arr, 1, 0) array([[ 1, 2, 3, 4], [ 9, 10, 11, 12]]) np.delete(arr, np.s_[::2], 1) 用np.s_构造索引 array([[ 2, 4], [ 6, 8], [10, 12]]) np.delete(arr, [1,3,5], None) array([ 1, 3, 5, 7, 8, 9, 10, 11, 12]) all函数1234a=np.arange(-3,3)np.all(abs(a)&lt;5) #Truea=np.arange(-3,6)np.all(abs(a)&lt;5) #False 更改数据类型astype函数如a.astype(np.int32) 普通数组与numpy数组互转12np.arange(3).tolist() #to listnp.asarray([0,1,2]) #to numpy axis的理解123456789a=np.arange(20).reshape(2,10) a.sum(axis=0) #array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])np.diff(a,axis=0) #得到array([[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]]) a.sum(axis=1) #array([ 45, 145])#axis=0把列当做成对处理的对象#axis=1把行当做成对处理的对象 广播机制1234np.array([1,2])*np.array([3,4]) #np.array([3,8]) 行向量的内积 np.array([1,2])*np.array([[3,4],[5,6]]) #np.array([[3,8],[5,12]]) 行向量乘以矩阵 np.array([1,2]).reshape(-1,1)*np.array([[3,4],[5,6]]) #np.array([[3,4],[10,12]]) 列向量乘以矩阵 np.array([[1,2],[3,4]])*np.array([[5,6],[7,8]]) #矩阵的点乘 Element-wisenp.less([1, 2], [2, 2])返回array([True, False], dtype=bool) 行向量列向量的转化12345np.array([1, 2, 3, 4]).reshape((-1, 1)) # &lt;--- THIS IS THE TRICKnp.array([[5, 4]]).Tnp.array([10,20,30]).shape #(3,) 向量np.array([[10,20,30]]).shape #(1,3) 行向量 函数式编程Outer 123m=np.arange(5);n=np.arange(5);a=np.subtract.outer(m,n) #结果和mma一样 Inner 123a = np.arange(12).reshape((4,3))b = [0,1,2,3]np.inner(a, b) #array([ 5, 14, 23, 32]) 结果同MMA 拼接标准数学形式的拼接按列拼接包括向量拼向量 向量拼矩阵 矩阵拼矩阵123456a = np.array([1, 2, 3])b = np.array([2, 3, 4])c = np.vstack((a,b))print c #array([[1, 2, 3], [2, 3, 4]])print np.vstack((a,c)) #array([[1 2 3], [1 2 3], [2 3 4]])print np.vstack((c,c)) #array([[1 2 3], [2 3 4], [1 2 3], [2 3 4]]) 按行拼接包括向量拼向量 向量拼矩阵 矩阵拼矩阵123456a = np.array([[1], [2], [3]])b = np.array([[2], [3], [4]])c = np.hstack((a,b))print c #array([[1, 2], [2, 3], [3, 4]])print np.hstack((a,c)) #array([[1, 1, 2], [2, 2, 3], [3, 3, 4]])print np.hstack((c,c)) #array([[1, 2, 1, 2], [2, 3, 2, 3], [3, 4, 3, 4]]) 仿matlab式拼接123456a = np.array([[1, 2], [3, 4]])b = np.array([[5, 6]])np.concatenate((a, b), axis=0)#array([[1, 2], [3, 4], [5, 6]])np.concatenate((a, b.T), axis=1)#array([[1, 2, 5], [3, 4, 6]]) 多个numpy数组的拼接12np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]#array([[1, 2, 3, 0, 0, 4, 5, 6]]) 数据的填充12a = [1, 2, 3, 4, 5]np.lib.pad(a, (2, 3), 'edge') array([1, 1, 1, 2, 3, 4, 5, 5, 5, 5]) 12a = [[1, 2], [3, 4]]np.lib.pad(a, ((3, 2), (2, 3)), 'minimum') array([[1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 2, 1, 1, 1], [3, 3, 3, 4, 3, 3, 3], [1, 1, 1, 2, 1, 1, 1], matplotlib库等值线图 ContourPlot12345678910111213141516%matplotlib inlineimport matplotlib.pylab as plt def f(x,y): z = (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) return z n = 256 x = np.linspace(-1,1,n)y = np.linspace(-1,1,n)X,Y = np.meshgrid(x,y) fig = plt.figure()surf1 = plt.contourf(X, Y, f(X,Y))fig.colorbar(surf1) 三维图 Plot3D123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure()ax = Axes3D(fig)# X, Y valueX = np.arange(-4, 4, 0.25)Y = np.arange(-4, 4, 0.25)X, Y = np.meshgrid(X, Y) # x-y 平面的网格Z = np.sin(np.sqrt(X ** 2 + Y ** 2))ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('rainbow')) 柱状图1234567891011import matplotlib.pyplot as pltimport numpy as npmu, sigma = 100, 15x = mu + sigma * np.random.randn(10000)hist, bins = np.histogram(x, bins=30)width = 0.9 * (bins[1] - bins[0])center = (bins[:-1] + bins[1:]) / 2plt.bar(center, hist, align='center', width=width)plt.show() 其他可视化库 Seaborn：Seaborn跟matplotlib最大的区别就是它的默认绘图风格和色彩搭配都具有现代美感。由于Seaborn是构建在matplotlib的基础上的，你需要了解matplotlib从而来调整Seaborn的默认参数。 不要用Bokeh和ggplot2，前一个语法兼容不好，晦涩难懂，后一个作者弃坑了且bug多 pygal超美丽，语法超简单，可以直接输出SVG的Tooltip形式的矢量图，但是只能输出SVG格式文件不能直接看图的效果 plotly很美，也是神器之一！致力于交互图表的制作，但是它提供在别的库中很难找到的几种图表类型，比如等值线图，树形图和三维图表。如何离线使用参见Here! 美美哒~但是由于我很熟悉Mathematica，作图基本上就是靠她了。如果是动态图，我使用JavaScript和D3。 可视化大规模数据集的库 Datashader安装conda install -c bokeh datashader 12345678import datashader as dsimport datashader.transfer_functions as tfimport pandas as pddf = pd.read_csv(&apos;user_data.csv&apos;)cvs = ds.Canvas(plot_width=400, plot_height=400)agg = cvs.points(df, &apos;x_col&apos;, &apos;y_col&apos;, ds.mean(&apos;z_col&apos;))img = tf.shade(agg, cmap=[&apos;lightblue&apos;, &apos;darkblue&apos;], how=&apos;log&apos;) 在Jupyter中画图3D散点图12345678910111213%matplotlib notebookfrom matplotlib import pyplotfrom mpl_toolkits.mplot3d import Axes3Dimport randomfig = pyplot.figure()ax = Axes3D(fig)sequence_containing_x_vals = X[:, 0].asnumpy()sequence_containing_y_vals = X[:, 1].asnumpy()sequence_containing_z_vals = y.asnumpy()ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)pyplot.show() 显示图像123%matplotlib inlineimport matplotlib.pyplot as pltplt.imshow(image_data) 操作系统库 os 调用系统cmd的ls程序打印当前目录，并且返回是否成功（0即为成功）os.system(&#39;ls&#39;) os.mkdir(path)函数创建目录（创建一级目录) os.makedirs(path)函数创建多级目录 os.listdir(path)可以得到一个包含当前目录下文件和子目录的List列表（但是是乱序的，需要sorted） os.walk() 方法用于通过在目录树种游走输出在目录中的文件名，向上或者向下 显示进度条12345678from time import sleepfrom tqdm import tqdmfor i in tqdm(range(100)): sleep(0.01) #也可以用于迭代器 但是要传total参数告诉它迭代器的大小for index, batch in tqdm(enumerate(dataiter),total=num_examples/batch_size,unit="mini-batchs"): pass print(&quot;Epoch %d&quot; % epoch)可以改为tqdm.write(&quot;Epoch %d&quot; % epoch) 找到某一后缀的文件 glob库12import globprint glob.glob("./source/*.cpp") 递归查找可以用glob2库,注意使用了 **12import glob2print glob2.glob("./source/**/*.cpp") h5py使用指南读取h5文件12345678import h5pyf = h5py.File('test_data_SE.h5', 'r')f.keys()#[u'Input', u'Output']f['Input']#&lt;HDF5 dataset "Input": shape (1681, 2), type "&lt;f8"&gt;f['Input'][:] #得到所有数据f.close() 多进程和多线程库1234567891011121314151617181920212223import multiprocessingimport osdef square(x): return x*x def Run(cmd): assert(os.system(cmd)==0)def ParallelFunction(func,argList,threads=5): if threads&gt;multiprocessing.cpu_count(): threads=multiprocessing.cpu_count() pool = multiprocessing.Pool(processes=threads) res=pool.map(func, argList) pool.close() return res def ParallelRun(cmds,threads=5): ParallelFunction(Run,cmds,threads=threads)if __name__ == '__main__': print ParallelFunction(square,range(10)) ParallelRun(['time','dir']) 简单示例 （结合深度学习）创建一个输入，一个输出的的网络所需的hdf5文件 新版12345678910111213141516171819202122232425import numpy as npimport h5pyimport mxnet as mxN = 1000X = np.random.normal(0, 1, (N, 12))y = np.random.randint(0, 2, N)# write data to filewith h5py.File('myfile.hdf5', "w") as ofile: ofile.create_dataset("X", data=X) ofile.create_dataset("y", data=y)# load data from fileifile = h5py.File('myfile.hdf5', 'r')X_h5 = ifile["X"]y_h5 = ifile["y"]batch_size = 200dataiter = mx.io.NDArrayIter(X_h5, y_h5, batch_size=batch_size)for iBatch, batch in enumerate(dataiter): print(iBatch, batch.data[0].asnumpy().shape)ifile.close() 旧版12345678910111213141516171819202122232425262728import osimport h5pyimport numpy as npimport structimport randomfloat_size=4input_node=2output_node=1input_file='test_data_SE.dat'out_file='test_data_SE.h5'input_and_output_node=input_node+output_nodewith open(input_file,'rb') as f: f.seek(0,os.SEEK_END) file_len=f.tell()/(float_size*input_and_output_node)with h5py.File(out_file, "w") as f: Input = f.create_dataset('Input', (1681,input_node ),dtype='float', chunks=True) Output = f.create_dataset('Output', (1681,output_node),dtype='float', chunks=True) fin=open(input_file,'rb') index=range(file_len) random.shuffle(index) for i in index: fin.seek(float_size*input_and_output_node*i,os.SEEK_SET) Input[i,:] = np.array(struct.unpack('&lt;'+str(input_node )+'f',fin.read(float_size*input_node))) Output[i,:] = np.array(struct.unpack('&lt;'+str(output_node)+'f',fin.read(float_size*output_node))) fin.close() Python小工具检查项目代码memcpy是否都包含了sizeof使用了glob2库 这个相比glob不仅可以找到目录下的特定后缀文件还可以递归查询它的子目录下的文件1234567891011import glob2files=glob2.glob("./source/**/*.cpp")for file in files: num=0 for line in open(file,'rt'): num=num+1 line=line.strip() if line.startswith('memcpy'): if('sizeof' not in line): print line+'\t\t'+file+'\t'+str(num) 可以显示行 文件名 行号，效果还是不错的，因为可以自定义呀~ 导入导出数据读取文本数据np.loadtxt忽略首行，数据是浮点数np.loadtxt(&#39;test.txt&#39;,dtype=float,skiprows=1)读取特定的列使用参数usecols,多列是usecols=(1,3)，单列是usecols=(3,) np.genfromtxt只读取第一三列浮点数据且忽略首行np.genfromtxt(&#39;test.txt&#39;,dtype=float,usecols=(1,3),skip_header=1) 读取二进制数据123456789101112#速度慢data=np.array(struct.unpack('&lt;'+str(lis_len)+'f',fin.read()))#速度快data = np.fromfile(datafile,dtype=np.float32)#为了方便使用这第二种快速读取的方式，定义如下函数def BinaryRead(datafile,column): data = np.fromfile(datafile,dtype=np.float32) LengthOfFile=len(data) assert(LengthOfFile) assert((LengthOfFile%column)==0) data.shape = [LengthOfFile/column,column] return data 导出字典（使用JSON）打印到屏幕indent可以控制缩进单位，美化JSON用的print json.dumps(mydict, indent=2)输出到文件12with open('Unit2Vec_tSNE.json', 'w') as outfile: json.dump(mydict, outfile, indent=2) 导出字典（使用pickle）可以保存字典、列表、numpy数据等pickle.dump(数据, 文件，[使用协议])表示将要持久化的数据，保存到文件中，使用协议有3种，索引0为ASCII，1是旧式2进制，2是新式二进制协议，不同之处在于后者更高效一些。默认的话dump方法使用使用协议0。1234567891011121314151617181920212223import pickleimport numpy as npdata1 = &#123;'a': [1, 2.0, 3, 4+6j], 'b': ('string', u'Unicode string'), 'c': None&#125;data2 = [1, 2, [3,4,5]]data3 = np.arange(5)with open('data.pkl', 'wb') as output_file: # Using -1 to make it more stable and less file size pickle.dump(data1, output_file, -1) pickle.dump(data2, output_file, -1) pickle.dump(data3, output_file, -1)with open('data.pkl', 'r') as input_fine: data4 = pickle.load(input_fine) data5 = pickle.load(input_fine) data6 = pickle.load(input_fine) print data4 print data5 print np.sum(data6) #0+1+2+3+4==10 Anaconda使用备忘录安装环境conda create -n 环境名conda create -n 环境名 python=3.6 删除环境conda remove -n 环境名 –all 查看所处环境conda info -e 升级Condaconda update conda 解决错误出现Intel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.so错误执行conda install nomkl就可以了。在计算DTW算法的库时遇到 解决h5py的⚠️pip install numpy==1.13.0 找不到conda对于Linux: 如果最终conda not found 只需要修改~/.bashrc 增加 export PATH=”/home/xzhou/anaconda2/bin:$PATH”,然后source ~/.bashrc就行了对于window: scripts文件夹路径作为环境变量 ipython的环境不正常当激活一个环境后 ipython的sys.executable不对劲 只需要Reactivate the environment or run hash -r (in bash) or rehash (in zsh). 就行了 Conda不能联网注意当conda不能用时可以考虑使用手机USB共享网络，但是一定要关闭微软输入法，不然会导致蓝屏。最好用4G网络，更新顺利。使用科大镜像 conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config –set show_channel_urls yes 移除使用conda config –remove channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ 待Check如果conda create -n test_env python=2.7 创建出的环境并不在envs里，那么执行conda create –prefix /tmp/test-env python=2.7]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>MXNet</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大连之行]]></title>
    <url>%2F2018%2F07%2F25%2F%E5%A4%A7%E8%BF%9E%E4%B9%8B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer-mHVhKWeC"), narrow: false, autoplay: false, showlrc: false, music: { title: "单车练习曲", author: "王雁盟", url: "单车练习曲.mp3", pic: "/2018/07/25/大连之行/单车练习曲.jpg", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 2018年7月20日 周五上午十点飞机，11.40到达大连 凯宁来机场接我，中午吃了蒸汽海鲜，海胆海螺海参。 吃完饭打的回去，就连蝉也和合肥到不同，不是吱吱吱叫很久，而是断断续续的，也许是气温不像我们这里这么炎热吧 下午从海军大连舰艇学院出来后沿着海边一直走 先路过老虎滩(老虎抽象的雕塑位于广场正中） 接着路过了滨海路还有北大桥，把他家小狗牛牛也带出来遛了。晚上找了家东北菜吃，有特色菜焖子(就是炸过的地瓜粉做的) 还有锅包肉(吃起来像厦门的拔丝，酸甜口的)，都吃不完，分量很足也不贵。吃完饭去了东港，有音乐喷泉! 还有欧洲风情街比如凯旋门威尼斯啥的，人头攒动 2018年7月21日 周六早晨去了吃鲜肉小笼包 甜口的好吃些江浙口味，鲜虾饺子。之后去北广场坐车去旅顺,主要去了两个景点一个是旅顺军港，不大，但是有很多海鸥。 另一个是日俄旅顺监狱，一个爱国主义基地，可看到当时监狱条件是多差（监狱嘛照片就不拍了）。 回市里已经是下午三点，我吃了顿铁板后看了电影《邪不压正》，也许是喝了咖啡的原因真是特别想上厕所呀，而且姜文的这部电影很难懂。晚上去了星海广场和附近的沙滩 晚上从游乐园出来后去了烧烤店，第一次大胆从容吃蚕蛹，很好吃，只有微微苦味，中间一个小心心不能吃。 2018年7月22日 周日去了老虎滩海洋公园还有鸟语林，感受就是海洋公园里头太阳那么大，极地动物还要表演也是一种折磨。鸟语林不错，各种鸟可以凑近你，喂了它们巧克力面包。 老虎滩公园里的沙滩比星海广场的软，白天能看见细长的小鱼在浅滩处（所以钓鱼抓鱼的都能见到） 之后我又去老虎滩广场了，喂食海鸥，基本上刚开始都不过来都离我很远在天上飞，不过只要象征性的撒几次，海鸥都过来了，他们空中接食很厉害。然后去见了凯宁朋友一起吃了饭喝了点酒，晚上去了凯宁家吃的饭，饭菜主打海鲜，但是吃不掉有些多，第一次吃知了猴，味道不错哦，高蛋白，别人都是把知了当主食吃。 傍晚走在老虎滩的海边大道上一种夏日的宁静。 晚上在大院散步是凯宁不知怎么说到了法国对应于中国难忘春宵的曲子是Les demons De Minuit，二三十年的老歌，每当什么活动大家就唱这个，所以他也顺便学学。节奏感很好听 接着就外放着这首歌晚上去了星海广场，顺便也踩沙滩了，不过很硌脚。 晚上的星海湾大桥开灯了，很长，打通了开发区与星海广场的距离。 2018年7月23日 周一今天早上随便吃了一点后就先去了造船厂看到了辽宁号航空母舰，只能远望 去了金石滩公园，做轻轨3号线花了一个小时(8元)才到，够远的。中午吃了肯德基，直接坐车(20元)坐到了地质公园入口处。然后就又走回了三号线终点，一路上风景很好，都是礁石海滩，穿行在林间感觉特别不错。 就是太热了我们把衣服套头上，好一副沙特王子的样子。下午买了水特产，还看到了鳐鱼 晚上吃了鲅鱼鲜饺等，这是北方特产（听说山东人也爱吃） 2018年7月24日 周二坐飞机回合肥]]></content>
      <categories>
        <category>旅行</category>
      </categories>
      <tags>
        <tag>大连</tag>
      </tags>
  </entry>
</search>
